This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.github/
  ISSUE_TEMPLATE/
    bug_report.md
    feature_request.md
  workflows/
    python-package.yml
    release.yml
  PULL_REQUEST_TEMPLATE.md
docs/
  refactoring_progress.md
folder_extractor/
  cli/
    __init__.py
    app_v2.py
    app.py
    interface.py
    parser.py
  config/
    __init__.py
    constants.py
    settings.py
  core/
    __init__.py
    extractor_v2.py
    extractor.py
    file_discovery.py
    file_operations.py
    migration.py
    progress.py
    state_manager.py
    state.py
  utils/
    __init__.py
    file_validators.py
    parsers.py
    path_validators.py
    terminal.py
  __init__.py
  main_final.py
  main_new.py
  main_refactored.py
test_folder/
  subdir/
    .hiddensubdir/
      inside.txt
    .hidden2.txt
    normal.txt
  .hidden.txt
tests/
  integration/
    test_backward_compatibility.py
    test_extraction_workflow.py
  performance/
    test_benchmarks.py
  unit/
    test_cli_app.py
    test_cli_interface.py
    test_cli_parser.py
    test_core_extractor.py
    test_core_file_discovery.py
    test_core_file_operations.py
    test_file_operations.py
    test_new_parsers.py
    test_progress.py
    test_state_manager.py
    test_validators.py
  __init__.py
  conftest.py
  README.md
.coderabbit.yaml
.gitignore
ARCHITECTURE.md
CHANGELOG.md
CLAUDE.md
CODE_OF_CONDUCT.md
CODE_RABBIT_SETUP.md
CONTRIBUTING.md
FINAL_SETUP_SUMMARY.md
GITHUB_README.md
GITHUB_SETUP_SUMMARY.md
LICENSE
README.md
requirements.txt
run_tests.py
setup.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".github/ISSUE_TEMPLATE/bug_report.md">
---
name: Bug Report
about: Report a bug in Folder Extractor
title: "[BUG] "
labels: bug
assignees: ''
---

## üêõ Bug Report

### Describe the Bug
A clear and concise description of what the bug is.

### To Reproduce
Steps to reproduce the behavior:
1. Go to '...'
2. Run command '....'
3. See error

### Expected Behavior
A clear and concise description of what you expected to happen.

### Actual Behavior
What actually happened.

### Screenshots
If applicable, add screenshots to help explain your problem.

### Environment
- **OS**: [e.g., macOS, Windows, Linux]
- **Python Version**: [e.g., 3.8, 3.9, 3.10]
- **Folder Extractor Version**: [e.g., 1.3.3]
- **Installation Method**: [pip, source, other]

### Additional Context
Add any other context about the problem here.

### Logs
If applicable, include error logs or stack traces:

```
Paste error output here
```

### Possible Solution
If you have suggestions for a fix, please describe it.
</file>

<file path=".github/ISSUE_TEMPLATE/feature_request.md">
---
name: Feature Request
about: Suggest an idea for Folder Extractor
title: "[FEATURE] "
labels: enhancement
assignees: ''
---

## üöÄ Feature Request

### Is your feature request related to a problem?
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]

### Describe the Solution
A clear and concise description of what you want to happen.

### Describe Alternatives
A clear and concise description of any alternative solutions or features you've considered.

### Additional Context
Add any other context or screenshots about the feature request here.

### Use Cases
Describe specific use cases where this feature would be helpful:

1. Use case 1
2. Use case 2

### Technical Considerations
If you have thoughts on how this could be implemented, please share them:

- Should it be a new command-line option?
- Should it modify existing behavior?
- Any specific libraries or approaches that could help?
</file>

<file path=".github/workflows/python-package.yml">
name: Python Package CI

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.7", "3.8", "3.9", "3.10", "3.11", "3.12"]

    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-cov
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    
    - name: Install package
      run: pip install -e .
    
    - name: Run tests with coverage
      run: |
        python -m pytest tests/ --cov=folder_extractor --cov-report=xml
    
    - name: Upload coverage to Codecov
      if: matrix.python-version == '3.12'
      uses: codecov/codecov-action@v3
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  lint:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.12"
    
    - name: Install linting tools
      run: |
        python -m pip install --upgrade pip
        pip install black flake8 isort
    
    - name: Run Black
      run: black --check .
    
    - name: Run Flake8
      run: flake8 .
    
    - name: Run isort
      run: isort --check .

  build:
    runs-on: ubuntu-latest
    needs: [test, lint]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.12"
    
    - name: Install build dependencies
      run: pip install build twine
    
    - name: Build package
      run: python -m build
    
    - name: Check package
      run: twine check dist/*
    
    - name: Upload artifacts
      uses: actions/upload-artifact@v3
      with:
        name: python-package
        path: dist/
</file>

<file path=".github/workflows/release.yml">
name: Release

on:
  push:
    tags:
      - 'v*'

jobs:
  release:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.12"
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build twine
    
    - name: Build package
      run: python -m build
    
    - name: Create Release
      id: create_release
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: ${{ github.ref }}
        release_name: Release ${{ github.ref }}
        draft: false
        prerelease: false
    
    - name: Upload Release Asset
      uses: actions/upload-release-asset@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        upload_url: ${{ steps.create_release.outputs.upload_url }}
        asset_path: ./dist/folder_extractor-${{ github.ref_name }}-py3-none-any.whl
        asset_name: folder_extractor-${{ github.ref_name }}-py3-none-any.whl
        asset_content_type: application/octet-stream
    
    - name: Upload Release Asset (tar.gz)
      uses: actions/upload-release-asset@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        upload_url: ${{ steps.create_release.outputs.upload_url }}
        asset_path: ./dist/folder_extractor-${{ github.ref_name }}.tar.gz
        asset_name: folder_extractor-${{ github.ref_name }}.tar.gz
        asset_content_type: application/gzip
</file>

<file path=".github/PULL_REQUEST_TEMPLATE.md">
# Pull Request

## üìã Description

Please provide a clear and concise description of what this PR does.

## üéØ Related Issue

- Fixes # (issue number)
- Addresses # (issue number)
- Related to # (issue number)

## ‚úÖ Checklist

- [ ] I have read the [CONTRIBUTING.md](CONTRIBUTING.md) guidelines
- [ ] My code follows the project's code style
- [ ] I have added tests for my changes
- [ ] All existing tests pass
- [ ] I have updated the documentation (if applicable)
- [ ] I have added appropriate comments to my code
- [ ] My changes maintain backward compatibility

## üîß Changes Made

- Change 1: Description
- Change 2: Description
- Change 3: Description

## üß™ Testing

Describe how you tested your changes:

- Test scenario 1
- Test scenario 2
- Test scenario 3

## üìä Performance Impact

If applicable, describe any performance implications:

- Before: X ms
- After: Y ms
- Improvement: Z%

## üìù Additional Notes

Any additional information that might be helpful for reviewers.
</file>

<file path="docs/refactoring_progress.md">
# Folder Extractor Refactoring Progress

## Overview
This document tracks the progress of refactoring the monolithic `main.py` into a modular architecture.

## Phase 1: Test Suite Creation ‚úÖ
- Created comprehensive test suite with 100+ tests
- Unit tests for all major functions
- Integration tests for workflows
- Performance benchmarks
- Test infrastructure (fixtures, runners)

## Phase 2: Project Structure & Constants ‚úÖ
- Created modular directory structure
- Extracted all constants to `config/constants.py`
- Created settings management in `config/settings.py`
- Extracted utility modules:
  - `utils/parsers.py` - Command line parsing
  - `utils/file_validators.py` - File validation
  - `utils/path_validators.py` - Path security
  - `utils/terminal.py` - Terminal handling

## Phase 3: Core Modules (In Progress) üöß
### Completed:
- ‚úÖ `core/file_operations.py` - File operations with interfaces
  - FileOperations class (move, rename, type detection)
  - HistoryManager class (undo functionality)
  - FileMover class (high-level moving operations)
  - Full test coverage

- ‚úÖ `core/file_discovery.py` - File finding with interfaces
  - FileDiscovery class (find files, check domains)
  - FileFilter class (advanced filtering)
  - Full test coverage

### Remaining in Phase 3:
- [ ] Extract FileExtractor main business logic
- [ ] Create interfaces for all core components
- [ ] Update main.py to use new modules

## Phase 4: UI/CLI Separation (Pending)
- [ ] Extract argument parsing
- [ ] Extract user interaction
- [ ] Extract progress display
- [ ] Create CLI interface

## Phase 5: State Management (Pending)
- [ ] Extract global state (abort_signal)
- [ ] Create proper state container
- [ ] Implement dependency injection

## Phase 6: Integration (Pending)
- [ ] Update main.py to use all new modules
- [ ] Ensure backward compatibility
- [ ] Migration guide

## Phase 7: Documentation & Cleanup (Pending)
- [ ] API documentation
- [ ] Architecture documentation
- [ ] Remove old code
- [ ] Final testing

## Key Improvements So Far

### Architecture
- Introduced interfaces (ABC) for all major components
- Clear separation of concerns
- Dependency injection ready
- Testable design

### Code Quality
- Type hints throughout
- Comprehensive docstrings
- Error handling improvements
- No global state in new modules

### Testing
- 100% compatibility with original behavior
- Unit tests for each module
- Integration tests maintained
- Performance benchmarks

## Next Steps
1. Complete Phase 3 by extracting FileExtractor
2. Begin Phase 4 with CLI separation
3. Implement proper state management
4. Final integration and testing
</file>

<file path="folder_extractor/cli/__init__.py">
"""
Command Line Interface module for Folder Extractor.
"""
</file>

<file path="folder_extractor/cli/app_v2.py">
"""
Enhanced CLI application with integrated state management.

Coordinates the command line interface with new state management
and progress tracking capabilities.
"""
import os
import sys
from typing import Optional

from folder_extractor.cli.parser import create_parser
from folder_extractor.cli.interface import (
    create_console_interface, KeyboardHandler
)
from folder_extractor.core.extractor_v2 import (
    EnhancedFileExtractor, EnhancedExtractionOrchestrator
)
from folder_extractor.core.state_manager import (
    get_state_manager, ManagedOperation
)
from folder_extractor.core.progress import ProgressInfo
from folder_extractor.config.settings import configure_from_args
from folder_extractor.config.constants import MESSAGES


class EnhancedFolderExtractorCLI:
    """Enhanced CLI application with state management."""
    
    def __init__(self):
        """Initialize enhanced CLI application."""
        self.parser = create_parser()
        self.interface = create_console_interface()
        self.state_manager = get_state_manager()
    
    def run(self, args: Optional[list] = None) -> int:
        """Run the CLI application.
        
        Args:
            args: Optional command line arguments
        
        Returns:
            Exit code (0 for success, non-zero for error)
        """
        try:
            # Parse arguments
            parsed_args = self.parser.parse_args(args)
            
            # Configure settings from arguments
            configure_from_args(parsed_args)
            
            # Migrate settings to state manager
            from folder_extractor.core.migration import MigrationHelper
            MigrationHelper.migrate_settings()
            
            # Get current directory
            current_dir = os.getcwd()
            
            # Show welcome message
            if not parsed_args.undo:
                self.interface.show_welcome()
            
            # Execute operation
            if parsed_args.undo:
                return self._execute_undo(current_dir)
            else:
                return self._execute_extraction(current_dir)
        
        except KeyboardInterrupt:
            print("\n" + MESSAGES["OPERATION_CANCELLED"])
            return 1
        
        except Exception as e:
            self.interface.show_message(
                f"Fehler: {str(e)}", 
                message_type="error"
            )
            return 1
    
    def _execute_extraction(self, path: str) -> int:
        """Execute file extraction operation.
        
        Args:
            path: Path to extract files from
        
        Returns:
            Exit code
        """
        # Create extractor and orchestrator
        extractor = EnhancedFileExtractor(state_manager=self.state_manager)
        orchestrator = EnhancedExtractionOrchestrator(extractor, self.state_manager)
        
        # Set up progress integration
        def progress_callback(current: int, total: int, 
                            filepath: str, error: Optional[str] = None):
            self.interface.show_progress(current, total, filepath, error)
        
        # Set up keyboard handler for abort
        keyboard_handler = None
        if not self.state_manager.get_value("dry_run", False):
            keyboard_handler = KeyboardHandler(
                lambda: self.state_manager.request_abort()
            )
            keyboard_handler.start()
        
        try:
            # Execute extraction
            result = orchestrator.execute_extraction(
                source_path=path,
                confirmation_callback=self.interface.confirm_operation,
                progress_callback=progress_callback
            )
            
            # Show summary
            self.interface.show_summary(result)
            
            # Show operation statistics if available
            if "operation_id" in result:
                stats = self.state_manager.get_operation_stats(result["operation_id"])
                if stats and stats.duration:
                    self.interface.show_message(
                        f"\nOperation dauerte {stats.duration:.2f} Sekunden",
                        message_type="info"
                    )
                    if stats.files_processed > 0:
                        rate = stats.files_processed / stats.duration
                        self.interface.show_message(
                            f"Durchschnitt: {rate:.1f} Dateien/Sekunde",
                            message_type="info"
                        )
            
            # Return appropriate exit code
            if result.get("status") == "success":
                return 0
            elif result.get("status") in ["no_files", "cancelled"]:
                return 0  # Not an error
            else:
                return 1
        
        finally:
            # Stop keyboard handler
            if keyboard_handler:
                keyboard_handler.stop()
    
    def _execute_undo(self, path: str) -> int:
        """Execute undo operation.
        
        Args:
            path: Path where history is located
        
        Returns:
            Exit code
        """
        # Create extractor and orchestrator
        extractor = EnhancedFileExtractor(state_manager=self.state_manager)
        orchestrator = EnhancedExtractionOrchestrator(extractor, self.state_manager)
        
        # Show operation message
        self.interface.show_message(
            "R√ºckg√§ngig machen der letzten Operation...",
            message_type="info"
        )
        
        # Execute undo
        result = orchestrator.execute_undo(path)
        
        # Show result
        self.interface.show_message(
            result["message"],
            message_type="success" if result["status"] == "success" else "warning"
        )
        
        # Show statistics if available
        if result.get("restored", 0) > 0:
            self.interface.show_message(
                f"‚úì {result['restored']} Dateien wiederhergestellt",
                message_type="success"
            )
            if result.get("errors", 0) > 0:
                self.interface.show_message(
                    f"‚úó {result['errors']} Fehler aufgetreten",
                    message_type="error"
                )
        
        return 0 if result["status"] == "success" else 1


def main(args: Optional[list] = None) -> int:
    """Main entry point for the enhanced CLI.
    
    Args:
        args: Optional command line arguments
    
    Returns:
        Exit code
    """
    app = EnhancedFolderExtractorCLI()
    return app.run(args)


if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="folder_extractor/cli/app.py">
"""
Main CLI application module.

Coordinates the command line interface for Folder Extractor.
"""
import os
import sys
from typing import Optional

from folder_extractor.cli.parser import create_parser
from folder_extractor.cli.interface import (
    create_console_interface, KeyboardHandler
)
from folder_extractor.core.extractor import (
    FileExtractor, ExtractionOrchestrator
)
from folder_extractor.core.state import get_app_state, OperationContext
from folder_extractor.config.settings import configure_from_args, settings
from folder_extractor.config.constants import MESSAGES


class FolderExtractorCLI:
    """Main CLI application class."""
    
    def __init__(self):
        """Initialize CLI application."""
        self.parser = create_parser()
        self.interface = create_console_interface()
        self.app_state = get_app_state()
    
    def run(self, args: Optional[list] = None) -> int:
        """Run the CLI application.
        
        Args:
            args: Optional command line arguments
        
        Returns:
            Exit code (0 for success, non-zero for error)
        """
        try:
            # Parse arguments
            parsed_args = self.parser.parse_args(args)
            
            # Configure settings from arguments
            configure_from_args(parsed_args)
            
            # Get current directory
            current_dir = os.getcwd()
            
            # Show welcome message
            if not parsed_args.undo:
                self.interface.show_welcome()
            
            # Execute operation
            with OperationContext(self.app_state) as context:
                if parsed_args.undo:
                    return self._execute_undo(current_dir, context)
                else:
                    return self._execute_extraction(current_dir, context)
        
        except KeyboardInterrupt:
            print("\n" + MESSAGES["OPERATION_CANCELLED"])
            return 1
        
        except Exception as e:
            self.interface.show_message(
                f"Fehler: {str(e)}", 
                message_type="error"
            )
            return 1
    
    def _execute_extraction(self, path: str, context: OperationContext) -> int:
        """Execute file extraction operation.
        
        Args:
            path: Path to extract files from
            context: Operation context
        
        Returns:
            Exit code
        """
        # Create extractor and orchestrator
        extractor = FileExtractor(abort_signal=context.abort_signal)
        orchestrator = ExtractionOrchestrator(extractor)
        
        # Set up keyboard handler for abort
        keyboard_handler = None
        if not settings.get("dry_run", False):
            keyboard_handler = KeyboardHandler(
                lambda: self.app_state.request_abort()
            )
            keyboard_handler.start()
        
        try:
            # Execute extraction
            result = orchestrator.execute_extraction(
                source_path=path,
                confirmation_callback=self.interface.confirm_operation,
                progress_callback=self.interface.show_progress
            )
            
            # Check if aborted
            if self.app_state.is_abort_requested():
                result["aborted"] = True
            
            # Show summary
            self.interface.show_summary(result)
            
            # Return appropriate exit code
            if result.get("status") == "success":
                return 0
            elif result.get("status") in ["no_files", "cancelled"]:
                return 0  # Not an error
            else:
                return 1
        
        finally:
            # Stop keyboard handler
            if keyboard_handler:
                keyboard_handler.stop()
    
    def _execute_undo(self, path: str, context: OperationContext) -> int:
        """Execute undo operation.
        
        Args:
            path: Path where history is located
            context: Operation context
        
        Returns:
            Exit code
        """
        # Create extractor and orchestrator
        extractor = FileExtractor(abort_signal=context.abort_signal)
        orchestrator = ExtractionOrchestrator(extractor)
        
        # Show operation message
        self.interface.show_message(
            "R√ºckg√§ngig machen der letzten Operation...",
            message_type="info"
        )
        
        # Execute undo
        result = orchestrator.execute_undo(path)
        
        # Show result
        self.interface.show_message(
            result["message"],
            message_type="success" if result["status"] == "success" else "warning"
        )
        
        return 0 if result["status"] == "success" else 1


def main(args: Optional[list] = None) -> int:
    """Main entry point for the CLI.
    
    Args:
        args: Optional command line arguments
    
    Returns:
        Exit code
    """
    app = FolderExtractorCLI()
    return app.run(args)


if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="folder_extractor/cli/interface.py">
"""
Command line interface module.

Handles user interaction, progress display, and terminal operations.
"""
import os
import sys
import threading
import time
from typing import Optional, Callable, Any
from abc import ABC, abstractmethod

from folder_extractor.config.constants import (
    MESSAGES, VERSION, AUTHOR, TERMINAL_CLEAR_LINE
)
from folder_extractor.utils.terminal import (
    Color, clear_line, format_progress_bar, 
    save_terminal_settings, restore_terminal_settings,
    set_raw_mode
)
from folder_extractor.config.settings import settings


class IUserInterface(ABC):
    """Interface for user interaction."""
    
    @abstractmethod
    def show_welcome(self) -> None:
        """Show welcome message."""
        pass
    
    @abstractmethod
    def show_message(self, message: str, message_type: str = "info") -> None:
        """Show a message to the user."""
        pass
    
    @abstractmethod
    def confirm_operation(self, file_count: int) -> bool:
        """Get user confirmation for operation."""
        pass
    
    @abstractmethod
    def show_progress(self, current: int, total: int, 
                     filepath: str, error: Optional[str] = None) -> None:
        """Show operation progress."""
        pass
    
    @abstractmethod
    def show_summary(self, results: dict) -> None:
        """Show operation summary."""
        pass


class ConsoleInterface(IUserInterface):
    """Console-based user interface implementation."""
    
    def __init__(self):
        """Initialize console interface."""
        self.last_progress_update = 0
        self.progress_update_interval = 0.1
    
    def show_welcome(self) -> None:
        """Show welcome message."""
        message = MESSAGES["WELCOME"].format(
            version=VERSION,
            author=AUTHOR
        )
        print(message)
    
    def show_message(self, message: str, message_type: str = "info") -> None:
        """Show a message to the user.
        
        Args:
            message: Message to display
            message_type: Type of message (info, success, error, warning)
        """
        if settings.get("quiet", False):
            return
        
        # Apply color based on type
        if message_type == "success":
            message = Color.success(message)
        elif message_type == "error":
            message = Color.error(message)
        elif message_type == "warning":
            message = Color.warning(message)
        elif message_type == "info":
            message = Color.info(message)
        
        print(message)
    
    def confirm_operation(self, file_count: int) -> bool:
        """Get user confirmation for operation.
        
        Args:
            file_count: Number of files to be processed
        
        Returns:
            True if user confirms, False otherwise
        """
        if settings.get("dry_run", False):
            return True  # No confirmation needed for dry run
        
        if not settings.get("confirm_operations", True):
            return True  # Auto-confirm if disabled
        
        # Show file count
        print(MESSAGES["FILES_FOUND"].format(count=file_count))
        
        # Get confirmation
        try:
            response = input(MESSAGES["CONFIRM_MOVE"]).lower().strip()
            return response in ['j', 'ja', 'y', 'yes']
        except (KeyboardInterrupt, EOFError):
            return False
    
    def show_progress(self, current: int, total: int, 
                     filepath: str, error: Optional[str] = None) -> None:
        """Show operation progress.
        
        Args:
            current: Current file number
            total: Total number of files
            filepath: Current file path
            error: Optional error message
        """
        if settings.get("quiet", False):
            return
        
        # Rate limit updates
        current_time = time.time()
        if (current_time - self.last_progress_update) < self.progress_update_interval:
            return
        self.last_progress_update = current_time
        
        # Clear previous line
        clear_line()
        
        # Format message
        if error:
            message = MESSAGES["MOVE_ERROR"].format(
                file=os.path.basename(filepath),
                error=error
            )
            print(message)
        else:
            # Show progress bar
            progress_bar = format_progress_bar(current, total, width=30)
            filename = os.path.basename(filepath)
            
            # Truncate filename if too long
            max_length = 40
            if len(filename) > max_length:
                filename = filename[:max_length-3] + "..."
            
            print(f"{progress_bar} {filename}", end='', flush=True)
    
    def show_summary(self, results: dict) -> None:
        """Show operation summary.
        
        Args:
            results: Dictionary with operation results
        """
        # Clear progress line
        clear_line()
        
        # Check if operation was aborted
        if results.get("aborted", False):
            print(MESSAGES["OPERATION_ABORTED"])
        
        # Show summary based on operation type
        if results.get("status") == "no_files":
            print(results.get("message", MESSAGES["NO_FILES_FOUND"]))
        
        elif results.get("status") == "cancelled":
            print(results.get("message", MESSAGES["OPERATION_CANCELLED"]))
        
        elif results.get("status") == "success":
            # Show move summary
            if "moved" in results:
                summary = MESSAGES["MOVE_SUMMARY"].format(
                    moved=results.get("moved", 0),
                    duplicates=results.get("duplicates", 0),
                    errors=results.get("errors", 0)
                )
                print(summary)
            
            # Show created folders if sort by type
            if results.get("created_folders"):
                print("\nErstellte Ordner:")
                for folder in results["created_folders"]:
                    print(f"  ‚úì {folder}")
            
            # Show removed directories
            if results.get("removed_directories", 0) > 0:
                print(MESSAGES["EMPTY_FOLDERS_REMOVED"].format(
                    count=results["removed_directories"]
                ))
            
            # Show undo hint
            if not settings.get("dry_run", False) and results.get("moved", 0) > 0:
                print(MESSAGES["UNDO_AVAILABLE"])


class KeyboardHandler:
    """Handles keyboard input for abort functionality."""
    
    def __init__(self, abort_callback: Callable[[], None]):
        """Initialize keyboard handler.
        
        Args:
            abort_callback: Function to call when ESC is pressed
        """
        self.abort_callback = abort_callback
        self.running = False
        self.thread = None
        self.terminal_settings = None
    
    def start(self) -> None:
        """Start listening for keyboard input."""
        if sys.platform == 'win32':
            # Windows not supported for now
            return
        
        self.running = True
        self.thread = threading.Thread(target=self._listen, daemon=True)
        self.thread.start()
        
        # Show hint
        print(MESSAGES["ESC_TO_ABORT"])
    
    def stop(self) -> None:
        """Stop listening for keyboard input."""
        self.running = False
        if self.thread:
            self.thread.join(timeout=0.5)
    
    def _listen(self) -> None:
        """Listen for ESC key press."""
        try:
            # Save terminal settings
            self.terminal_settings = save_terminal_settings()
            
            # Set raw mode
            if not set_raw_mode():
                return
            
            # Listen for keys
            while self.running:
                try:
                    if sys.stdin.isatty():
                        # Read one character
                        char = sys.stdin.read(1)
                        
                        # Check for ESC (ASCII 27)
                        if ord(char) == 27:
                            self.abort_callback()
                            break
                except Exception:
                    pass
                
                time.sleep(0.01)
        
        finally:
            # Restore terminal settings
            if self.terminal_settings:
                restore_terminal_settings(self.terminal_settings)


def create_console_interface() -> ConsoleInterface:
    """Create and return a console interface."""
    return ConsoleInterface()
</file>

<file path="folder_extractor/cli/parser.py">
"""
Command line argument parser.

Handles parsing and validation of CLI arguments.
"""
import argparse
import sys
from typing import Optional, List

from folder_extractor.config.constants import VERSION, AUTHOR, HELP_TEXT
from folder_extractor.utils.parsers import parse_depth


class ArgumentParser:
    """Custom argument parser for Folder Extractor."""
    
    def __init__(self):
        """Initialize argument parser."""
        self.parser = self._create_parser()
    
    def _create_parser(self) -> argparse.ArgumentParser:
        """Create and configure the argument parser."""
        parser = argparse.ArgumentParser(
            prog='folder-extractor',
            description='Dateien aus Unterordnern extrahieren',
            add_help=False,  # We'll handle help ourselves
            formatter_class=argparse.RawDescriptionHelpFormatter
        )
        
        # Add arguments
        parser.add_argument(
            '-h', '--help',
            action='store_true',
            help='Diese Hilfe anzeigen'
        )
        
        parser.add_argument(
            '-v', '--version',
            action='store_true',
            help='Version anzeigen'
        )
        
        parser.add_argument(
            '-d', '--depth',
            type=str,
            default='0',
            metavar='TIEFE',
            help='Maximale Ordnertiefe (0 = unbegrenzt)'
        )
        
        parser.add_argument(
            '-t', '--type',
            type=str,
            metavar='TYPEN',
            help='Nur bestimmte Dateitypen (z.B. pdf,jpg,mp3)'
        )
        
        parser.add_argument(
            '-n', '--dry-run',
            action='store_true',
            help='Testlauf - zeigt was passieren w√ºrde'
        )
        
        parser.add_argument(
            '-s', '--sort-by-type',
            action='store_true',
            help='Dateien nach Typ in Unterordner sortieren'
        )
        
        parser.add_argument(
            '-u', '--undo',
            action='store_true',
            help='Letzte Operation r√ºckg√§ngig machen'
        )
        
        parser.add_argument(
            '--include-hidden',
            action='store_true',
            help='Versteckte Dateien einbeziehen'
        )
        
        parser.add_argument(
            '--domain',
            type=str,
            metavar='DOMAINS',
            help='Nur Weblinks von bestimmten Domains (z.B. youtube.com)'
        )
        
        return parser
    
    def parse_args(self, args: Optional[List[str]] = None) -> argparse.Namespace:
        """Parse command line arguments.
        
        Args:
            args: Optional list of arguments (for testing)
        
        Returns:
            Parsed arguments namespace
        """
        # Parse arguments
        parsed = self.parser.parse_args(args)
        
        # Handle special cases
        if parsed.help:
            self.print_help()
            sys.exit(0)
        
        if parsed.version:
            self.print_version()
            sys.exit(0)
        
        # Validate and convert depth
        try:
            parsed.depth = parse_depth(parsed.depth)
        except ValueError as e:
            self.parser.error(str(e))
        
        return parsed
    
    def print_help(self) -> None:
        """Print custom help text."""
        print(HELP_TEXT)
    
    def print_version(self) -> None:
        """Print version information."""
        print(f"folder-extractor {VERSION}")
        print(f"Von {AUTHOR}")


def create_parser() -> ArgumentParser:
    """Create and return a configured argument parser."""
    return ArgumentParser()
</file>

<file path="folder_extractor/config/__init__.py">
"""
Configuration module for Folder Extractor.
"""
</file>

<file path="folder_extractor/config/constants.py">
"""
Constants and configuration values for Folder Extractor.

This module centralizes all constants, making them easy to modify
and test. All values that were previously hardcoded are now here.
"""
import os
from pathlib import Path


# Version Information
VERSION = "1.3.3"
AUTHOR = "Philipp Briese"


# Safe Paths Configuration
SAFE_FOLDER_NAMES = ["Desktop", "Downloads", "Documents"]


# File System Constants
HIDDEN_FILE_PREFIX = "."
GIT_DIRECTORY = ".git"
HISTORY_FILE_NAME = ".folder_extractor_history.json"


# Temporary and System Files
TEMP_EXTENSIONS = {
    ".tmp", ".temp", ".part", ".partial", ".crdownload", 
    ".download", ".downloading", ".lock", ".lck"
}

SYSTEM_FILES = {
    ".DS_Store", "Thumbs.db", "desktop.ini", ".localized",
    "._*", "~$*", ".~*"
}

EDITOR_TEMP_FILES = {
    ".swp", ".swo", ".swn", ".swm",  # Vim
    ".#*", "#*#",  # Emacs
    "~*",  # General backup
    ".bak", ".backup", ".old"
}

GIT_TEMP_FILES = {
    "COMMIT_EDITMSG", "HEAD", "FETCH_HEAD", "ORIG_HEAD", 
    "MERGE_HEAD", "REBASE_HEAD"
}


# File Type Mappings for Sort-by-Type
FILE_TYPE_FOLDERS = {
    # Documents
    ".pdf": "PDF",
    ".doc": "DOC",
    ".docx": "DOC",
    ".odt": "ODT",
    ".rtf": "RTF",
    ".tex": "TEX",
    
    # Spreadsheets
    ".xls": "EXCEL",
    ".xlsx": "EXCEL",
    ".ods": "ODS",
    ".csv": "CSV",
    
    # Presentations
    ".ppt": "POWERPOINT",
    ".pptx": "POWERPOINT",
    ".odp": "ODP",
    
    # Images
    ".jpg": "JPEG",
    ".jpeg": "JPEG",
    ".png": "PNG",
    ".gif": "GIF",
    ".bmp": "BMP",
    ".svg": "SVG",
    ".ico": "ICO",
    ".tiff": "TIFF",
    ".tif": "TIFF",
    ".webp": "WEBP",
    ".heic": "HEIC",
    ".heif": "HEIC",
    
    # Videos
    ".mp4": "VIDEO",
    ".avi": "VIDEO",
    ".mkv": "VIDEO",
    ".mov": "VIDEO",
    ".wmv": "VIDEO",
    ".flv": "VIDEO",
    ".webm": "VIDEO",
    ".m4v": "VIDEO",
    ".mpg": "VIDEO",
    ".mpeg": "VIDEO",
    
    # Audio
    ".mp3": "AUDIO",
    ".wav": "AUDIO",
    ".flac": "AUDIO",
    ".aac": "AUDIO",
    ".ogg": "AUDIO",
    ".wma": "AUDIO",
    ".m4a": "AUDIO",
    ".opus": "AUDIO",
    
    # Archives
    ".zip": "ZIP",
    ".rar": "RAR",
    ".7z": "7ZIP",
    ".tar": "TAR",
    ".gz": "GZ",
    ".bz2": "BZ2",
    ".xz": "XZ",
    
    # Code
    ".py": "PYTHON",
    ".js": "JAVASCRIPT",
    ".ts": "TYPESCRIPT",
    ".java": "JAVA",
    ".cpp": "CPP",
    ".c": "C",
    ".h": "C",
    ".cs": "CSHARP",
    ".php": "PHP",
    ".rb": "RUBY",
    ".go": "GO",
    ".rs": "RUST",
    ".swift": "SWIFT",
    ".kt": "KOTLIN",
    ".r": "R",
    ".m": "MATLAB",
    
    # Web
    ".html": "HTML",
    ".htm": "HTML",
    ".css": "CSS",
    ".scss": "SCSS",
    ".sass": "SASS",
    ".less": "LESS",
    
    # Data
    ".json": "JSON",
    ".xml": "XML",
    ".yaml": "YAML",
    ".yml": "YAML",
    ".toml": "TOML",
    ".ini": "INI",
    ".cfg": "CONFIG",
    ".conf": "CONFIG",
    
    # Text
    ".txt": "TEXT",
    ".md": "MARKDOWN",
    ".rst": "RST",
    ".log": "LOG",
    
    # Database
    ".sql": "SQL",
    ".db": "DATABASE",
    ".sqlite": "SQLITE",
    
    # Fonts
    ".ttf": "FONT",
    ".otf": "FONT",
    ".woff": "FONT",
    ".woff2": "FONT",
    
    # Other
    ".iso": "ISO",
    ".dmg": "DMG",
    ".exe": "EXE",
    ".app": "APP",
    ".deb": "DEB",
    ".rpm": "RPM",
}


# Default folder name for files without extension
NO_EXTENSION_FOLDER = "OHNE_ERWEITERUNG"


# Terminal Control
TERMINAL_CLEAR_LINE = "\r\033[K"
PROGRESS_BAR_WIDTH = 50


# User Interface Messages (German)
MESSAGES = {
    "WELCOME": """
Folder Extractor v{version}
Von {author}

Dieses Tool extrahiert alle Dateien aus Unterordnern in das aktuelle Verzeichnis.
""",
    
    "SECURITY_ERROR": """
‚ö†Ô∏è  SICHERHEITSWARNUNG: Dieses Tool darf nur in folgenden Ordnern ausgef√ºhrt werden:
   - Desktop
   - Downloads  
   - Documents
   
Aktueller Pfad: {path}

Bitte navigieren Sie zu einem der erlaubten Ordner.
""",
    
    "NO_FILES_FOUND": "Keine Dateien in Unterordnern gefunden.",
    
    "FILES_FOUND": "\n{count} Dateien in Unterordnern gefunden.",
    
    "CONFIRM_MOVE": "\nM√∂chten Sie diese Dateien hierher verschieben? (j/n): ",
    
    "OPERATION_CANCELLED": "\nOperation abgebrochen.",
    
    "MOVING_FILES": "\nVerschiebe Dateien...",
    
    "DRY_RUN_PREFIX": "[TEST] ",
    
    "MOVE_SUCCESS": "‚úì {file}",
    
    "MOVE_ERROR": "‚úó Fehler bei {file}: {error}",
    
    "DUPLICATE_RENAMED": "‚ö†Ô∏è  {old} ‚Üí {new} (umbenannt)",
    
    "OPERATION_ABORTED": "\n\n‚ö†Ô∏è  Operation wurde abgebrochen!",
    
    "MOVE_SUMMARY": """

==================================================
Zusammenfassung:
‚úì {moved} Dateien verschoben
‚ö†Ô∏è  {duplicates} Dateien umbenannt (Duplikate)
‚úó {errors} Fehler
==================================================
""",
    
    "EMPTY_FOLDERS_REMOVED": "\n‚úì {count} leere Ordner entfernt.",
    
    "UNDO_AVAILABLE": "\nR√ºckg√§ngig machen mit: folder-extractor --undo",
    
    "UNDO_NO_HISTORY": "Keine Verlaufsdatei gefunden. Nichts zum R√ºckg√§ngigmachen.",
    
    "UNDO_SUCCESS": "‚úì {file} wiederhergestellt",
    
    "UNDO_ERROR": "‚úó Fehler beim Wiederherstellen von {file}: {error}",
    
    "UNDO_SUMMARY": "\n‚úì {count} Dateien erfolgreich wiederhergestellt.",
    
    "SORT_BY_TYPE_CREATING": "\nErstelle Ordnerstruktur nach Dateityp...",
    
    "SORT_BY_TYPE_CREATED": "‚úì Ordner '{folder}' erstellt",
    
    "ESC_TO_ABORT": "\nDr√ºcken Sie ESC zum Abbrechen...",
}


# Help Text
HELP_TEXT = """
Folder Extractor - Dateien aus Unterordnern extrahieren

Verwendung:
    folder-extractor [OPTIONEN]

Optionen:
    -h, --help              Diese Hilfe anzeigen
    -v, --version           Version anzeigen
    -d, --depth TIEFE       Maximale Ordnertiefe (0 = unbegrenzt, Standard: 0)
    -t, --type TYPEN        Nur bestimmte Dateitypen (z.B. pdf,jpg,mp3)
    -n, --dry-run           Testlauf - zeigt was passieren w√ºrde
    -s, --sort-by-type      Dateien nach Typ in Unterordner sortieren
    -u, --undo              Letzte Operation r√ºckg√§ngig machen
    --include-hidden        Versteckte Dateien einbeziehen
    --domain DOMAINS        Nur Weblinks von bestimmten Domains (z.B. youtube.com)

Beispiele:
    # Alle Dateien aus Unterordnern extrahieren
    folder-extractor
    
    # Nur PDFs und Bilder extrahieren
    folder-extractor --type pdf,jpg,png
    
    # Dateien nach Typ sortiert extrahieren
    folder-extractor --sort-by-type
    
    # Nur Dateien aus direkten Unterordnern (Tiefe 1)
    folder-extractor --depth 1
    
    # Testlauf ohne Dateien zu verschieben
    folder-extractor --dry-run
    
    # Nur YouTube-Links extrahieren
    folder-extractor --type url,webloc --domain youtube.com
    
    # Letzte Operation r√ºckg√§ngig machen
    folder-extractor --undo

Sicherheit:
    Das Tool funktioniert nur in den Ordnern Desktop, Downloads und Documents.
    
Tastenk√ºrzel:
    ESC - Operation abbrechen (w√§hrend Dateien verschoben werden)
"""


# Error Messages
ERROR_MESSAGES = {
    "PERMISSION_DENIED": "Zugriff verweigert",
    "FILE_NOT_FOUND": "Datei nicht gefunden",
    "DISK_FULL": "Nicht gen√ºgend Speicherplatz",
    "INVALID_PATH": "Ung√ºltiger Pfad",
    "UNKNOWN_ERROR": "Unbekannter Fehler",
}


# Limits and Defaults
MAX_PATH_LENGTH = 255  # Maximum file path length
DEFAULT_MAX_DEPTH = 0  # 0 means unlimited
PROGRESS_UPDATE_INTERVAL = 0.1  # seconds between progress updates


# Performance Tuning
BATCH_SIZE = 100  # Number of files to process in one batch
CACHE_SIZE = 1000  # Number of paths to cache
</file>

<file path="folder_extractor/config/settings.py">
"""
Runtime settings and configuration management.

This module handles runtime configuration that can be modified
during execution, unlike constants which are fixed.
"""
import os
import json
from pathlib import Path
from typing import Dict, Any, Optional


class Settings:
    """Runtime settings manager."""
    
    def __init__(self):
        """Initialize default settings."""
        self.reset_to_defaults()
    
    def reset_to_defaults(self):
        """Reset all settings to default values."""
        self._settings = {
            # Operation settings
            "dry_run": False,
            "max_depth": 0,
            "include_hidden": False,
            "sort_by_type": False,
            
            # Filtering
            "file_type_filter": None,
            "domain_filter": None,
            
            # Performance
            "batch_size": 100,
            "show_progress": True,
            "progress_update_interval": 0.1,
            
            # Safety
            "confirm_operations": True,
            "safe_mode": True,
            
            # Output
            "verbose": False,
            "quiet": False,
            "color_output": True,
        }
    
    def get(self, key: str, default: Any = None) -> Any:
        """Get a setting value."""
        return self._settings.get(key, default)
    
    def set(self, key: str, value: Any) -> None:
        """Set a setting value."""
        self._settings[key] = value
    
    def update(self, settings: Dict[str, Any]) -> None:
        """Update multiple settings at once."""
        self._settings.update(settings)
    
    def to_dict(self) -> Dict[str, Any]:
        """Export settings as dictionary."""
        return self._settings.copy()
    
    def from_dict(self, settings: Dict[str, Any]) -> None:
        """Import settings from dictionary."""
        self._settings = settings.copy()
    
    def save_to_file(self, filepath: Path) -> None:
        """Save settings to JSON file."""
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self._settings, f, indent=2)
    
    def load_from_file(self, filepath: Path) -> None:
        """Load settings from JSON file."""
        if filepath.exists():
            with open(filepath, 'r', encoding='utf-8') as f:
                self._settings = json.load(f)
    
    @property
    def dry_run(self) -> bool:
        return self._settings["dry_run"]
    
    @property
    def max_depth(self) -> int:
        return self._settings["max_depth"]
    
    @property
    def include_hidden(self) -> bool:
        return self._settings["include_hidden"]
    
    @property
    def sort_by_type(self) -> bool:
        return self._settings["sort_by_type"]
    
    @property
    def file_type_filter(self) -> Optional[list]:
        return self._settings["file_type_filter"]
    
    @property
    def domain_filter(self) -> Optional[list]:
        return self._settings["domain_filter"]


# Global settings instance
settings = Settings()


def configure_from_args(args) -> None:
    """Configure settings from command line arguments."""
    settings.set("dry_run", args.dry_run)
    settings.set("max_depth", args.depth)
    settings.set("include_hidden", args.include_hidden)
    settings.set("sort_by_type", args.sort_by_type)
    
    # Parse filters
    if args.type:
        from folder_extractor.utils.parsers import parse_file_types
        settings.set("file_type_filter", parse_file_types(args.type))
    
    if args.domain:
        from folder_extractor.utils.parsers import parse_domains
        settings.set("domain_filter", parse_domains(args.domain))
</file>

<file path="folder_extractor/core/__init__.py">
"""
Core business logic for Folder Extractor.
"""
</file>

<file path="folder_extractor/core/extractor_v2.py">
"""
Enhanced extractor module with state management integration.

Coordinates file discovery, filtering, and moving operations
with integrated progress tracking and state management.
"""
import os
from typing import List, Optional, Dict, Any, Callable
from abc import ABC, abstractmethod

from folder_extractor.core.file_discovery import IFileDiscovery, FileDiscovery
from folder_extractor.core.file_operations import (
    IFileOperations, FileOperations, FileMover, HistoryManager
)
from folder_extractor.core.state_manager import (
    IStateManager, ManagedOperation, get_state_manager
)
from folder_extractor.core.progress import (
    IProgressTracker, ProgressTracker, ProgressInfo
)
from folder_extractor.config.settings import settings
from folder_extractor.utils.path_validators import is_safe_path
from folder_extractor.config.constants import MESSAGES


class ExtractionError(Exception):
    """Base exception for extraction errors."""
    pass


class SecurityError(ExtractionError):
    """Raised when security validation fails."""
    pass


class IEnhancedExtractor(ABC):
    """Interface for enhanced file extraction with state management."""
    
    @abstractmethod
    def validate_security(self, path: str) -> None:
        """Validate that the path is safe for operations."""
        pass
    
    @abstractmethod
    def discover_files(self, path: str) -> List[str]:
        """Discover files based on current settings."""
        pass
    
    @abstractmethod
    def extract_files(self, files: List[str], destination: str,
                     operation_id: Optional[str] = None,
                     progress_callback: Optional[Callable[[int, int, str, Optional[str]], None]] = None) -> Dict[str, Any]:
        """Extract files to destination with operation tracking."""
        pass
    
    @abstractmethod
    def undo_last_operation(self, path: str) -> Dict[str, Any]:
        """Undo the last operation."""
        pass


class EnhancedFileExtractor(IEnhancedExtractor):
    """Enhanced file extractor with integrated state and progress tracking."""
    
    def __init__(self,
                 file_discovery: Optional[IFileDiscovery] = None,
                 file_operations: Optional[IFileOperations] = None,
                 state_manager: Optional[IStateManager] = None):
        """Initialize enhanced extractor.
        
        Args:
            file_discovery: File discovery implementation
            file_operations: File operations implementation
            state_manager: State manager implementation
        """
        self.file_discovery = file_discovery or FileDiscovery()
        self.file_operations = file_operations or FileOperations()
        self.state_manager = state_manager or get_state_manager()
        self.history_manager = HistoryManager()
    
    def validate_security(self, path: str) -> None:
        """Validate that the path is safe for operations."""
        if not is_safe_path(path):
            raise SecurityError(
                MESSAGES["SECURITY_ERROR"].format(path=path)
            )
    
    def discover_files(self, path: str) -> List[str]:
        """Discover files based on current settings."""
        return self.file_discovery.find_files(
            directory=path,
            max_depth=settings.get("max_depth", 0),
            file_type_filter=settings.get("file_type_filter"),
            include_hidden=settings.get("include_hidden", False)
        )
    
    def extract_files(self, files: List[str], destination: str,
                     operation_id: Optional[str] = None,
                     progress_callback: Optional[Callable[[int, int, str, Optional[str]], None]] = None) -> Dict[str, Any]:
        """Extract files to destination with operation tracking.
        
        Args:
            files: List of files to extract
            destination: Destination directory
            operation_id: Optional operation ID for tracking
            progress_callback: Optional progress callback
        
        Returns:
            Dictionary with extraction results
        """
        results = {
            "moved": 0,
            "skipped": 0,
            "duplicates": 0,
            "errors": 0,
            "created_folders": [],
            "history": []
        }
        
        # Get abort signal from state manager
        abort_signal = self.state_manager.get_abort_signal()
        
        # Create file mover with abort signal
        file_mover = FileMover(self.file_operations, abort_signal)
        
        # Create progress tracker
        def update_progress(info: ProgressInfo):
            # Update operation stats in state manager
            if operation_id:
                self.state_manager.update_operation_stats(
                    operation_id,
                    files_processed=1,
                    files_moved=1 if not info.error else 0,
                    errors=1 if info.error else 0
                )
            
            # Call external progress callback if provided
            if progress_callback:
                progress_callback(
                    info.current,
                    info.total,
                    info.current_file or "",
                    info.error
                )
        
        progress_tracker = ProgressTracker(callback=update_progress)
        progress_tracker.start(len(files))
        
        # Process files
        if settings.get("sort_by_type", False):
            # Move files sorted by type
            moved, errors, duplicates, history, created_folders = file_mover.move_files_sorted(
                files=files,
                destination=destination,
                dry_run=settings.get("dry_run", False),
                progress_callback=lambda c, t, f, e=None: progress_tracker.update(c, f, e)
            )
            move_results = {
                "moved": moved,
                "errors": errors,
                "duplicates": duplicates,
                "history": history,
                "created_folders": created_folders
            }
        else:
            # Move files flat
            moved, errors, duplicates, history = file_mover.move_files(
                files=files,
                destination=destination,
                dry_run=settings.get("dry_run", False),
                progress_callback=lambda c, t, f, e=None: progress_tracker.update(c, f, e)
            )
            move_results = {
                "moved": moved,
                "errors": errors,
                "duplicates": duplicates,
                "history": history,
                "created_folders": []
            }
        
        # Finish progress tracking
        progress_tracker.finish()
        
        # Update results
        results.update(move_results)
        
        # Save history if not dry run and files were moved
        if not settings.get("dry_run", False) and results["moved"] > 0:
            self.history_manager.save_history(destination, move_results["history"])
        
        # Check if aborted
        if abort_signal.is_set():
            results["aborted"] = True
        
        # Clean up empty directories if not dry run and not filtering by type
        if (not settings.get("dry_run", False) and 
            not settings.get("sort_by_type", False) and
            not settings.get("file_type_filter") and
            results["moved"] > 0):
            # Import the function we need
            from folder_extractor.utils.file_validators import get_temp_files_list
            
            # Remove empty directories
            removed_count = self._remove_empty_directories(destination, get_temp_files_list())
            results["removed_directories"] = removed_count
        
        return results
    
    def _remove_empty_directories(self, path: str, temp_files: list) -> int:
        """Remove empty directories after extraction.
        
        Args:
            path: Root path
            temp_files: List of temporary files to ignore
            
        Returns:
            Number of directories removed
        """
        removed_count = 0
        
        for root, dirs, files in os.walk(path, topdown=False):
            # Skip root directory
            if root == path:
                continue
            
            # Filter out temp files and hidden files if not included
            filtered_files = []
            for f in files:
                if f in temp_files:
                    continue
                if not settings.get("include_hidden", False) and f.startswith('.'):
                    continue
                filtered_files.append(f)
            
            # Check if directory is empty
            if not filtered_files and not dirs:
                try:
                    os.rmdir(root)
                    removed_count += 1
                except OSError:
                    pass
        
        return removed_count
    
    def undo_last_operation(self, path: str) -> Dict[str, Any]:
        """Undo the last operation.
        
        Args:
            path: Path where history is located
        
        Returns:
            Dictionary with undo results
        """
        # Load history
        history_data = self.history_manager.load_history(path)
        
        if not history_data or "operationen" not in history_data:
            return {
                "status": "no_history",
                "message": MESSAGES["UNDO_NO_HISTORY"],
                "restored": 0
            }
        
        # Get operations from history
        operations = history_data["operationen"]
        
        # Create operation for undo
        with ManagedOperation(self.state_manager, "undo") as op:
            restored = 0
            errors = 0
            
            # Create progress tracker
            progress_tracker = ProgressTracker()
            progress_tracker.start(len(operations))
            
            # Process history in reverse
            for i, entry in enumerate(reversed(operations)):
                if op.abort_signal.is_set():
                    break
                
                try:
                    # Undo the move
                    self.file_operations.move_file(
                        entry.get("neuer_pfad", entry.get("new_path")),
                        entry.get("original_pfad", entry.get("original_path"))
                    )
                    restored += 1
                    
                    # Update progress
                    original_path = entry.get("original_pfad", entry.get("original_path"))
                    progress_tracker.increment(original_path)
                    op.update_stats(files_processed=1, files_moved=1)
                    
                except Exception as e:
                    errors += 1
                    original_path = entry.get("original_pfad", entry.get("original_path"))
                    progress_tracker.increment(
                        original_path,
                        error=str(e)
                    )
                    op.update_stats(files_processed=1, errors=1)
            
            # Finish progress
            progress_tracker.finish()
            
            # Clear history after successful undo
            if restored > 0 and not op.abort_signal.is_set():
                self.history_manager.delete_history(path)
            
            return {
                "status": "success" if restored > 0 else "failed",
                "message": MESSAGES["UNDO_SUMMARY"].format(count=restored),
                "restored": restored,
                "errors": errors,
                "aborted": op.abort_signal.is_set()
            }


class EnhancedExtractionOrchestrator:
    """Orchestrates the complete extraction workflow with state management."""
    
    def __init__(self, extractor: IEnhancedExtractor,
                 state_manager: Optional[IStateManager] = None):
        """Initialize orchestrator.
        
        Args:
            extractor: Extractor implementation
            state_manager: State manager implementation
        """
        self.extractor = extractor
        self.state_manager = state_manager or get_state_manager()
    
    def execute_extraction(self, source_path: str,
                         confirmation_callback: Optional[Callable[[int], bool]] = None,
                         progress_callback: Optional[Callable[[int, int, str, Optional[str]], None]] = None) -> Dict[str, Any]:
        """Execute complete extraction workflow.
        
        Args:
            source_path: Source directory path
            confirmation_callback: Optional callback for user confirmation
            progress_callback: Optional callback for progress updates
        
        Returns:
            Dictionary with operation results
        """
        # Start operation
        with ManagedOperation(self.state_manager, "extraction") as op:
            try:
                # Validate security
                self.extractor.validate_security(source_path)
                
                # Discover files
                files = self.extractor.discover_files(source_path)
                
                if not files:
                    return {
                        "status": "no_files",
                        "message": MESSAGES["NO_FILES_FOUND"],
                        "files_found": 0
                    }
                
                # Get confirmation if callback provided
                if confirmation_callback and not settings.get("dry_run", False):
                    if not confirmation_callback(len(files)):
                        return {
                            "status": "cancelled",
                            "message": MESSAGES["OPERATION_CANCELLED"],
                            "files_found": len(files)
                        }
                
                # Note: Progress tracking is handled directly in extract_files
                # via the progress tracker callback, not through state manager listeners
                
                # Extract files
                results = self.extractor.extract_files(
                    files, source_path, op.operation_id, progress_callback
                )
                
                # Add metadata
                results["status"] = "success"
                results["files_found"] = len(files)
                results["operation_id"] = op.operation_id
                
                # Get final stats
                stats = self.state_manager.get_operation_stats(op.operation_id)
                if stats:
                    results["duration"] = stats.duration
                    results["success_rate"] = stats.success_rate
                
                return results
                
            except SecurityError as e:
                return {
                    "status": "security_error",
                    "message": str(e),
                    "error": True
                }
            
            except Exception as e:
                return {
                    "status": "error",
                    "message": f"Fehler: {str(e)}",
                    "error": True
                }
    
    def execute_undo(self, path: str) -> Dict[str, Any]:
        """Execute undo operation.
        
        Args:
            path: Path where history is located
        
        Returns:
            Dictionary with undo results
        """
        return self.extractor.undo_last_operation(path)
</file>

<file path="folder_extractor/core/extractor.py">
"""
Core extractor module.

Coordinates file discovery, filtering, and moving operations.
"""
import os
import threading
from typing import List, Tuple, Optional, Dict, Any, Callable
from abc import ABC, abstractmethod

from folder_extractor.core.file_discovery import IFileDiscovery, FileDiscovery
from folder_extractor.core.file_operations import (
    IFileOperations, FileOperations, FileMover, HistoryManager
)
from folder_extractor.config.settings import settings
from folder_extractor.utils.path_validators import is_safe_path
from folder_extractor.config.constants import MESSAGES


class ExtractionError(Exception):
    """Base exception for extraction errors."""
    pass


class SecurityError(ExtractionError):
    """Raised when security validation fails."""
    pass


class IExtractor(ABC):
    """Interface for file extraction operations."""
    
    @abstractmethod
    def validate_security(self, path: str) -> None:
        """Validate that the path is safe for operations."""
        pass
    
    @abstractmethod
    def discover_files(self, path: str) -> List[str]:
        """Discover files based on current settings."""
        pass
    
    @abstractmethod
    def extract_files(self, files: List[str], destination: str,
                     progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
        """Extract files to destination."""
        pass
    
    @abstractmethod
    def undo_last_operation(self, path: str) -> int:
        """Undo the last extraction operation."""
        pass


class FileExtractor(IExtractor):
    """Main file extractor implementation."""
    
    def __init__(self, 
                 file_discovery: Optional[IFileDiscovery] = None,
                 file_operations: Optional[IFileOperations] = None,
                 abort_signal: Optional[threading.Event] = None):
        """
        Initialize file extractor.
        
        Args:
            file_discovery: File discovery implementation
            file_operations: File operations implementation
            abort_signal: Threading event for operation abort
        """
        self.abort_signal = abort_signal or threading.Event()
        self.file_discovery = file_discovery or FileDiscovery(self.abort_signal)
        self.file_operations = file_operations or FileOperations(self.abort_signal)
        self.file_mover = FileMover(self.file_operations, self.abort_signal)
    
    def validate_security(self, path: str) -> None:
        """
        Validate that the path is safe for operations.
        
        Args:
            path: Path to validate
        
        Raises:
            SecurityError: If path is not safe
        """
        if not is_safe_path(path):
            raise SecurityError(
                MESSAGES["SECURITY_ERROR"].format(path=path)
            )
    
    def discover_files(self, path: str) -> List[str]:
        """
        Discover files based on current settings.
        
        Args:
            path: Root path to search
        
        Returns:
            List of discovered file paths
        """
        return self.file_discovery.find_files(
            directory=path,
            max_depth=settings.max_depth,
            file_type_filter=settings.file_type_filter,
            include_hidden=settings.include_hidden
        )
    
    def filter_by_domain(self, files: List[str], domains: List[str]) -> List[str]:
        """
        Filter weblink files by domain.
        
        Args:
            files: List of file paths
            domains: Allowed domains
        
        Returns:
            Filtered list of files
        """
        if not domains:
            return files
        
        filtered = []
        for filepath in files:
            # Check if it's a weblink file
            if filepath.endswith(('.url', '.webloc')):
                if self.file_discovery.check_weblink_domain(filepath, domains):
                    filtered.append(filepath)
            else:
                # Non-weblink files are included
                filtered.append(filepath)
        
        return filtered
    
    def extract_files(self, files: List[str], destination: str,
                     progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
        """
        Extract files to destination.
        
        Args:
            files: List of files to extract
            destination: Destination directory
            progress_callback: Optional progress callback
        
        Returns:
            Dictionary with extraction results
        """
        # Apply domain filter if set
        if settings.domain_filter:
            files = self.filter_by_domain(files, settings.domain_filter)
        
        # Determine extraction method
        if settings.sort_by_type:
            moved, errors, duplicates, history, created_folders = \
                self.file_mover.move_files_sorted(
                    files, destination, 
                    dry_run=settings.dry_run,
                    progress_callback=progress_callback
                )
            
            result = {
                "moved": moved,
                "errors": errors,
                "duplicates": duplicates,
                "history": history,
                "created_folders": created_folders
            }
        else:
            moved, errors, duplicates, history = \
                self.file_mover.move_files(
                    files, destination,
                    dry_run=settings.dry_run,
                    progress_callback=progress_callback
                )
            
            result = {
                "moved": moved,
                "errors": errors,
                "duplicates": duplicates,
                "history": history,
                "created_folders": []
            }
        
        # Save history if not dry run
        if not settings.dry_run and history:
            HistoryManager.save_history(history, destination)
        
        # Clean up empty directories if enabled
        if not settings.dry_run and not settings.file_type_filter:
            removed = self.file_operations.remove_empty_directories(
                destination, settings.include_hidden
            )
            result["removed_directories"] = removed
        else:
            result["removed_directories"] = 0
        
        return result
    
    def undo_last_operation(self, path: str) -> int:
        """
        Undo the last extraction operation.
        
        Args:
            path: Path where history file is located
        
        Returns:
            Number of files restored
        """
        # Load history
        history_data = HistoryManager.load_history(path)
        if not history_data or "operationen" not in history_data:
            return 0
        
        restored = 0
        operations = history_data["operationen"]
        
        # Restore files in reverse order
        for operation in reversed(operations):
            if self.abort_signal.is_set():
                break
            
            try:
                # Move file back to original location
                if os.path.exists(operation["neuer_pfad"]):
                    # Ensure original directory exists
                    os.makedirs(
                        os.path.dirname(operation["original_pfad"]), 
                        exist_ok=True
                    )
                    
                    # Move file back
                    self.file_operations.move_file(
                        operation["neuer_pfad"],
                        operation["original_pfad"]
                    )
                    restored += 1
            except Exception:
                # Continue with other files even if one fails
                pass
        
        # Delete history after successful undo
        if restored > 0:
            HistoryManager.delete_history(path)
        
        return restored


class ExtractionOrchestrator:
    """Orchestrates the complete extraction workflow."""
    
    def __init__(self, extractor: IExtractor):
        """
        Initialize orchestrator.
        
        Args:
            extractor: Extractor implementation
        """
        self.extractor = extractor
    
    def execute_extraction(self, 
                          source_path: str,
                          confirmation_callback: Optional[Callable] = None,
                          progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
        """
        Execute complete extraction workflow.
        
        Args:
            source_path: Source directory path
            confirmation_callback: Callback for user confirmation
            progress_callback: Callback for progress updates
        
        Returns:
            Extraction results
        
        Raises:
            ExtractionError: If extraction fails
        """
        # Validate security
        self.extractor.validate_security(source_path)
        
        # Discover files
        files = self.extractor.discover_files(source_path)
        
        if not files:
            return {
                "status": "no_files",
                "message": MESSAGES["NO_FILES_FOUND"]
            }
        
        # Get confirmation if callback provided
        if confirmation_callback and not settings.dry_run:
            if not confirmation_callback(len(files)):
                return {
                    "status": "cancelled",
                    "message": MESSAGES["OPERATION_CANCELLED"]
                }
        
        # Extract files
        result = self.extractor.extract_files(
            files, source_path, progress_callback
        )
        
        result["status"] = "success"
        result["total_files"] = len(files)
        
        return result
    
    def execute_undo(self, path: str) -> Dict[str, Any]:
        """
        Execute undo operation.
        
        Args:
            path: Path where history is located
        
        Returns:
            Undo results
        """
        # Validate security
        self.extractor.validate_security(path)
        
        # Perform undo
        restored = self.extractor.undo_last_operation(path)
        
        if restored == 0:
            return {
                "status": "no_history",
                "message": MESSAGES["UNDO_NO_HISTORY"],
                "restored": 0
            }
        
        return {
            "status": "success",
            "message": MESSAGES["UNDO_SUMMARY"].format(count=restored),
            "restored": restored
        }
</file>

<file path="folder_extractor/core/file_discovery.py">
"""
File discovery module.

Handles finding files in directories with various filtering options.
"""
import os
from pathlib import Path
from typing import List, Optional, Set
from abc import ABC, abstractmethod
from urllib.parse import urlparse
import xml.etree.ElementTree as ET

from folder_extractor.utils.file_validators import (
    should_include_file,
    validate_file_extension,
    is_hidden_file
)
from folder_extractor.config.constants import HIDDEN_FILE_PREFIX


class IFileDiscovery(ABC):
    """Interface for file discovery operations."""
    
    @abstractmethod
    def find_files(self, directory: str, max_depth: int = 0,
                  file_type_filter: Optional[List[str]] = None,
                  include_hidden: bool = False) -> List[str]:
        """Find files in directory with given criteria."""
        pass
    
    @abstractmethod
    def check_weblink_domain(self, filepath: str, allowed_domains: List[str]) -> bool:
        """Check if a weblink file matches allowed domains."""
        pass


class FileDiscovery(IFileDiscovery):
    """Implementation of file discovery operations."""
    
    def __init__(self, abort_signal=None):
        """
        Initialize file discovery.
        
        Args:
            abort_signal: Threading event to signal operation abort
        """
        self.abort_signal = abort_signal
    
    def find_files(self, directory: str, max_depth: int = 0,
                  file_type_filter: Optional[List[str]] = None,
                  include_hidden: bool = False) -> List[str]:
        """
        Find all files in directory and subdirectories.
        
        Args:
            directory: Root directory to search
            max_depth: Maximum depth to search (0 = unlimited)
            file_type_filter: List of allowed file extensions
            include_hidden: Whether to include hidden files
        
        Returns:
            List of file paths found
        """
        found_files = []
        
        # Walk through directory
        for root, dirs, files in os.walk(directory):
            # Check abort signal
            if self.abort_signal and self.abort_signal.is_set():
                break
            
            # Calculate current depth
            depth = self._calculate_depth(directory, root)
            
            # Check depth limit
            if max_depth > 0 and depth > max_depth:
                continue  # Skip this directory entirely
            
            # If we're at max depth, don't go deeper
            if max_depth > 0 and depth == max_depth:
                dirs.clear()  # Don't go deeper but process files here
            
            # Filter directories if not including hidden
            if not include_hidden:
                # Remove hidden directories from dirs list (modifies in-place)
                dirs[:] = [d for d in dirs if not d.startswith(HIDDEN_FILE_PREFIX)]
            
            # Note: Original behavior skips root directory files
            # but we process them to match the test expectations
            # In real usage, users typically want files from subdirectories only
            if depth == 0:
                # Skip root directory to maintain original behavior
                continue
            
            # Process files in this directory
            for filename in files:
                filepath = os.path.join(root, filename)
                
                # Check if file should be included
                if not should_include_file(filepath, include_hidden):
                    continue
                
                # Check file type filter
                if not validate_file_extension(filepath, file_type_filter):
                    continue
                
                found_files.append(filepath)
        
        return found_files
    
    def check_weblink_domain(self, filepath: str, allowed_domains: List[str]) -> bool:
        """
        Check if a weblink file (.url or .webloc) is from an allowed domain.
        
        Args:
            filepath: Path to the weblink file
            allowed_domains: List of allowed domains
        
        Returns:
            True if the file is from an allowed domain
        """
        if not os.path.exists(filepath):
            return False
        
        try:
            # Determine file type
            if filepath.endswith('.url'):
                return self._check_url_file(filepath, allowed_domains)
            elif filepath.endswith('.webloc'):
                return self._check_webloc_file(filepath, allowed_domains)
            else:
                return False
        except Exception:
            return False
    
    def _calculate_depth(self, base_dir: str, current_dir: str) -> int:
        """
        Calculate the depth of current directory relative to base.
        
        Args:
            base_dir: Base directory
            current_dir: Current directory
        
        Returns:
            Depth level (0 = base directory)
        """
        base_path = os.path.abspath(base_dir)
        current_path = os.path.abspath(current_dir)
        
        # Get relative path
        try:
            rel_path = os.path.relpath(current_path, base_path)
            if rel_path == '.':
                return 0
            return len(rel_path.split(os.sep))
        except ValueError:
            # Paths are on different drives
            return 0
    
    def _check_url_file(self, filepath: str, allowed_domains: List[str]) -> bool:
        """
        Check Windows .url file for allowed domains.
        
        Args:
            filepath: Path to .url file
            allowed_domains: List of allowed domains
        
        Returns:
            True if URL is from allowed domain
        """
        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
        
        # Extract URL from .url file
        for line in content.splitlines():
            if line.startswith('URL='):
                url = line[4:].strip()
                return self._check_url_domain(url, allowed_domains)
        
        return False
    
    def _check_webloc_file(self, filepath: str, allowed_domains: List[str]) -> bool:
        """
        Check macOS .webloc file for allowed domains.
        
        Args:
            filepath: Path to .webloc file
            allowed_domains: List of allowed domains
        
        Returns:
            True if URL is from allowed domain
        """
        try:
            # Parse XML plist
            tree = ET.parse(filepath)
            root = tree.getroot()
            
            # Find URL in plist
            for dict_elem in root.findall('.//dict'):
                keys = dict_elem.findall('key')
                for i, key in enumerate(keys):
                    if key.text == 'URL':
                        # Next element should be the string with URL
                        string_elem = dict_elem.find(f'string[{i+1}]')
                        if string_elem is None:
                            # Try alternative structure
                            strings = dict_elem.findall('string')
                            if i < len(strings):
                                url = strings[i].text
                                return self._check_url_domain(url, allowed_domains)
                        else:
                            url = string_elem.text
                            return self._check_url_domain(url, allowed_domains)
        except Exception:
            pass
        
        return False
    
    def _check_url_domain(self, url: str, allowed_domains: List[str]) -> bool:
        """
        Check if URL domain is in allowed list.
        
        Args:
            url: URL to check
            allowed_domains: List of allowed domains
        
        Returns:
            True if domain is allowed
        """
        try:
            parsed = urlparse(url)
            domain = parsed.netloc.lower()
            
            # Remove www prefix
            if domain.startswith('www.'):
                domain = domain[4:]
            
            return domain in allowed_domains
        except Exception:
            return False


class FileFilter:
    """Advanced file filtering capabilities."""
    
    def __init__(self):
        """Initialize file filter."""
        self._filters = []
    
    def add_extension_filter(self, extensions: List[str]):
        """Add file extension filter."""
        def filter_func(filepath: str) -> bool:
            return validate_file_extension(filepath, extensions)
        self._filters.append(filter_func)
    
    def add_size_filter(self, min_size: Optional[int] = None, 
                       max_size: Optional[int] = None):
        """Add file size filter."""
        def filter_func(filepath: str) -> bool:
            try:
                size = os.path.getsize(filepath)
                if min_size is not None and size < min_size:
                    return False
                if max_size is not None and size > max_size:
                    return False
                return True
            except OSError:
                return False
        self._filters.append(filter_func)
    
    def add_name_pattern_filter(self, pattern: str):
        """Add filename pattern filter (simple wildcard)."""
        import fnmatch
        def filter_func(filepath: str) -> bool:
            filename = os.path.basename(filepath)
            return fnmatch.fnmatch(filename, pattern)
        self._filters.append(filter_func)
    
    def apply(self, filepath: str) -> bool:
        """Apply all filters to a file."""
        return all(f(filepath) for f in self._filters)
</file>

<file path="folder_extractor/core/file_operations.py">
"""
File operations module.

Handles all file system operations including moving files,
generating unique names, and managing directories.
"""
import os
import shutil
import json
from pathlib import Path
from datetime import datetime
from typing import List, Tuple, Dict, Optional, Any
from abc import ABC, abstractmethod

from folder_extractor.config.constants import (
    NO_EXTENSION_FOLDER,
    FILE_TYPE_FOLDERS,
    HISTORY_FILE_NAME
)
from folder_extractor.utils.terminal import Color


class FileOperationError(Exception):
    """Base exception for file operation errors."""
    pass


class IFileOperations(ABC):
    """Interface for file operations."""
    
    @abstractmethod
    def move_file(self, source: str, destination: str, dry_run: bool = False) -> bool:
        """Move a single file."""
        pass
    
    @abstractmethod
    def generate_unique_name(self, directory: str, filename: str) -> str:
        """Generate a unique filename in the given directory."""
        pass
    
    @abstractmethod
    def remove_empty_directories(self, path: str, include_hidden: bool = False) -> int:
        """Remove empty directories recursively."""
        pass
    
    @abstractmethod
    def determine_type_folder(self, filename: str) -> str:
        """Determine the folder name for a file type."""
        pass


class FileOperations(IFileOperations):
    """Implementation of file operations."""
    
    def __init__(self, abort_signal=None):
        """Initialize file operations.
        
        Args:
            abort_signal: Threading event to signal operation abort
        """
        self.abort_signal = abort_signal
    
    def move_file(self, source: str, destination: str, dry_run: bool = False) -> bool:
        """
        Move a single file from source to destination.
        
        Args:
            source: Source file path
            destination: Destination file path
            dry_run: If True, don't actually move the file
        
        Returns:
            True if successful, False otherwise
        
        Raises:
            FileOperationError: If the move operation fails
        """
        if dry_run:
            return True
        
        try:
            # Try to move using rename (fastest)
            os.rename(source, destination)
            return True
        except OSError:
            # Fall back to copy and delete (works across filesystems)
            try:
                shutil.copy2(source, destination)
                os.remove(source)
                return True
            except Exception as e:
                raise FileOperationError(f"Failed to move file: {str(e)}")
    
    def generate_unique_name(self, directory: str, filename: str) -> str:
        """
        Generate a unique filename in the given directory.
        
        If a file with the given name already exists, appends _1, _2, etc.
        
        Args:
            directory: Directory to check for existing files
            filename: Original filename
        
        Returns:
            Unique filename that doesn't exist in the directory
        """
        if not os.path.exists(os.path.join(directory, filename)):
            return filename
        
        # Split name and extension
        name_parts = filename.rsplit('.', 1)
        if len(name_parts) == 2:
            base_name, extension = name_parts
            extension = '.' + extension
        else:
            base_name = filename
            extension = ''
        
        # Find unique name
        counter = 1
        while True:
            new_name = f"{base_name}_{counter}{extension}"
            if not os.path.exists(os.path.join(directory, new_name)):
                return new_name
            counter += 1
    
    def remove_empty_directories(self, path: str, include_hidden: bool = False) -> int:
        """
        Remove empty directories recursively.
        
        Args:
            path: Root path to start from
            include_hidden: Whether to consider hidden files
        
        Returns:
            Number of directories removed
        """
        removed_count = 0
        
        for root, dirs, files in os.walk(path, topdown=False):
            # Skip the root directory itself
            if root == path:
                continue
            
            # Check if directory is empty
            try:
                dir_content = os.listdir(root)
                
                # If not including hidden files, filter them out
                if not include_hidden:
                    dir_content = [item for item in dir_content 
                                 if not item.startswith('.')]
                
                # If directory is empty (or only has hidden files), remove it
                if not dir_content:
                    # Remove hidden files if not including them
                    if not include_hidden:
                        for item in os.listdir(root):
                            if item.startswith('.'):
                                item_path = os.path.join(root, item)
                                if os.path.isfile(item_path):
                                    os.remove(item_path)
                                elif os.path.isdir(item_path):
                                    shutil.rmtree(item_path)
                    
                    os.rmdir(root)
                    removed_count += 1
            except (OSError, PermissionError):
                # Skip directories we can't access
                pass
        
        return removed_count
    
    def determine_type_folder(self, filename: str) -> str:
        """
        Determine the folder name for a file based on its type.
        
        Args:
            filename: Name of the file
        
        Returns:
            Folder name for the file type
        """
        # Get file extension
        _, ext = os.path.splitext(filename.lower())
        
        # Look up in mapping
        if ext in FILE_TYPE_FOLDERS:
            return FILE_TYPE_FOLDERS[ext]
        elif ext:
            # Unknown extension - use uppercase extension without dot
            return ext[1:].upper()
        else:
            # No extension
            return NO_EXTENSION_FOLDER


class HistoryManager:
    """Manages operation history for undo functionality."""
    
    @staticmethod
    def save_history(operations: List[Dict[str, Any]], directory: str) -> str:
        """
        Save operation history to file.
        
        Args:
            operations: List of operation records
            directory: Directory to save history file
        
        Returns:
            Path to the history file
        """
        history_file = os.path.join(directory, HISTORY_FILE_NAME)
        
        history_data = {
            "zeitstempel": datetime.now().isoformat(),
            "version": "1.0",
            "operationen": operations
        }
        
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(history_data, f, indent=2, ensure_ascii=False)
        
        return history_file
    
    @staticmethod
    def load_history(directory: str) -> Optional[Dict[str, Any]]:
        """
        Load operation history from file.
        
        Args:
            directory: Directory containing history file
        
        Returns:
            History data or None if not found
        """
        history_file = os.path.join(directory, HISTORY_FILE_NAME)
        
        if not os.path.exists(history_file):
            return None
        
        try:
            with open(history_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (json.JSONDecodeError, IOError):
            return None
    
    @staticmethod
    def delete_history(directory: str) -> bool:
        """
        Delete history file.
        
        Args:
            directory: Directory containing history file
        
        Returns:
            True if deleted, False if not found
        """
        history_file = os.path.join(directory, HISTORY_FILE_NAME)
        
        if os.path.exists(history_file):
            os.remove(history_file)
            return True
        
        return False


class FileMover:
    """High-level file moving operations."""
    
    def __init__(self, file_ops: IFileOperations, abort_signal=None):
        """
        Initialize file mover.
        
        Args:
            file_ops: File operations implementation
            abort_signal: Threading event to signal abort
        """
        self.file_ops = file_ops
        self.abort_signal = abort_signal
    
    def move_files(self, files: List[str], destination: str, 
                   dry_run: bool = False,
                   progress_callback=None) -> Tuple[int, int, int, List[Dict]]:
        """
        Move multiple files to destination.
        
        Args:
            files: List of file paths to move
            destination: Destination directory
            dry_run: If True, simulate the operation
            progress_callback: Optional callback for progress updates
        
        Returns:
            Tuple of (moved_count, error_count, duplicate_count, history)
        """
        moved = 0
        errors = 0
        duplicates = 0
        history = []
        
        for i, file_path in enumerate(files):
            # Check abort signal
            if self.abort_signal and self.abort_signal.is_set():
                break
            
            # Progress callback
            if progress_callback:
                progress_callback(i + 1, len(files), file_path)
            
            try:
                filename = os.path.basename(file_path)
                
                # Generate unique name if needed
                unique_name = self.file_ops.generate_unique_name(destination, filename)
                if unique_name != filename:
                    duplicates += 1
                
                dest_path = os.path.join(destination, unique_name)
                
                # Move file
                if self.file_ops.move_file(file_path, dest_path, dry_run):
                    moved += 1
                    
                    # Record in history
                    if not dry_run:
                        history.append({
                            "original_pfad": file_path,
                            "neuer_pfad": dest_path,
                            "original_name": filename,
                            "neuer_name": unique_name,
                            "zeitstempel": datetime.now().isoformat()
                        })
                
            except Exception as e:
                errors += 1
                if progress_callback:
                    progress_callback(i + 1, len(files), file_path, error=str(e))
        
        return moved, errors, duplicates, history
    
    def move_files_sorted(self, files: List[str], destination: str,
                         dry_run: bool = False,
                         progress_callback=None) -> Tuple[int, int, int, List[Dict], List[str]]:
        """
        Move files sorted by type into subdirectories.
        
        Args:
            files: List of file paths to move
            destination: Destination directory
            dry_run: If True, simulate the operation
            progress_callback: Optional callback for progress updates
        
        Returns:
            Tuple of (moved_count, error_count, duplicate_count, history, created_folders)
        """
        moved = 0
        errors = 0
        duplicates = 0
        history = []
        created_folders = set()
        
        for i, file_path in enumerate(files):
            # Check abort signal
            if self.abort_signal and self.abort_signal.is_set():
                break
            
            # Progress callback
            if progress_callback:
                progress_callback(i + 1, len(files), file_path)
            
            try:
                filename = os.path.basename(file_path)
                
                # Determine type folder
                type_folder = self.file_ops.determine_type_folder(filename)
                type_path = os.path.join(destination, type_folder)
                
                # Create type folder if needed
                if not os.path.exists(type_path) and not dry_run:
                    os.makedirs(type_path, exist_ok=True)
                    created_folders.add(type_folder)
                
                # Generate unique name
                unique_name = self.file_ops.generate_unique_name(type_path, filename)
                if unique_name != filename:
                    duplicates += 1
                
                dest_path = os.path.join(type_path, unique_name)
                
                # Move file
                if self.file_ops.move_file(file_path, dest_path, dry_run):
                    moved += 1
                    
                    # Record in history
                    if not dry_run:
                        history.append({
                            "original_pfad": file_path,
                            "neuer_pfad": dest_path,
                            "original_name": filename,
                            "neuer_name": unique_name,
                            "zeitstempel": datetime.now().isoformat()
                        })
                
            except Exception as e:
                errors += 1
                if progress_callback:
                    progress_callback(i + 1, len(files), file_path, error=str(e))
        
        return moved, errors, duplicates, history, list(created_folders)
</file>

<file path="folder_extractor/core/migration.py">
"""
Migration utilities for transitioning to new architecture.

Provides adapters and utilities to ensure backward compatibility
while transitioning to the new modular architecture.
"""
import threading
from typing import Optional, Dict, Any, Callable

from folder_extractor.core.state import (
    IApplicationState, ApplicationState, OperationContext
)
from folder_extractor.core.state_manager import (
    IStateManager, StateManager, get_state_manager
)
from folder_extractor.core.extractor import IExtractor, FileExtractor
from folder_extractor.core.extractor_v2 import (
    IEnhancedExtractor, EnhancedFileExtractor
)


class StateAdapter(IApplicationState):
    """Adapter to make new StateManager compatible with old IApplicationState."""
    
    def __init__(self, state_manager: Optional[IStateManager] = None):
        """Initialize adapter.
        
        Args:
            state_manager: State manager to adapt
        """
        self.state_manager = state_manager or get_state_manager()
    
    def get_abort_signal(self) -> threading.Event:
        """Get the abort signal event."""
        return self.state_manager.get_abort_signal()
    
    def request_abort(self) -> None:
        """Request operation abort."""
        self.state_manager.request_abort()
    
    def clear_abort(self) -> None:
        """Clear abort request."""
        self.state_manager.clear_abort()
    
    def is_abort_requested(self) -> bool:
        """Check if abort was requested."""
        return self.state_manager.is_abort_requested()


class ExtractorAdapter(IExtractor):
    """Adapter to make new EnhancedExtractor compatible with old IExtractor."""
    
    def __init__(self, enhanced_extractor: Optional[IEnhancedExtractor] = None,
                 state_manager: Optional[IStateManager] = None):
        """Initialize adapter.
        
        Args:
            enhanced_extractor: Enhanced extractor to adapt
            state_manager: State manager for operation tracking
        """
        self.enhanced_extractor = enhanced_extractor or EnhancedFileExtractor()
        self.state_manager = state_manager or get_state_manager()
        self._abort_signal: Optional[threading.Event] = None
    
    def validate_security(self, path: str) -> None:
        """Validate that the path is safe for operations."""
        self.enhanced_extractor.validate_security(path)
    
    def discover_files(self, path: str) -> list[str]:
        """Discover files based on current settings."""
        return self.enhanced_extractor.discover_files(path)
    
    def extract_files(self, files: list[str], destination: str,
                     progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
        """Extract files to destination."""
        # Start an operation for tracking
        op_id = self.state_manager.start_operation("extraction")
        
        try:
            # If progress callback provided, wrap it
            if progress_callback:
                def wrapped_callback(current, total, filepath, error):
                    # Update state manager
                    self.state_manager.set_value("current_file", filepath)
                    if error:
                        self.state_manager.set_value("last_error", error)
                    
                    # Call original callback
                    progress_callback(current, total, filepath, error)
                
                # Use wrapped callback by setting up listener
                self.state_manager.add_listener("state_changed", 
                    lambda **kwargs: wrapped_callback(
                        self.state_manager.get_operation_stats(op_id).files_processed,
                        len(files),
                        kwargs.get('new_value') if kwargs.get('key') == 'current_file' else "",
                        kwargs.get('new_value') if kwargs.get('key') == 'last_error' else None
                    )
                )
            
            # Execute extraction
            results = self.enhanced_extractor.extract_files(
                files, destination, op_id
            )
            
            return results
            
        finally:
            # End operation
            self.state_manager.end_operation(op_id)
    
    def undo_last_operation(self, path: str) -> int:
        """Undo the last operation."""
        results = self.enhanced_extractor.undo_last_operation(path)
        return results.get("restored", 0)
    
    def set_abort_signal(self, signal: threading.Event) -> None:
        """Set abort signal (for compatibility)."""
        self._abort_signal = signal
        # Note: The new implementation uses state manager's abort signal


class MigrationHelper:
    """Helper class for migrating to new architecture."""
    
    @staticmethod
    def create_compatible_extractor(abort_signal: Optional[threading.Event] = None) -> FileExtractor:
        """Create a FileExtractor that uses new implementation internally.
        
        Args:
            abort_signal: Optional abort signal for compatibility
        
        Returns:
            FileExtractor instance using new implementation
        """
        # Create new enhanced extractor
        enhanced = EnhancedFileExtractor()
        
        # Wrap in adapter
        adapter = ExtractorAdapter(enhanced)
        
        # Create old-style extractor with adapter
        from folder_extractor.core.file_discovery import FileDiscovery
        from folder_extractor.core.file_operations import FileOperations
        
        # Return FileExtractor that will use our adapter
        # Note: This requires modifying FileExtractor to accept IExtractor
        # For now, return the adapter cast as FileExtractor
        return adapter  # type: ignore
    
    @staticmethod
    def migrate_settings() -> None:
        """Migrate settings to new state manager."""
        state_manager = get_state_manager()
        
        # Copy relevant settings to state manager
        from folder_extractor.config.settings import settings
        
        state_values = {
            "dry_run": settings.get("dry_run", False),
            "max_depth": settings.get("max_depth", 0),
            "include_hidden": settings.get("include_hidden", False),
            "sort_by_type": settings.get("sort_by_type", False),
            "file_type_filter": settings.get("file_type_filter"),
            "domain_filter": settings.get("domain_filter"),
        }
        
        state_manager.update_values(state_values)
    
    @staticmethod
    def create_operation_context() -> OperationContext:
        """Create an OperationContext using new state manager.
        
        Returns:
            OperationContext with state adapter
        """
        state_adapter = StateAdapter()
        return OperationContext(state_adapter)
</file>

<file path="folder_extractor/core/progress.py">
"""
Progress tracking and reporting.

Provides progress tracking capabilities with callbacks
and integration with state management.
"""
import time
from typing import Optional, Callable, Any, Dict
from dataclasses import dataclass
from abc import ABC, abstractmethod


@dataclass
class ProgressInfo:
    """Information about current progress."""
    current: int
    total: int
    current_file: Optional[str] = None
    error: Optional[str] = None
    
    @property
    def percentage(self) -> float:
        """Calculate progress percentage."""
        if self.total == 0:
            return 100.0
        return (self.current / self.total) * 100.0
    
    @property
    def is_complete(self) -> bool:
        """Check if operation is complete."""
        return self.current >= self.total


class IProgressTracker(ABC):
    """Interface for progress tracking."""
    
    @abstractmethod
    def start(self, total: int) -> None:
        """Start tracking progress."""
        pass
    
    @abstractmethod
    def update(self, current: int, current_file: Optional[str] = None,
              error: Optional[str] = None) -> None:
        """Update progress."""
        pass
    
    @abstractmethod
    def increment(self, current_file: Optional[str] = None,
                 error: Optional[str] = None) -> None:
        """Increment progress by one."""
        pass
    
    @abstractmethod
    def finish(self) -> None:
        """Finish tracking."""
        pass
    
    @abstractmethod
    def get_info(self) -> ProgressInfo:
        """Get current progress information."""
        pass


class ProgressTracker(IProgressTracker):
    """Progress tracker with callback support."""
    
    def __init__(self, callback: Optional[Callable[[ProgressInfo], None]] = None,
                 update_interval: float = 0.1):
        """Initialize progress tracker.
        
        Args:
            callback: Optional callback for progress updates
            update_interval: Minimum interval between callbacks (seconds)
        """
        self.callback = callback
        self.update_interval = update_interval
        self._current = 0
        self._total = 0
        self._current_file: Optional[str] = None
        self._last_error: Optional[str] = None
        self._last_update_time = 0.0
        self._start_time: Optional[float] = None
        self._end_time: Optional[float] = None
    
    def start(self, total: int) -> None:
        """Start tracking progress."""
        self._current = 0
        self._total = total
        self._current_file = None
        self._last_error = None
        self._start_time = time.time()
        self._end_time = None
        self._last_update_time = 0.0
        
        # Initial callback
        self._notify_progress()
    
    def update(self, current: int, current_file: Optional[str] = None,
              error: Optional[str] = None) -> None:
        """Update progress."""
        self._current = min(current, self._total)
        self._current_file = current_file
        self._last_error = error
        
        # Check if we should notify
        current_time = time.time()
        if (current_time - self._last_update_time) >= self.update_interval:
            self._notify_progress()
            self._last_update_time = current_time
    
    def increment(self, current_file: Optional[str] = None,
                 error: Optional[str] = None) -> None:
        """Increment progress by one."""
        self.update(self._current + 1, current_file, error)
    
    def finish(self) -> None:
        """Finish tracking."""
        self._end_time = time.time()
        self._current = self._total
        self._notify_progress()  # Always notify on finish
    
    def get_info(self) -> ProgressInfo:
        """Get current progress information."""
        return ProgressInfo(
            current=self._current,
            total=self._total,
            current_file=self._current_file,
            error=self._last_error
        )
    
    def _notify_progress(self) -> None:
        """Notify callback of progress update."""
        if self.callback:
            info = self.get_info()
            self.callback(info)
    
    @property
    def elapsed_time(self) -> float:
        """Get elapsed time in seconds."""
        if self._start_time is None:
            return 0.0
        
        if self._end_time is not None:
            return self._end_time - self._start_time
        
        return time.time() - self._start_time
    
    @property
    def estimated_remaining_time(self) -> Optional[float]:
        """Estimate remaining time in seconds."""
        if self._current == 0 or self._total == 0:
            return None
        
        elapsed = self.elapsed_time
        rate = self._current / elapsed if elapsed > 0 else 0
        
        if rate == 0:
            return None
        
        remaining_items = self._total - self._current
        return remaining_items / rate
    
    def get_statistics(self) -> Dict[str, Any]:
        """Get detailed statistics."""
        return {
            'current': self._current,
            'total': self._total,
            'percentage': self.get_info().percentage,
            'elapsed_time': self.elapsed_time,
            'estimated_remaining': self.estimated_remaining_time,
            'average_rate': self._current / self.elapsed_time if self.elapsed_time > 0 else 0,
            'has_errors': self._last_error is not None
        }


class BatchProgressTracker(ProgressTracker):
    """Progress tracker with batch processing support."""
    
    def __init__(self, callback: Optional[Callable[[ProgressInfo], None]] = None,
                 update_interval: float = 0.1, batch_size: int = 100):
        """Initialize batch progress tracker.
        
        Args:
            callback: Optional callback for progress updates
            update_interval: Minimum interval between callbacks
            batch_size: Size of each batch
        """
        super().__init__(callback, update_interval)
        self.batch_size = batch_size
        self._batch_start = 0
        self._batch_errors = 0
    
    def start_batch(self) -> None:
        """Start a new batch."""
        self._batch_start = self._current
        self._batch_errors = 0
    
    def end_batch(self) -> Dict[str, Any]:
        """End current batch and return statistics."""
        batch_items = self._current - self._batch_start
        return {
            'items_processed': batch_items,
            'errors': self._batch_errors,
            'success_rate': ((batch_items - self._batch_errors) / batch_items * 100)
                           if batch_items > 0 else 0
        }
    
    def increment(self, current_file: Optional[str] = None,
                 error: Optional[str] = None) -> None:
        """Increment progress by one."""
        if error:
            self._batch_errors += 1
        super().increment(current_file, error)


class CompositeProgressTracker(IProgressTracker):
    """Composite progress tracker that delegates to multiple trackers."""
    
    def __init__(self, trackers: list[IProgressTracker]):
        """Initialize composite tracker.
        
        Args:
            trackers: List of progress trackers
        """
        self.trackers = trackers
    
    def start(self, total: int) -> None:
        """Start tracking progress."""
        for tracker in self.trackers:
            tracker.start(total)
    
    def update(self, current: int, current_file: Optional[str] = None,
              error: Optional[str] = None) -> None:
        """Update progress."""
        for tracker in self.trackers:
            tracker.update(current, current_file, error)
    
    def increment(self, current_file: Optional[str] = None,
                 error: Optional[str] = None) -> None:
        """Increment progress by one."""
        for tracker in self.trackers:
            tracker.increment(current_file, error)
    
    def finish(self) -> None:
        """Finish tracking."""
        for tracker in self.trackers:
            tracker.finish()
    
    def get_info(self) -> ProgressInfo:
        """Get current progress information."""
        # Return info from first tracker
        if self.trackers:
            return self.trackers[0].get_info()
        return ProgressInfo(current=0, total=0)
</file>

<file path="folder_extractor/core/state_manager.py">
"""
Enhanced state management with operation tracking and statistics.

Provides centralized state management with thread-safety,
operation history, and performance metrics.
"""
import threading
import time
import json
from pathlib import Path
from typing import Optional, Any, Dict, List, Callable
from dataclasses import dataclass, asdict
from datetime import datetime
from abc import ABC, abstractmethod


@dataclass
class OperationStats:
    """Statistics for a single operation."""
    operation_type: str
    start_time: float
    end_time: Optional[float] = None
    files_processed: int = 0
    files_moved: int = 0
    files_skipped: int = 0
    errors: int = 0
    aborted: bool = False
    
    @property
    def duration(self) -> Optional[float]:
        """Calculate operation duration."""
        if self.end_time:
            return self.end_time - self.start_time
        return None
    
    @property
    def success_rate(self) -> float:
        """Calculate success rate."""
        if self.files_processed == 0:
            return 0.0
        return (self.files_moved / self.files_processed) * 100


class IStateManager(ABC):
    """Interface for state management."""
    
    @abstractmethod
    def start_operation(self, operation_type: str) -> str:
        """Start a new operation and return its ID."""
        pass
    
    @abstractmethod
    def end_operation(self, operation_id: str) -> None:
        """End an operation."""
        pass
    
    @abstractmethod
    def update_operation_stats(self, operation_id: str, **kwargs) -> None:
        """Update operation statistics."""
        pass
    
    @abstractmethod
    def get_operation_stats(self, operation_id: str) -> Optional[OperationStats]:
        """Get statistics for an operation."""
        pass
    
    @abstractmethod
    def get_current_operation_id(self) -> Optional[str]:
        """Get the current operation ID."""
        pass
    
    @abstractmethod
    def request_abort(self) -> None:
        """Request abort of current operation."""
        pass
    
    @abstractmethod
    def is_abort_requested(self) -> bool:
        """Check if abort was requested."""
        pass
    
    @abstractmethod
    def clear_abort(self) -> None:
        """Clear abort request."""
        pass


class StateManager(IStateManager):
    """Enhanced state manager with operation tracking."""
    
    def __init__(self):
        """Initialize state manager."""
        self._lock = threading.RLock()
        self._abort_signal = threading.Event()
        self._current_operation_id: Optional[str] = None
        self._operations: Dict[str, OperationStats] = {}
        self._state: Dict[str, Any] = {}
        self._listeners: Dict[str, List[Callable]] = {}
        self._operation_counter = 0
    
    def start_operation(self, operation_type: str) -> str:
        """Start a new operation and return its ID."""
        with self._lock:
            # Generate unique operation ID with counter
            self._operation_counter += 1
            operation_id = f"{operation_type}_{int(time.time() * 1000)}_{self._operation_counter}"
            
            # Create operation stats
            stats = OperationStats(
                operation_type=operation_type,
                start_time=time.time()
            )
            
            # Store operation
            self._operations[operation_id] = stats
            self._current_operation_id = operation_id
            
            # Clear abort signal
            self._abort_signal.clear()
            
            # Notify listeners
            self._notify_listeners('operation_started', operation_id=operation_id)
            
            return operation_id
    
    def end_operation(self, operation_id: str) -> None:
        """End an operation."""
        with self._lock:
            if operation_id in self._operations:
                stats = self._operations[operation_id]
                stats.end_time = time.time()
                stats.aborted = self._abort_signal.is_set()
                
                # Clear current operation if it matches
                if self._current_operation_id == operation_id:
                    self._current_operation_id = None
                
                # Notify listeners
                self._notify_listeners('operation_ended', 
                                     operation_id=operation_id,
                                     stats=stats)
    
    def update_operation_stats(self, operation_id: str, **kwargs) -> None:
        """Update operation statistics."""
        with self._lock:
            if operation_id in self._operations:
                stats = self._operations[operation_id]
                for key, value in kwargs.items():
                    if hasattr(stats, key):
                        if key in ['files_processed', 'files_moved', 
                                  'files_skipped', 'errors']:
                            # Increment counters
                            current = getattr(stats, key)
                            setattr(stats, key, current + value)
                        else:
                            setattr(stats, key, value)
    
    def get_operation_stats(self, operation_id: str) -> Optional[OperationStats]:
        """Get statistics for an operation."""
        with self._lock:
            return self._operations.get(operation_id)
    
    def get_current_operation_id(self) -> Optional[str]:
        """Get the current operation ID."""
        with self._lock:
            return self._current_operation_id
    
    def request_abort(self) -> None:
        """Request abort of current operation."""
        self._abort_signal.set()
        self._notify_listeners('abort_requested')
    
    def is_abort_requested(self) -> bool:
        """Check if abort was requested."""
        return self._abort_signal.is_set()
    
    def clear_abort(self) -> None:
        """Clear abort request."""
        self._abort_signal.clear()
    
    def get_abort_signal(self) -> threading.Event:
        """Get the abort signal event."""
        return self._abort_signal
    
    def set_value(self, key: str, value: Any) -> None:
        """Set a state value."""
        with self._lock:
            old_value = self._state.get(key)
            self._state[key] = value
            if old_value != value:
                self._notify_listeners('state_changed', 
                                     key=key, 
                                     old_value=old_value,
                                     new_value=value)
    
    def get_value(self, key: str, default: Any = None) -> Any:
        """Get a state value."""
        with self._lock:
            return self._state.get(key, default)
    
    def update_values(self, values: Dict[str, Any]) -> None:
        """Update multiple state values."""
        with self._lock:
            for key, value in values.items():
                self.set_value(key, value)
    
    def add_listener(self, event: str, callback: Callable) -> None:
        """Add an event listener."""
        with self._lock:
            if event not in self._listeners:
                self._listeners[event] = []
            self._listeners[event].append(callback)
    
    def remove_listener(self, event: str, callback: Callable) -> None:
        """Remove an event listener."""
        with self._lock:
            if event in self._listeners:
                self._listeners[event].remove(callback)
    
    def _notify_listeners(self, event: str, **kwargs) -> None:
        """Notify all listeners of an event."""
        listeners = self._listeners.get(event, [])
        for listener in listeners:
            try:
                listener(**kwargs)
            except Exception:
                # Log error but continue notifying
                pass
    
    def get_all_operations(self) -> Dict[str, OperationStats]:
        """Get all operation statistics."""
        with self._lock:
            return self._operations.copy()
    
    def save_state(self, filepath: Path) -> None:
        """Save state to file."""
        with self._lock:
            state_data = {
                'state': self._state,
                'operations': {
                    op_id: asdict(stats) 
                    for op_id, stats in self._operations.items()
                },
                'timestamp': datetime.now().isoformat()
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(state_data, f, indent=2)
    
    def load_state(self, filepath: Path) -> None:
        """Load state from file."""
        if not filepath.exists():
            return
        
        with self._lock:
            with open(filepath, 'r', encoding='utf-8') as f:
                state_data = json.load(f)
            
            self._state = state_data.get('state', {})
            
            # Reconstruct operation stats
            self._operations = {}
            for op_id, stats_dict in state_data.get('operations', {}).items():
                self._operations[op_id] = OperationStats(**stats_dict)
    
    def clear(self) -> None:
        """Clear all state."""
        with self._lock:
            self._state.clear()
            self._operations.clear()
            self._current_operation_id = None
            self._abort_signal.clear()
            self._operation_counter = 0


class ManagedOperation:
    """Context manager for operations with automatic tracking."""
    
    def __init__(self, state_manager: IStateManager, operation_type: str):
        """Initialize managed operation.
        
        Args:
            state_manager: State manager instance
            operation_type: Type of operation
        """
        self.state_manager = state_manager
        self.operation_type = operation_type
        self.operation_id: Optional[str] = None
    
    def __enter__(self):
        """Start the operation."""
        self.operation_id = self.state_manager.start_operation(self.operation_type)
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """End the operation."""
        if self.operation_id:
            self.state_manager.end_operation(self.operation_id)
    
    def update_stats(self, **kwargs) -> None:
        """Update operation statistics."""
        if self.operation_id:
            self.state_manager.update_operation_stats(self.operation_id, **kwargs)
    
    @property
    def abort_signal(self) -> threading.Event:
        """Get abort signal."""
        return self.state_manager.get_abort_signal()


# Global state manager instance
_state_manager: Optional[StateManager] = None


def get_state_manager() -> StateManager:
    """Get or create the global state manager."""
    global _state_manager
    if _state_manager is None:
        _state_manager = StateManager()
    return _state_manager


def reset_state_manager() -> None:
    """Reset the global state manager."""
    global _state_manager
    if _state_manager is not None:
        _state_manager.clear()
    _state_manager = StateManager()
</file>

<file path="folder_extractor/core/state.py">
"""
State management module.

Centralizes application state and provides thread-safe access.
"""
import threading
from typing import Optional, Any, Dict
from abc import ABC, abstractmethod


class IApplicationState(ABC):
    """Interface for application state management."""
    
    @abstractmethod
    def get_abort_signal(self) -> threading.Event:
        """Get the abort signal event."""
        pass
    
    @abstractmethod
    def request_abort(self) -> None:
        """Request operation abort."""
        pass
    
    @abstractmethod
    def clear_abort(self) -> None:
        """Clear abort request."""
        pass
    
    @abstractmethod
    def is_abort_requested(self) -> bool:
        """Check if abort was requested."""
        pass


class ApplicationState(IApplicationState):
    """Thread-safe application state container."""
    
    def __init__(self):
        """Initialize application state."""
        self._abort_signal = threading.Event()
        self._lock = threading.Lock()
        self._state: Dict[str, Any] = {}
    
    def get_abort_signal(self) -> threading.Event:
        """Get the abort signal event."""
        return self._abort_signal
    
    def request_abort(self) -> None:
        """Request operation abort."""
        self._abort_signal.set()
    
    def clear_abort(self) -> None:
        """Clear abort request."""
        self._abort_signal.clear()
    
    def is_abort_requested(self) -> bool:
        """Check if abort was requested."""
        return self._abort_signal.is_set()
    
    def set_value(self, key: str, value: Any) -> None:
        """Set a state value thread-safely."""
        with self._lock:
            self._state[key] = value
    
    def get_value(self, key: str, default: Any = None) -> Any:
        """Get a state value thread-safely."""
        with self._lock:
            return self._state.get(key, default)
    
    def update_values(self, values: Dict[str, Any]) -> None:
        """Update multiple state values atomically."""
        with self._lock:
            self._state.update(values)
    
    def clear(self) -> None:
        """Clear all state."""
        with self._lock:
            self._state.clear()
        self._abort_signal.clear()


class OperationContext:
    """Context for a single operation with its own state."""
    
    def __init__(self, app_state: IApplicationState):
        """Initialize operation context.
        
        Args:
            app_state: Application state container
        """
        self.app_state = app_state
        self.operation_data: Dict[str, Any] = {}
        self.start_time: Optional[float] = None
        self.end_time: Optional[float] = None
    
    @property
    def abort_signal(self) -> threading.Event:
        """Get abort signal from app state."""
        return self.app_state.get_abort_signal()
    
    def set_data(self, key: str, value: Any) -> None:
        """Set operation-specific data."""
        self.operation_data[key] = value
    
    def get_data(self, key: str, default: Any = None) -> Any:
        """Get operation-specific data."""
        return self.operation_data.get(key, default)
    
    def __enter__(self):
        """Enter operation context."""
        import time
        self.start_time = time.time()
        self.app_state.clear_abort()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Exit operation context."""
        import time
        self.end_time = time.time()
        # Could log operation duration here


# Global application state instance
_app_state: Optional[ApplicationState] = None


def get_app_state() -> ApplicationState:
    """Get or create the global application state."""
    global _app_state
    if _app_state is None:
        _app_state = ApplicationState()
    return _app_state


def reset_app_state() -> None:
    """Reset the global application state."""
    global _app_state
    if _app_state is not None:
        _app_state.clear()
    _app_state = ApplicationState()
</file>

<file path="folder_extractor/utils/__init__.py">
"""
Utility modules for Folder Extractor.
"""
</file>

<file path="folder_extractor/utils/file_validators.py">
"""
File validation utilities.

Provides functions to validate files, paths, and check
for temporary or system files.
"""
import os
from pathlib import Path
from typing import Optional

from folder_extractor.config.constants import (
    TEMP_EXTENSIONS,
    SYSTEM_FILES,
    EDITOR_TEMP_FILES,
    GIT_TEMP_FILES,
    GIT_DIRECTORY,
    HIDDEN_FILE_PREFIX
)


def is_temp_or_system_file(filename: str) -> bool:
    """
    Check if a file is a temporary or system file.
    
    Args:
        filename: Name of the file to check
    
    Returns:
        True if the file is temporary or system file
    
    Examples:
        >>> is_temp_or_system_file(".DS_Store")
        True
        >>> is_temp_or_system_file("document.pdf")
        False
    """
    basename = os.path.basename(filename)
    name_lower = basename.lower()
    
    # Check exact matches first
    if basename in SYSTEM_FILES or basename in GIT_TEMP_FILES:
        return True
    
    # Check lowercase matches for case-insensitive systems
    if name_lower in {f.lower() for f in SYSTEM_FILES}:
        return True
    
    # Check extensions
    _, ext = os.path.splitext(name_lower)
    if ext in TEMP_EXTENSIONS:
        return True
    
    # Check editor temp files patterns
    for pattern in EDITOR_TEMP_FILES:
        if pattern.endswith('*'):
            if basename.startswith(pattern[:-1]):
                return True
        elif pattern.startswith('*'):
            if basename.endswith(pattern[1:]):
                return True
        elif basename == pattern:
            return True
    
    # Check for various temp file patterns
    if basename.startswith('~$') or basename.startswith('.~'):
        return True
    
    if basename.startswith('.#') or (basename.startswith('#') and basename.endswith('#')):
        return True
    
    if basename.endswith('~'):
        return True
    
    # Check for hidden macOS resource forks
    if basename.startswith('._'):
        return True
    
    return False


def is_git_path(path: str) -> bool:
    """
    Check if a path is within a git directory.
    
    Args:
        path: Path to check
    
    Returns:
        True if the path is within .git directory
    
    Examples:
        >>> is_git_path("/project/.git/config")
        True
        >>> is_git_path("/project/src/main.py")
        False
    """
    path_parts = Path(path).parts
    return GIT_DIRECTORY in path_parts


def is_hidden_file(path: str) -> bool:
    """
    Check if a file or directory is hidden.
    
    Args:
        path: Path to check
    
    Returns:
        True if the file/directory is hidden
    """
    basename = os.path.basename(path)
    # Exclude current (.) and parent (..) directories
    return basename.startswith(HIDDEN_FILE_PREFIX) and basename not in ['.', '..']


def should_include_file(filepath: str, include_hidden: bool = False) -> bool:
    """
    Determine if a file should be included based on various criteria.
    
    Args:
        filepath: Path to the file
        include_hidden: Whether to include hidden files
    
    Returns:
        True if the file should be included
    """
    # Skip temp and system files
    if is_temp_or_system_file(filepath):
        return False
    
    # Skip git files
    if is_git_path(filepath):
        return False
    
    # Skip hidden files if not included
    if not include_hidden and is_hidden_file(filepath):
        return False
    
    return True


def validate_file_extension(filepath: str, allowed_extensions: Optional[list] = None) -> bool:
    """
    Check if a file has an allowed extension.
    
    Args:
        filepath: Path to the file
        allowed_extensions: List of allowed extensions (with dots)
    
    Returns:
        True if the file extension is allowed or no filter is set
    """
    if not allowed_extensions:
        return True
    
    _, ext = os.path.splitext(filepath.lower())
    return ext in allowed_extensions
</file>

<file path="folder_extractor/utils/parsers.py">
"""
Parsing utilities for command line arguments and user input.

Extracts parsing logic from the main module for better
testability and reusability.
"""
from typing import List, Optional


def parse_file_types(type_string: Optional[str]) -> Optional[List[str]]:
    """
    Parse file type filter string.
    
    Args:
        type_string: Comma-separated file types (e.g., "pdf,jpg,png")
    
    Returns:
        List of file extensions with dots (e.g., [".pdf", ".jpg", ".png"])
        or None if input is empty
    
    Examples:
        >>> parse_file_types("pdf,jpg")
        ['.pdf', '.jpg']
        >>> parse_file_types(".pdf,.jpg")
        ['.pdf', '.jpg']
        >>> parse_file_types("*.pdf,*.jpg")
        ['.pdf', '.jpg']
        >>> parse_file_types("")
        None
    """
    if not type_string or type_string.strip() == "":
        return None
    
    types = []
    for t in type_string.split(','):
        t = t.strip().lower()
        if t:
            # Remove common prefixes
            if t.startswith('*.'):
                t = t[2:]
            elif t.startswith('*'):
                t = t[1:]
            
            # Ensure dot prefix
            if not t.startswith('.'):
                t = '.' + t
            
            types.append(t)
    
    return types if types else None


def parse_domains(domain_string: Optional[str]) -> Optional[List[str]]:
    """
    Parse domain filter string.
    
    Args:
        domain_string: Comma-separated domains (e.g., "youtube.com,github.com")
    
    Returns:
        List of domains without www prefix (e.g., ["youtube.com", "github.com"])
        or None if input is empty
    
    Examples:
        >>> parse_domains("youtube.com,github.com")
        ['youtube.com', 'github.com']
        >>> parse_domains("www.youtube.com")
        ['youtube.com']
        >>> parse_domains("")
        None
    """
    if not domain_string or domain_string.strip() == "":
        return None
    
    domains = []
    for d in domain_string.split(','):
        d = d.strip().lower()
        if d:
            # Remove www prefix
            if d.startswith('www.'):
                d = d[4:]
            domains.append(d)
    
    return domains if domains else None


def parse_depth(depth_string: str) -> int:
    """
    Parse depth argument.
    
    Args:
        depth_string: Depth value as string
    
    Returns:
        Integer depth value (0 means unlimited)
    
    Raises:
        ValueError: If depth is not a valid non-negative integer
    """
    try:
        depth = int(depth_string)
        if depth < 0:
            raise ValueError("Tiefe muss eine positive Zahl sein")
        return depth
    except ValueError as e:
        if "invalid literal" in str(e):
            raise ValueError(f"Ung√ºltige Tiefe: '{depth_string}' ist keine Zahl")
        raise
</file>

<file path="folder_extractor/utils/path_validators.py">
"""
Path validation and security utilities.

Ensures operations only occur in safe directories.
"""
import os
from pathlib import Path
from typing import Tuple

from folder_extractor.config.constants import SAFE_FOLDER_NAMES


def is_safe_path(path: str) -> bool:
    """
    Check if a path is in a safe location.
    
    Only allows operations in Desktop, Downloads, or Documents folders.
    
    Args:
        path: Path to validate
    
    Returns:
        True if the path is in a safe location
    
    Examples:
        >>> is_safe_path("/Users/user/Desktop/test")
        True
        >>> is_safe_path("/etc/passwd")
        False
    """
    try:
        # Resolve to absolute path
        abs_path = os.path.abspath(path)
        
        # Get user home directory
        home = str(Path.home())
        
        # Path must be within home directory
        if not abs_path.startswith(home):
            return False
        
        # Get relative path from home
        rel_path = os.path.relpath(abs_path, home)
        path_parts = rel_path.split(os.sep)
        
        # Check if first part is a safe folder
        if path_parts and path_parts[0] in SAFE_FOLDER_NAMES:
            return True
        
        return False
    
    except Exception:
        # Any error in path resolution means it's not safe
        return False


def get_safe_path_info(path: str) -> Tuple[bool, str]:
    """
    Get detailed information about path safety.
    
    Args:
        path: Path to check
    
    Returns:
        Tuple of (is_safe, reason)
    """
    try:
        abs_path = os.path.abspath(path)
        home = str(Path.home())
        
        if not abs_path.startswith(home):
            return False, "Path is outside home directory"
        
        rel_path = os.path.relpath(abs_path, home)
        path_parts = rel_path.split(os.sep)
        
        if not path_parts:
            return False, "Invalid path structure"
        
        if path_parts[0] in SAFE_FOLDER_NAMES:
            return True, f"Path is in safe folder: {path_parts[0]}"
        
        return False, f"Path is not in allowed folders: {', '.join(SAFE_FOLDER_NAMES)}"
    
    except Exception as e:
        return False, f"Error validating path: {str(e)}"


def normalize_path(path: str) -> str:
    """
    Normalize a path for consistent handling.
    
    Args:
        path: Path to normalize
    
    Returns:
        Normalized absolute path
    """
    return os.path.abspath(os.path.expanduser(path))


def is_subdirectory(parent: str, child: str) -> bool:
    """
    Check if one path is a subdirectory of another.
    
    Args:
        parent: Parent directory path
        child: Potential child directory path
    
    Returns:
        True if child is a subdirectory of parent
    """
    parent = normalize_path(parent)
    child = normalize_path(child)
    
    try:
        # Get relative path - will raise if not related
        rel = os.path.relpath(child, parent)
        # If it starts with .., it's not a subdirectory
        return not rel.startswith('..')
    except ValueError:
        # Paths are on different drives (Windows)
        return False
</file>

<file path="folder_extractor/utils/terminal.py">
"""
Terminal handling utilities.

Provides functions for terminal settings management
and output formatting.
"""
import os
import sys
import platform
from typing import Optional, List

# Only import termios on Unix-like systems
if platform.system() != 'Windows':
    import termios
    import tty


def save_terminal_settings() -> Optional[List]:
    """
    Save current terminal settings.
    
    Returns:
        Terminal settings list or None on Windows/error
    """
    if platform.system() == 'Windows':
        return None
    
    try:
        if hasattr(sys.stdin, 'fileno') and sys.stdin.isatty():
            return termios.tcgetattr(sys.stdin.fileno())
    except Exception:
        pass
    
    return None


def restore_terminal_settings(settings: Optional[List]) -> None:
    """
    Restore terminal settings.
    
    Args:
        settings: Previously saved terminal settings
    """
    if platform.system() == 'Windows' or settings is None:
        return
    
    try:
        if hasattr(sys.stdin, 'fileno') and sys.stdin.isatty():
            termios.tcsetattr(sys.stdin.fileno(), termios.TCSANOW, settings)
    except Exception:
        pass


def set_raw_mode() -> bool:
    """
    Set terminal to raw mode for key detection.
    
    Returns:
        True if successful, False otherwise
    """
    if platform.system() == 'Windows':
        return False
    
    try:
        if hasattr(sys.stdin, 'fileno') and sys.stdin.isatty():
            tty.setraw(sys.stdin.fileno())
            return True
    except Exception:
        pass
    
    return False


def clear_line() -> None:
    """
    Clear the current terminal line.
    """
    print('\r\033[K', end='', flush=True)


def move_cursor_up(lines: int = 1) -> None:
    """
    Move cursor up by specified number of lines.
    
    Args:
        lines: Number of lines to move up
    """
    if lines > 0:
        print(f'\033[{lines}A', end='', flush=True)


def move_cursor_down(lines: int = 1) -> None:
    """
    Move cursor down by specified number of lines.
    
    Args:
        lines: Number of lines to move down
    """
    if lines > 0:
        print(f'\033[{lines}B', end='', flush=True)


def get_terminal_width() -> int:
    """
    Get terminal width in characters.
    
    Returns:
        Terminal width or 80 as default
    """
    try:
        if platform.system() == 'Windows':
            # Windows-specific method
            import shutil
            return shutil.get_terminal_size().columns
        else:
            # Unix-like systems
            import fcntl
            import struct
            h, w, hp, wp = struct.unpack('HHHH',
                fcntl.ioctl(0, termios.TIOCGWINSZ,
                struct.pack('HHHH', 0, 0, 0, 0)))
            return w
    except Exception:
        return 80  # Default width


def format_progress_bar(current: int, total: int, width: int = 50) -> str:
    """
    Format a progress bar string.
    
    Args:
        current: Current progress value
        total: Total value
        width: Width of the progress bar
    
    Returns:
        Formatted progress bar string
    """
    if total == 0:
        percentage = 100
    else:
        percentage = int((current / total) * 100)
    
    filled = int((current / total) * width) if total > 0 else width
    bar = '‚ñà' * filled + '‚ñë' * (width - filled)
    
    return f"[{bar}] {percentage}% ({current}/{total})"


def supports_color() -> bool:
    """
    Check if terminal supports color output.
    
    Returns:
        True if color is supported
    """
    # Check if output is to a terminal
    if not hasattr(sys.stdout, 'isatty') or not sys.stdout.isatty():
        return False
    
    # Check platform
    if platform.system() == 'Windows':
        # Windows 10+ supports ANSI colors
        try:
            import ctypes
            kernel32 = ctypes.windll.kernel32
            kernel32.SetConsoleMode(kernel32.GetStdHandle(-11), 7)
            return True
        except Exception:
            return False
    
    # Unix-like systems usually support color
    term = os.environ.get('TERM', '')
    return term != 'dumb'


class Color:
    """ANSI color codes for terminal output."""
    
    # Reset
    RESET = '\033[0m'
    
    # Regular colors
    BLACK = '\033[30m'
    RED = '\033[31m'
    GREEN = '\033[32m'
    YELLOW = '\033[33m'
    BLUE = '\033[34m'
    MAGENTA = '\033[35m'
    CYAN = '\033[36m'
    WHITE = '\033[37m'
    
    # Bright colors
    BRIGHT_BLACK = '\033[90m'
    BRIGHT_RED = '\033[91m'
    BRIGHT_GREEN = '\033[92m'
    BRIGHT_YELLOW = '\033[93m'
    BRIGHT_BLUE = '\033[94m'
    BRIGHT_MAGENTA = '\033[95m'
    BRIGHT_CYAN = '\033[96m'
    BRIGHT_WHITE = '\033[97m'
    
    # Styles
    BOLD = '\033[1m'
    DIM = '\033[2m'
    ITALIC = '\033[3m'
    UNDERLINE = '\033[4m'
    
    @classmethod
    def colorize(cls, text: str, color: str) -> str:
        """Apply color to text if supported."""
        if supports_color():
            return f"{color}{text}{cls.RESET}"
        return text
    
    @classmethod
    def success(cls, text: str) -> str:
        """Format success message."""
        return cls.colorize(text, cls.GREEN)
    
    @classmethod
    def error(cls, text: str) -> str:
        """Format error message."""
        return cls.colorize(text, cls.RED)
    
    @classmethod
    def warning(cls, text: str) -> str:
        """Format warning message."""
        return cls.colorize(text, cls.YELLOW)
    
    @classmethod
    def info(cls, text: str) -> str:
        """Format info message."""
        return cls.colorize(text, cls.CYAN)
</file>

<file path="folder_extractor/__init__.py">
"""
Folder Extractor - Ein sicheres Tool zum Extrahieren von Dateien aus Unterordnern
"""

__version__ = "1.3.3"
__author__ = "Philipp Briese"
</file>

<file path="folder_extractor/main_final.py">
#!/usr/bin/env python3
"""
Folder Extractor - Main entry point.

This module provides the entry point for the modular architecture.
"""
import sys


def main():
    """Main entry point using the new modular architecture."""
    from folder_extractor.cli.app_v2 import main as enhanced_main
    return enhanced_main()


if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="folder_extractor/main_new.py">
#!/usr/bin/env python3
"""
Folder Extractor - Neue modulare Version

Dieses Modul dient als Br√ºcke zwischen der alten monolithischen
und der neuen modularen Architektur.
"""
import sys

# Import der neuen CLI-App
from folder_extractor.cli.app import main as cli_main


def main():
    """Haupteinstiegspunkt f√ºr Folder Extractor."""
    return cli_main()


if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="folder_extractor/main_refactored.py">
#!/usr/bin/env python3
"""
Folder Extractor - Refactored Version

This is a transitional file that imports from the new modular structure
while maintaining backward compatibility.
"""

import os
import sys
import json
import shutil
import argparse
import threading
import time
from pathlib import Path
from datetime import datetime
from urllib.parse import urlparse
import xml.etree.ElementTree as ET
import platform

# Import from new structure
from folder_extractor.config.constants import (
    VERSION, AUTHOR, SAFE_FOLDER_NAMES, HIDDEN_FILE_PREFIX,
    GIT_DIRECTORY, HISTORY_FILE_NAME, FILE_TYPE_FOLDERS,
    NO_EXTENSION_FOLDER, MESSAGES, HELP_TEXT,
    DEFAULT_MAX_DEPTH, PROGRESS_BAR_WIDTH
)

from folder_extractor.config.settings import settings, configure_from_args

from folder_extractor.utils.parsers import (
    parse_file_types as parse_dateitypen,
    parse_domains
)

from folder_extractor.utils.file_validators import (
    is_temp_or_system_file as ist_temp_oder_system_datei,
    is_git_path as ist_git_pfad,
    should_include_file,
    validate_file_extension
)

from folder_extractor.utils.path_validators import (
    is_safe_path as ist_sicherer_pfad,
    normalize_path
)

from folder_extractor.utils.terminal import (
    save_terminal_settings,
    restore_terminal_settings,
    clear_line,
    format_progress_bar,
    Color
)

# Global abort signal (will be moved to proper state management)
abort_signal = threading.Event()

# Re-export all functions that were in the original main.py
# This ensures backward compatibility during migration

# For now, we'll keep the original implementations here
# In the next phase, these will be moved to their respective modules

# Placeholder for remaining functions that haven't been migrated yet
# These will be extracted in subsequent phases
</file>

<file path="tests/integration/test_backward_compatibility.py">
"""
Test backward compatibility with legacy architecture.
"""
import os
import sys
import tempfile
import shutil
from pathlib import Path
import pytest
import json

# Add parent to path for imports
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

from folder_extractor.config.settings import settings
from folder_extractor.core.state_manager import reset_state_manager


class TestBackwardCompatibility:
    """Test backward compatibility features."""
    
    def setup_method(self):
        """Set up test environment."""
        # Reset state
        reset_state_manager()
        settings.reset_to_defaults()
        
        # Create temporary test directory in Desktop (safe path)
        desktop = Path.home() / "Desktop"
        self.test_dir = tempfile.mkdtemp(dir=str(desktop), prefix="folder_extractor_compat_")
        self.original_cwd = os.getcwd()
    
    def teardown_method(self):
        """Clean up test environment."""
        os.chdir(self.original_cwd)
        if os.path.exists(self.test_dir):
            shutil.rmtree(self.test_dir)
    
    def test_legacy_history_format_reading(self):
        """Test reading history in legacy format."""
        from folder_extractor.core.file_operations import HistoryManager
        
        # Create legacy history file
        history_file = Path(self.test_dir) / ".folder_extractor_history.json"
        legacy_history = {
            "zeitstempel": "2024-01-01T12:00:00",
            "version": "1.0",
            "operationen": [
                {
                    "original_pfad": "/old/path/file.txt",
                    "neuer_pfad": "/new/path/file.txt",
                    "original_name": "file.txt",
                    "neuer_name": "file.txt",
                    "zeitstempel": "2024-01-01T12:00:00"
                }
            ]
        }
        
        history_file.write_text(json.dumps(legacy_history, ensure_ascii=False))
        
        # Load history
        loaded = HistoryManager.load_history(self.test_dir)
        
        assert loaded is not None
        assert "operationen" in loaded
        assert len(loaded["operationen"]) == 1
        assert loaded["operationen"][0]["original_pfad"] == "/old/path/file.txt"
    
    def test_settings_migration(self):
        """Test settings migration to state manager."""
        from folder_extractor.core.migration import MigrationHelper
        from folder_extractor.core.state_manager import get_state_manager
        
        # Set some settings
        settings.set("max_depth", 5)
        settings.set("file_type_filter", "pdf")
        settings.set("dry_run", True)
        
        # Migrate
        MigrationHelper.migrate_settings()
        
        # Check state manager has settings
        state_manager = get_state_manager()
        assert state_manager.get_value("max_depth") == 5
        assert state_manager.get_value("file_type_filter") == "pdf"
        assert state_manager.get_value("dry_run") is True
    
    def test_extractor_adapter(self):
        """Test extractor adapter for new interface."""
        from folder_extractor.core.migration import ExtractorAdapter
        from folder_extractor.core.extractor_v2 import EnhancedFileExtractor
        
        # Create enhanced extractor
        enhanced_extractor = EnhancedFileExtractor()
        
        # Create adapter
        adapter = ExtractorAdapter(enhanced_extractor)
        
        # Test methods exist
        assert hasattr(adapter, "extract_files")
        assert hasattr(adapter, "undo_last_operation")
    
    def test_enhanced_cli_with_legacy_args(self):
        """Test enhanced CLI with legacy command line arguments."""
        from folder_extractor.cli.app_v2 import EnhancedFolderExtractorCLI
        
        # Create test structure
        sub_dir = Path(self.test_dir) / "subdir"
        sub_dir.mkdir()
        (sub_dir / "file1.txt").write_text("content1")
        (sub_dir / "file2.pdf").write_text("content2")
        
        os.chdir(self.test_dir)
        
        # Test legacy arguments work with new CLI
        cli = EnhancedFolderExtractorCLI()
        cli.interface.confirm_operation = lambda x: True
        
        # Test various legacy argument combinations
        result = cli.run(["--dry-run", "--depth", "2"])
        assert result == 0
        
        result = cli.run(["--dry-run", "--type", "txt"])
        assert result == 0
        
        result = cli.run(["--dry-run", "--sort-by-type"])
        assert result == 0
    
    def test_main_selector_legacy_fallback(self):
        """Test main selector falls back to legacy when needed."""
        import subprocess
        
        # Test with FOLDER_EXTRACTOR_ARCH=legacy
        env = os.environ.copy()
        env["FOLDER_EXTRACTOR_ARCH"] = "legacy"
        
        # Create test structure
        sub_dir = Path(self.test_dir) / "subdir"
        sub_dir.mkdir()
        (sub_dir / "file.txt").write_text("content")
        
        # Run main.py in legacy mode
        result = subprocess.run(
            [sys.executable, "-m", "folder_extractor.main_final", "--dry-run"],
            cwd=self.test_dir,
            env=env,
            capture_output=True,
            text=True
        )
        
        # Check it ran without errors
        assert result.returncode == 0
        assert "legacy architecture" in result.stderr.lower()
    
    def test_mixed_history_format(self):
        """Test handling mixed format history (German and English fields)."""
        from folder_extractor.core.extractor_v2 import EnhancedFileExtractor
        
        # Create mixed format history
        history_file = Path(self.test_dir) / ".folder_extractor_history.json"
        mixed_history = {
            "zeitstempel": "2024-01-01T12:00:00",
            "version": "1.0",
            "operationen": [
                {
                    # German format
                    "original_pfad": str(Path(self.test_dir) / "subdir" / "file1.txt"),
                    "neuer_pfad": str(Path(self.test_dir) / "file1.txt")
                },
                {
                    # English format (hypothetical future version)
                    "original_path": str(Path(self.test_dir) / "subdir" / "file2.txt"),
                    "new_path": str(Path(self.test_dir) / "file2.txt")
                }
            ]
        }
        
        # Create moved files
        (Path(self.test_dir) / "file1.txt").write_text("content1")
        (Path(self.test_dir) / "file2.txt").write_text("content2")
        
        # Create subdir
        subdir = Path(self.test_dir) / "subdir"
        subdir.mkdir()
        
        # Save history
        history_file.write_text(json.dumps(mixed_history))
        
        # Test undo works with both formats
        extractor = EnhancedFileExtractor()
        result = extractor.undo_last_operation(self.test_dir)
        
        assert result["status"] == "success"
        assert result["restored"] == 2
    
    def test_settings_compatibility(self):
        """Test that settings work with both old and new architecture."""
        # Test basic settings operations
        settings.set("max_depth", 3)
        settings.set("file_type_filter", "pdf")
        settings.set("include_hidden", True)
        settings.set("sort_by_type", True)
        
        # Verify settings
        assert settings.get("max_depth") == 3
        assert settings.get("file_type_filter") == "pdf"
        assert settings.get("include_hidden") is True
        assert settings.get("sort_by_type") is True
        
        # Test settings migration to state manager
        from folder_extractor.core.migration import MigrationHelper
        from folder_extractor.core.state_manager import get_state_manager
        
        MigrationHelper.migrate_settings()
        
        # Verify state manager has the same settings
        state_manager = get_state_manager()
        assert state_manager.get_value("max_depth") == 3
        assert state_manager.get_value("file_type_filter") == "pdf"
</file>

<file path="tests/integration/test_extraction_workflow.py">
"""
Integration tests for the complete extraction workflow.
"""
import os
import tempfile
import shutil
from pathlib import Path
import pytest

from folder_extractor.cli.app_v2 import EnhancedFolderExtractorCLI
from folder_extractor.core.state_manager import reset_state_manager
from folder_extractor.config.settings import settings


class TestExtractionWorkflow:
    """Test complete extraction workflow."""
    
    def setup_method(self):
        """Set up test environment."""
        # Reset state
        reset_state_manager()
        settings.reset_to_defaults()
        
        # Create temporary test directory in Desktop (safe path)
        desktop = Path.home() / "Desktop"
        self.test_dir = tempfile.mkdtemp(dir=str(desktop), prefix="folder_extractor_test_")
        self.original_cwd = os.getcwd()
    
    def teardown_method(self):
        """Clean up test environment."""
        # Restore working directory
        os.chdir(self.original_cwd)
        
        # Remove test directory
        if os.path.exists(self.test_dir):
            shutil.rmtree(self.test_dir)
    
    def create_test_structure(self):
        """Create test directory structure with files."""
        # Create subdirectories
        sub1 = Path(self.test_dir) / "subdir1"
        sub2 = Path(self.test_dir) / "subdir2"
        sub1_nested = sub1 / "nested"
        
        sub1.mkdir()
        sub2.mkdir()
        sub1_nested.mkdir()
        
        # Create test files
        files = [
            (sub1 / "file1.txt", "Content 1"),
            (sub1 / "file2.pdf", "PDF content"),
            (sub2 / "file3.jpg", "Image data"),
            (sub1_nested / "file4.txt", "Nested content"),
            (Path(self.test_dir) / "root.txt", "Root file"),
        ]
        
        for filepath, content in files:
            filepath.write_text(content)
        
        return files
    
    def test_basic_extraction(self):
        """Test basic file extraction."""
        # Create test structure
        self.create_test_structure()
        os.chdir(self.test_dir)
        
        # Run extraction
        cli = EnhancedFolderExtractorCLI()
        
        # Mock confirmation to auto-accept
        cli.interface.confirm_operation = lambda x: True
        
        # Execute and capture any errors
        try:
            result = cli.run(["--dry-run"])
            # Check success
            assert result == 0
        except Exception as e:
            print(f"Error during extraction: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def test_extraction_with_depth_limit(self):
        """Test extraction with depth limit."""
        # Create test structure
        self.create_test_structure()
        os.chdir(self.test_dir)
        
        # Run extraction with depth limit
        cli = EnhancedFolderExtractorCLI()
        cli.interface.confirm_operation = lambda x: True
        
        # Execute with depth=1 (should exclude nested files)
        result = cli.run(["--depth", "1", "--dry-run"])
        
        assert result == 0
    
    def test_extraction_with_type_filter(self):
        """Test extraction with file type filter."""
        # Create test structure
        self.create_test_structure()
        os.chdir(self.test_dir)
        
        # Run extraction filtering only txt files
        cli = EnhancedFolderExtractorCLI()
        cli.interface.confirm_operation = lambda x: True
        
        result = cli.run(["--type", "txt", "--dry-run"])
        
        assert result == 0
    
    def test_extraction_with_sort_by_type(self):
        """Test extraction with sort by type."""
        # Create test structure
        self.create_test_structure()
        os.chdir(self.test_dir)
        
        # Run extraction with sort by type
        cli = EnhancedFolderExtractorCLI()
        cli.interface.confirm_operation = lambda x: True
        
        result = cli.run(["--sort-by-type", "--dry-run"])
        
        assert result == 0
    
    def test_abort_handling(self):
        """Test abort functionality."""
        # Create test structure
        self.create_test_structure()
        os.chdir(self.test_dir)
        
        # Run extraction
        cli = EnhancedFolderExtractorCLI()
        cli.interface.confirm_operation = lambda x: True
        
        # Request abort immediately
        cli.state_manager.request_abort()
        
        result = cli.run(["--dry-run"])
        
        # Should still return 0 (aborted is not an error)
        assert result == 0
    
    def test_no_files_found(self):
        """Test when no files are found."""
        # Create empty directory
        empty_dir = Path(self.test_dir) / "empty"
        empty_dir.mkdir()
        os.chdir(empty_dir)
        
        # Run extraction
        cli = EnhancedFolderExtractorCLI()
        
        result = cli.run([])
        
        # Should return 0 (no files is not an error)
        assert result == 0
    
    def test_security_validation(self):
        """Test security validation."""
        # Try to run in a non-safe directory
        unsafe_dir = tempfile.mkdtemp(dir="/tmp")
        os.chdir(unsafe_dir)
        
        try:
            # Run extraction
            cli = EnhancedFolderExtractorCLI()
            result = cli.run([])
            
            # Should fail with security error
            assert result == 1
        finally:
            os.chdir(self.original_cwd)
            shutil.rmtree(unsafe_dir)
    
    def test_user_cancellation(self):
        """Test user cancellation during confirmation."""
        # Create test structure
        self.create_test_structure()
        os.chdir(self.test_dir)
        
        # Run extraction
        cli = EnhancedFolderExtractorCLI()
        
        # Mock confirmation to decline
        cli.interface.confirm_operation = lambda x: False
        
        result = cli.run([])
        
        # Should return 0 (cancellation is not an error)
        assert result == 0


class TestUndoWorkflow:
    """Test undo functionality."""
    
    def setup_method(self):
        """Set up test environment."""
        reset_state_manager()
        settings.reset_to_defaults()
        
        # Create temporary test directory in Desktop (safe path)
        desktop = Path.home() / "Desktop"
        self.test_dir = tempfile.mkdtemp(dir=str(desktop), prefix="folder_extractor_test_")
        self.original_cwd = os.getcwd()
    
    def teardown_method(self):
        """Clean up test environment."""
        os.chdir(self.original_cwd)
        if os.path.exists(self.test_dir):
            shutil.rmtree(self.test_dir)
    
    def test_undo_no_history(self):
        """Test undo when no history exists."""
        os.chdir(self.test_dir)
        
        # Run undo
        cli = EnhancedFolderExtractorCLI()
        result = cli.run(["--undo"])
        
        # Should return 1 (no history to undo)
        assert result == 1
    
    def test_undo_with_history(self):
        """Test undo with existing history."""
        os.chdir(self.test_dir)
        
        # Create fake history file
        history_file = Path(self.test_dir) / ".folder_extractor_history.json"
        history_data = {
            "zeitstempel": "2024-01-01T12:00:00",
            "version": "1.0",
            "operationen": [
                {
                    "original_pfad": str(Path(self.test_dir) / "subdir" / "file.txt"),
                    "neuer_pfad": str(Path(self.test_dir) / "file.txt")
                }
            ]
        }
        
        # Create the moved file and subdirectory
        moved_file = Path(self.test_dir) / "file.txt"
        moved_file.write_text("test content")
        
        # Create the subdirectory for undo operation
        subdir = Path(self.test_dir) / "subdir"
        subdir.mkdir(exist_ok=True)
        
        # Save history
        import json
        history_file.write_text(json.dumps(history_data))
        
        # Run undo
        cli = EnhancedFolderExtractorCLI()
        result = cli.run(["--undo"])
        
        # Should succeed
        assert result == 0


class TestStateManagement:
    """Test state management integration."""
    
    def setup_method(self):
        """Set up test environment."""
        reset_state_manager()
        settings.reset_to_defaults()
    
    def test_state_persistence(self):
        """Test that state persists across operations."""
        from folder_extractor.core.state_manager import get_state_manager
        
        # Set some state
        state_manager = get_state_manager()
        state_manager.set_value("test_key", "test_value")
        
        # Create new CLI instance
        cli = EnhancedFolderExtractorCLI()
        
        # State should be available
        assert cli.state_manager.get_value("test_key") == "test_value"
    
    def test_operation_tracking(self):
        """Test operation tracking."""
        from folder_extractor.core.state_manager import get_state_manager
        
        state_manager = get_state_manager()
        
        # Create test directory
        with tempfile.TemporaryDirectory() as test_dir:
            # Create a file
            sub_dir = Path(test_dir) / "subdir"
            sub_dir.mkdir()
            (sub_dir / "file.txt").write_text("content")
            
            os.chdir(test_dir)
            
            # Run extraction
            cli = EnhancedFolderExtractorCLI()
            cli.interface.confirm_operation = lambda x: True
            
            result = cli.run(["--dry-run"])
            
            # Check operations were tracked
            all_ops = state_manager.get_all_operations()
            assert len(all_ops) > 0
            
            # Check operation has statistics
            for op_id, stats in all_ops.items():
                if stats.operation_type == "extraction":
                    assert stats.files_processed >= 0
                    assert stats.end_time is not None
</file>

<file path="tests/performance/test_benchmarks.py">
"""
Performance benchmarks for critical operations.
"""
import os
import time
import pytest
from pathlib import Path
import tempfile
import shutil
import statistics

from folder_extractor.main import (
    finde_dateien,
    verschiebe_dateien,
    generiere_eindeutigen_namen,
    entferne_leere_ordner
)


class BenchmarkTimer:
    """Context manager for timing operations."""
    
    def __init__(self, name):
        self.name = name
        self.start_time = None
        self.end_time = None
        self.duration = None
    
    def __enter__(self):
        self.start_time = time.perf_counter()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.end_time = time.perf_counter()
        self.duration = self.end_time - self.start_time
        print(f"\n{self.name}: {self.duration:.4f} seconds")


def create_file_tree(base_path, num_files, depth, files_per_dir=10):
    """Create a file tree for testing."""
    created_files = []
    
    def create_level(path, current_depth):
        if current_depth > depth:
            return
        
        # Create files at this level
        for i in range(files_per_dir):
            file_path = path / f"file_{current_depth}_{i}.txt"
            file_path.write_text(f"Content at depth {current_depth}, file {i}")
            created_files.append(str(file_path))
        
        # Create subdirectories and recurse
        if current_depth < depth:
            for i in range(3):  # 3 subdirs per level
                subdir = path / f"subdir_{current_depth}_{i}"
                subdir.mkdir(exist_ok=True)
                create_level(subdir, current_depth + 1)
    
    create_level(Path(base_path), 0)
    return created_files


class TestFileDiscoveryPerformance:
    """Benchmark file discovery operations."""
    
    @pytest.mark.benchmark
    def test_find_files_flat_structure(self):
        """Benchmark finding files in flat structure."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create 1000 files in single directory
            print("\nCreating 1000 files in flat structure...")
            for i in range(1000):
                Path(temp_dir, f"file_{i:04d}.txt").touch()
            
            # Benchmark finding files
            with BenchmarkTimer("Find 1000 files (flat)"):
                files = finde_dateien(temp_dir)
            
            assert len(files) == 1000
    
    @pytest.mark.benchmark
    def test_find_files_deep_structure(self):
        """Benchmark finding files in deep structure."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create deep structure
            print("\nCreating deep file structure...")
            created = create_file_tree(temp_dir, 1000, depth=5)
            
            # Benchmark finding files
            with BenchmarkTimer("Find files (deep structure)"):
                files = finde_dateien(temp_dir, max_tiefe=0)
            
            assert len(files) >= len(created)
    
    @pytest.mark.benchmark
    def test_find_files_with_filtering(self):
        """Benchmark finding files with type filtering."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create mixed file types
            print("\nCreating mixed file types...")
            extensions = [".txt", ".pdf", ".jpg", ".doc", ".mp3"]
            for i in range(1000):
                ext = extensions[i % len(extensions)]
                Path(temp_dir, f"file_{i:04d}{ext}").touch()
            
            # Benchmark finding only txt and pdf files
            with BenchmarkTimer("Find files with type filter"):
                files = finde_dateien(temp_dir, dateityp_filter=[".txt", ".pdf"])
            
            assert len(files) == 400  # 200 txt + 200 pdf


class TestFileMovePerformance:
    """Benchmark file moving operations."""
    
    @pytest.mark.benchmark
    def test_move_many_small_files(self, safe_test_dir):
        """Benchmark moving many small files."""
        source_dir = Path(safe_test_dir) / "source"
        source_dir.mkdir(exist_ok=True)
        
        # Create 500 small files
        print("\nCreating 500 small files...")
        files = []
        for i in range(500):
            file_path = source_dir / f"file_{i:04d}.txt"
            file_path.write_text(f"Small content {i}")
            files.append(str(file_path))
        
        # Benchmark moving
        with BenchmarkTimer("Move 500 small files"):
            moved, errors, duplicates, history = verschiebe_dateien(
                files, safe_test_dir, dry_run=False
            )
        
        assert moved == 500
    
    @pytest.mark.benchmark
    def test_move_large_files(self, safe_test_dir):
        """Benchmark moving large files."""
        source_dir = Path(safe_test_dir) / "source"
        source_dir.mkdir(exist_ok=True)
        
        # Create 10 large files (1MB each)
        print("\nCreating 10 large files (1MB each)...")
        files = []
        large_content = "x" * (1024 * 1024)  # 1MB
        for i in range(10):
            file_path = source_dir / f"large_{i}.dat"
            file_path.write_text(large_content)
            files.append(str(file_path))
        
        # Benchmark moving
        with BenchmarkTimer("Move 10 large files (1MB each)"):
            moved, errors, duplicates, history = verschiebe_dateien(
                files, safe_test_dir, dry_run=False
            )
        
        assert moved == 10
    
    @pytest.mark.benchmark
    def test_move_with_many_duplicates(self, safe_test_dir):
        """Benchmark moving files with many duplicates."""
        source_dir = Path(safe_test_dir) / "source"
        source_dir.mkdir(exist_ok=True)
        
        # Create existing files
        print("\nCreating existing files for duplicate testing...")
        for i in range(100):
            Path(safe_test_dir, f"duplicate_{i % 10}.txt").touch()
        
        # Create source files that will conflict
        files = []
        for i in range(100):
            file_path = source_dir / f"duplicate_{i % 10}.txt"
            file_path.write_text(f"New content {i}")
            files.append(str(file_path))
        
        # Benchmark moving with duplicate handling
        with BenchmarkTimer("Move 100 files with duplicates"):
            moved, errors, duplicates, history = verschiebe_dateien(
                files, safe_test_dir, dry_run=False
            )
        
        assert moved == 100
        assert duplicates == 100


class TestUniqueNamePerformance:
    """Benchmark unique name generation."""
    
    @pytest.mark.benchmark
    def test_unique_name_no_conflicts(self):
        """Benchmark unique name generation with no conflicts."""
        with tempfile.TemporaryDirectory() as temp_dir:
            times = []
            
            print("\nBenchmarking unique name generation (no conflicts)...")
            for i in range(1000):
                start = time.perf_counter()
                name = generiere_eindeutigen_namen(temp_dir, f"test_{i}.txt")
                end = time.perf_counter()
                times.append(end - start)
            
            avg_time = statistics.mean(times)
            print(f"Average time per generation: {avg_time*1000:.4f} ms")
            print(f"Total time for 1000 generations: {sum(times):.4f} seconds")
    
    @pytest.mark.benchmark
    def test_unique_name_many_conflicts(self):
        """Benchmark unique name generation with many conflicts."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create many conflicting files
            print("\nCreating 100 conflicting files...")
            base_name = "conflict.txt"
            Path(temp_dir, base_name).touch()
            for i in range(1, 100):
                Path(temp_dir, f"conflict_{i}.txt").touch()
            
            # Benchmark finding next available name
            with BenchmarkTimer("Generate unique name with 100 conflicts"):
                name = generiere_eindeutigen_namen(temp_dir, base_name)
            
            assert name == "conflict_100.txt"


class TestEmptyFolderCleanupPerformance:
    """Benchmark empty folder cleanup."""
    
    @pytest.mark.benchmark
    def test_cleanup_many_empty_folders(self):
        """Benchmark cleaning up many empty folders."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create deep structure of empty folders
            print("\nCreating 1000 empty folders...")
            for i in range(100):
                for j in range(10):
                    path = Path(temp_dir) / f"level1_{i}" / f"level2_{j}"
                    path.mkdir(parents=True, exist_ok=True)
            
            # Benchmark cleanup
            with BenchmarkTimer("Clean up 1000 empty folders"):
                removed = entferne_leere_ordner(temp_dir)
            
            assert removed >= 1000
    
    @pytest.mark.benchmark
    def test_cleanup_mixed_folders(self):
        """Benchmark cleanup with mixed empty/non-empty folders."""
        with tempfile.TemporaryDirectory() as temp_dir:
            print("\nCreating mixed folder structure...")
            
            # Create some empty folders
            for i in range(500):
                Path(temp_dir, f"empty_{i}").mkdir()
            
            # Create some non-empty folders
            for i in range(500):
                folder = Path(temp_dir, f"full_{i}")
                folder.mkdir()
                (folder / "file.txt").touch()
            
            # Benchmark cleanup
            with BenchmarkTimer("Clean up mixed structure (500 empty, 500 full)"):
                removed = entferne_leere_ordner(temp_dir)
            
            assert removed == 500


def run_all_benchmarks():
    """Run all benchmarks and print summary."""
    print("\n" + "="*60)
    print("Running Folder Extractor Performance Benchmarks")
    print("="*60)
    
    # Run each benchmark class
    benchmark_classes = [
        TestFileDiscoveryPerformance,
        TestFileMovePerformance,
        TestUniqueNamePerformance,
        TestEmptyFolderCleanupPerformance
    ]
    
    for cls in benchmark_classes:
        print(f"\n\n{cls.__name__}:")
        print("-" * 40)
        
        instance = cls()
        for method_name in dir(instance):
            if method_name.startswith('test_') and hasattr(getattr(instance, method_name), '__call__'):
                method = getattr(instance, method_name)
                try:
                    method()
                except TypeError:
                    # Method needs safe_test_dir
                    desktop = Path.home() / "Desktop" / "benchmark_test"
                    desktop.mkdir(exist_ok=True)
                    try:
                        method(str(desktop))
                    finally:
                        if desktop.exists():
                            shutil.rmtree(desktop)
    
    print("\n\n" + "="*60)
    print("Benchmark Summary Complete")
    print("="*60 + "\n")


if __name__ == "__main__":
    run_all_benchmarks()
</file>

<file path="tests/unit/test_cli_app.py">
"""
Unit tests for CLI app module.
"""
import pytest
import os
import sys
from unittest.mock import Mock, patch, MagicMock
from io import StringIO

from folder_extractor.cli.app import FolderExtractorCLI, main
from folder_extractor.config.settings import settings


class TestFolderExtractorCLI:
    """Test FolderExtractorCLI class."""
    
    def setup_method(self):
        """Set up test fixtures."""
        # Reset settings
        settings.reset_to_defaults()
        # Create CLI instance with mocked dependencies
        with patch('folder_extractor.cli.app.create_parser'):
            with patch('folder_extractor.cli.app.create_console_interface'):
                with patch('folder_extractor.cli.app.get_app_state'):
                    self.cli = FolderExtractorCLI()
    
    def test_init(self):
        """Test CLI initialization."""
        with patch('folder_extractor.cli.app.create_parser') as mock_parser:
            with patch('folder_extractor.cli.app.create_console_interface') as mock_interface:
                with patch('folder_extractor.cli.app.get_app_state') as mock_state:
                    cli = FolderExtractorCLI()
                    
                    # Check all components initialized
                    mock_parser.assert_called_once()
                    mock_interface.assert_called_once()
                    mock_state.assert_called_once()
                    
                    assert cli.parser is not None
                    assert cli.interface is not None
                    assert cli.app_state is not None
    
    def test_run_keyboard_interrupt(self):
        """Test handling keyboard interrupt."""
        # Mock parser to raise KeyboardInterrupt
        self.cli.parser.parse_args = Mock(side_effect=KeyboardInterrupt)
        
        with patch('sys.stdout', new=StringIO()) as mock_stdout:
            result = self.cli.run()
            
            assert result == 1
            output = mock_stdout.getvalue()
            assert "abgebrochen" in output.lower()
    
    def test_run_general_exception(self):
        """Test handling general exceptions."""
        # Mock parser to raise exception
        self.cli.parser.parse_args = Mock(side_effect=ValueError("Test error"))
        
        # Mock interface
        self.cli.interface.show_message = Mock()
        
        result = self.cli.run()
        
        assert result == 1
        self.cli.interface.show_message.assert_called_once()
        args = self.cli.interface.show_message.call_args[0]
        assert "Test error" in args[0]
    
    def test_run_undo_operation(self):
        """Test running undo operation."""
        # Mock parsed arguments for undo
        mock_args = Mock(undo=True)
        self.cli.parser.parse_args = Mock(return_value=mock_args)
        
        # Mock execute_undo
        with patch.object(self.cli, '_execute_undo', return_value=0) as mock_undo:
            with patch('folder_extractor.cli.app.configure_from_args'):
                with patch('folder_extractor.cli.app.OperationContext'):
                    result = self.cli.run()
                    
                    assert result == 0
                    mock_undo.assert_called_once()
                    # Should not show welcome for undo
                    assert not self.cli.interface.show_welcome.called
    
    def test_run_extraction_operation(self):
        """Test running extraction operation."""
        # Mock parsed arguments for extraction
        mock_args = Mock(undo=False)
        self.cli.parser.parse_args = Mock(return_value=mock_args)
        
        # Mock interface
        self.cli.interface.show_welcome = Mock()
        
        # Mock execute_extraction
        with patch.object(self.cli, '_execute_extraction', return_value=0) as mock_extract:
            with patch('folder_extractor.cli.app.configure_from_args'):
                with patch('folder_extractor.cli.app.OperationContext'):
                    result = self.cli.run()
                    
                    assert result == 0
                    mock_extract.assert_called_once()
                    # Should show welcome for extraction
                    self.cli.interface.show_welcome.assert_called_once()
    
    def test_execute_extraction_success(self):
        """Test successful extraction execution."""
        # Mock context
        mock_context = Mock()
        mock_context.abort_signal = Mock()
        
        # Mock extractor and orchestrator
        mock_extractor = Mock()
        mock_orchestrator = Mock()
        mock_orchestrator.execute_extraction.return_value = {
            "status": "success",
            "moved": 10,
            "duplicates": 2,
            "errors": 0
        }
        
        # Mock interface
        self.cli.interface.confirm_operation = Mock(return_value=True)
        self.cli.interface.show_progress = Mock()
        self.cli.interface.show_summary = Mock()
        
        # Mock app state
        self.cli.app_state.is_abort_requested = Mock(return_value=False)
        self.cli.app_state.request_abort = Mock()
        
        with patch('folder_extractor.cli.app.FileExtractor', return_value=mock_extractor):
            with patch('folder_extractor.cli.app.ExtractionOrchestrator', return_value=mock_orchestrator):
                with patch('folder_extractor.cli.app.KeyboardHandler') as mock_handler_class:
                    with patch('folder_extractor.cli.app.settings', {"dry_run": False}):
                        result = self.cli._execute_extraction("/test/path", mock_context)
                        
                        assert result == 0
                        
                        # Check orchestrator called correctly
                        mock_orchestrator.execute_extraction.assert_called_once_with(
                            source_path="/test/path",
                            confirmation_callback=self.cli.interface.confirm_operation,
                            progress_callback=self.cli.interface.show_progress
                        )
                        
                        # Check keyboard handler started and stopped
                        mock_handler_class.assert_called_once()
                        mock_handler = mock_handler_class.return_value
                        mock_handler.start.assert_called_once()
                        mock_handler.stop.assert_called_once()
                        
                        # Check summary shown
                        self.cli.interface.show_summary.assert_called_once()
    
    def test_execute_extraction_no_files(self):
        """Test extraction with no files found."""
        mock_context = Mock()
        mock_orchestrator = Mock()
        mock_orchestrator.execute_extraction.return_value = {
            "status": "no_files",
            "message": "Keine Dateien gefunden"
        }
        
        with patch('folder_extractor.cli.app.FileExtractor'):
            with patch('folder_extractor.cli.app.ExtractionOrchestrator', return_value=mock_orchestrator):
                with patch('folder_extractor.cli.app.settings', {"dry_run": True}):
                    result = self.cli._execute_extraction("/test/path", mock_context)
                    
                    # Should still return 0 (not an error)
                    assert result == 0
    
    def test_execute_extraction_cancelled(self):
        """Test extraction cancelled by user."""
        mock_context = Mock()
        mock_orchestrator = Mock()
        mock_orchestrator.execute_extraction.return_value = {
            "status": "cancelled",
            "message": "Operation abgebrochen"
        }
        
        with patch('folder_extractor.cli.app.FileExtractor'):
            with patch('folder_extractor.cli.app.ExtractionOrchestrator', return_value=mock_orchestrator):
                with patch('folder_extractor.cli.app.settings', {"dry_run": True}):
                    result = self.cli._execute_extraction("/test/path", mock_context)
                    
                    # Should return 0 (not an error)
                    assert result == 0
    
    def test_execute_extraction_aborted(self):
        """Test extraction aborted via ESC."""
        mock_context = Mock()
        mock_orchestrator = Mock()
        mock_orchestrator.execute_extraction.return_value = {
            "status": "success",
            "moved": 5
        }
        
        # Mock abort requested
        self.cli.app_state.is_abort_requested = Mock(return_value=True)
        
        with patch('folder_extractor.cli.app.FileExtractor'):
            with patch('folder_extractor.cli.app.ExtractionOrchestrator', return_value=mock_orchestrator):
                with patch('folder_extractor.cli.app.settings', {"dry_run": True}):
                    result = self.cli._execute_extraction("/test/path", mock_context)
                    
                    assert result == 0
                    
                    # Check aborted flag set in results
                    self.cli.interface.show_summary.assert_called_once()
                    summary_results = self.cli.interface.show_summary.call_args[0][0]
                    assert summary_results["aborted"] is True
    
    def test_execute_undo_success(self):
        """Test successful undo execution."""
        mock_context = Mock()
        mock_orchestrator = Mock()
        mock_orchestrator.execute_undo.return_value = {
            "status": "success",
            "message": "10 Dateien zur√ºck verschoben"
        }
        
        # Mock interface
        self.cli.interface.show_message = Mock()
        
        with patch('folder_extractor.cli.app.FileExtractor'):
            with patch('folder_extractor.cli.app.ExtractionOrchestrator', return_value=mock_orchestrator):
                result = self.cli._execute_undo("/test/path", mock_context)
                
                assert result == 0
                
                # Check orchestrator called
                mock_orchestrator.execute_undo.assert_called_once_with("/test/path")
                
                # Check messages shown
                assert self.cli.interface.show_message.call_count == 2
                
                # Check success message
                final_call = self.cli.interface.show_message.call_args_list[-1]
                assert "10 Dateien zur√ºck verschoben" in final_call[0][0]
                assert final_call[1]["message_type"] == "success"
    
    def test_execute_undo_no_history(self):
        """Test undo with no history."""
        mock_context = Mock()
        mock_orchestrator = Mock()
        mock_orchestrator.execute_undo.return_value = {
            "status": "no_history",
            "message": "Keine History gefunden"
        }
        
        with patch('folder_extractor.cli.app.FileExtractor'):
            with patch('folder_extractor.cli.app.ExtractionOrchestrator', return_value=mock_orchestrator):
                result = self.cli._execute_undo("/test/path", mock_context)
                
                assert result == 1
                
                # Check warning message shown
                final_call = self.cli.interface.show_message.call_args_list[-1]
                assert final_call[1]["message_type"] == "warning"


def test_main_function():
    """Test main entry point function."""
    with patch('folder_extractor.cli.app.FolderExtractorCLI') as mock_cli_class:
        mock_cli = Mock()
        mock_cli.run.return_value = 0
        mock_cli_class.return_value = mock_cli
        
        # Test with no arguments
        result = main()
        assert result == 0
        mock_cli.run.assert_called_once_with(None)
        
        # Test with arguments
        mock_cli.run.reset_mock()
        test_args = ['--dry-run', '--depth', '3']
        result = main(test_args)
        assert result == 0
        mock_cli.run.assert_called_once_with(test_args)


def test_main_entry_point():
    """Test __main__ entry point."""
    # Test that main can be called when module is run directly
    test_module = "folder_extractor.cli.app"
    
    with patch(f'{test_module}.main', return_value=0) as mock_main:
        # Simulate the module being run as __main__
        with patch.dict('sys.modules', {test_module: MagicMock(__name__='__main__')}):
            # The actual code that would run
            if sys.modules[test_module].__name__ == '__main__':
                result = mock_main()
                assert result == 0
</file>

<file path="tests/unit/test_cli_interface.py">
"""
Unit tests for CLI interface module.
"""
import pytest
import sys
import time
from unittest.mock import Mock, patch, MagicMock
from io import StringIO

from folder_extractor.cli.interface import (
    ConsoleInterface, KeyboardHandler, create_console_interface
)
from folder_extractor.config.settings import settings


class TestConsoleInterface:
    """Test ConsoleInterface class."""
    
    def setup_method(self):
        """Set up test fixtures."""
        self.interface = ConsoleInterface()
        # Reset settings
        settings.reset_to_defaults()
    
    def test_show_welcome(self):
        """Test showing welcome message."""
        with patch('sys.stdout', new=StringIO()) as mock_stdout:
            self.interface.show_welcome()
            output = mock_stdout.getvalue()
            
            assert "Folder Extractor" in output
            assert "v" in output  # Version
            assert "Von" in output  # Author
    
    def test_show_message_types(self):
        """Test showing different message types."""
        # Mock supports_color to return True so we get colored output
        with patch('folder_extractor.utils.terminal.supports_color', return_value=True):
            test_cases = [
                ("info", "Info message", "\033[36m"),      # Cyan
                ("success", "Success message", "\033[32m"), # Green
                ("error", "Error message", "\033[31m"),     # Red
                ("warning", "Warning message", "\033[33m"),  # Yellow
            ]
            
            for msg_type, message, color_code in test_cases:
                with patch('sys.stdout', new=StringIO()) as mock_stdout:
                    self.interface.show_message(message, message_type=msg_type)
                    output = mock_stdout.getvalue()
                    
                    # Check message is displayed
                    assert message in output
                    # Check color code is applied (if not quiet mode)
                    if not settings.get("quiet", False):
                        assert color_code in output
    
    def test_show_message_quiet_mode(self):
        """Test message suppression in quiet mode."""
        settings.set("quiet", True)
        
        with patch('sys.stdout', new=StringIO()) as mock_stdout:
            self.interface.show_message("Test message")
            output = mock_stdout.getvalue()
            
            # No output in quiet mode
            assert output == ""
    
    def test_confirm_operation_dry_run(self):
        """Test confirmation in dry run mode."""
        settings.set("dry_run", True)
        
        # Should auto-confirm in dry run
        result = self.interface.confirm_operation(10)
        assert result is True
    
    def test_confirm_operation_auto_confirm(self):
        """Test confirmation with auto-confirm disabled."""
        settings.set("confirm_operations", False)
        
        # Should auto-confirm when disabled
        result = self.interface.confirm_operation(10)
        assert result is True
    
    def test_confirm_operation_user_input(self):
        """Test user confirmation input."""
        settings.set("confirm_operations", True)
        
        # Test different positive responses
        positive_responses = ['j', 'ja', 'y', 'yes']
        
        for response in positive_responses:
            with patch('builtins.input', return_value=response):
                with patch('sys.stdout', new=StringIO()):
                    result = self.interface.confirm_operation(10)
                    assert result is True
        
        # Test negative responses
        negative_responses = ['n', 'nein', 'no', '', 'x']
        
        for response in negative_responses:
            with patch('builtins.input', return_value=response):
                with patch('sys.stdout', new=StringIO()):
                    result = self.interface.confirm_operation(10)
                    assert result is False
    
    def test_confirm_operation_interrupt(self):
        """Test confirmation with keyboard interrupt."""
        with patch('builtins.input', side_effect=KeyboardInterrupt):
            with patch('sys.stdout', new=StringIO()):
                result = self.interface.confirm_operation(10)
                assert result is False
    
    def test_show_progress(self):
        """Test progress display."""
        with patch('sys.stdout', new=StringIO()) as mock_stdout:
            # First update should show
            self.interface.show_progress(1, 10, "/path/to/file.txt")
            output1 = mock_stdout.getvalue()
            assert "file.txt" in output1
            
            # Rate limiting - immediate second call shouldn't show
            mock_stdout.truncate(0)
            mock_stdout.seek(0)
            self.interface.show_progress(2, 10, "/path/to/file2.txt")
            output2 = mock_stdout.getvalue()
            
            # Depending on timing, might be empty due to rate limiting
            # But after waiting, should show
            time.sleep(0.15)
            self.interface.show_progress(3, 10, "/path/to/file3.txt")
            output3 = mock_stdout.getvalue()
            assert "file3.txt" in output3
    
    def test_show_progress_with_error(self):
        """Test progress display with error."""
        with patch('sys.stdout', new=StringIO()) as mock_stdout:
            self.interface.show_progress(
                5, 10, 
                "/path/to/file.txt", 
                error="Permission denied"
            )
            output = mock_stdout.getvalue()
            
            assert "file.txt" in output
            assert "Permission denied" in output
    
    def test_show_progress_quiet_mode(self):
        """Test progress suppression in quiet mode."""
        settings.set("quiet", True)
        
        with patch('sys.stdout', new=StringIO()) as mock_stdout:
            self.interface.show_progress(1, 10, "/path/to/file.txt")
            output = mock_stdout.getvalue()
            
            # No output in quiet mode
            assert output == ""
    
    def test_show_summary_aborted(self):
        """Test showing summary for aborted operation."""
        with patch('sys.stdout', new=StringIO()) as mock_stdout:
            results = {"aborted": True}
            self.interface.show_summary(results)
            output = mock_stdout.getvalue()
            
            assert "abgebrochen" in output.lower()
    
    def test_show_summary_no_files(self):
        """Test showing summary when no files found."""
        with patch('sys.stdout', new=StringIO()) as mock_stdout:
            results = {
                "status": "no_files",
                "message": "Keine Dateien gefunden"
            }
            self.interface.show_summary(results)
            output = mock_stdout.getvalue()
            
            assert "Keine Dateien gefunden" in output
    
    def test_show_summary_success(self):
        """Test showing summary for successful operation."""
        with patch('sys.stdout', new=StringIO()) as mock_stdout:
            results = {
                "status": "success",
                "moved": 15,
                "duplicates": 3,
                "errors": 1,
                "created_folders": ["PDF", "BILDER"],
                "removed_directories": 5
            }
            self.interface.show_summary(results)
            output = mock_stdout.getvalue()
            
            # Check move summary
            assert "15" in output
            assert "3" in output
            assert "1" in output
            
            # Check created folders
            assert "PDF" in output
            assert "BILDER" in output
            
            # Check removed directories
            assert "5" in output
            assert "leere" in output.lower()
            
            # Check undo hint
            assert "r√ºckg√§ngig" in output.lower()


class TestKeyboardHandler:
    """Test KeyboardHandler class."""
    
    def test_init(self):
        """Test keyboard handler initialization."""
        mock_callback = Mock()
        handler = KeyboardHandler(mock_callback)
        
        assert handler.abort_callback == mock_callback
        assert handler.running is False
        assert handler.thread is None
    
    @pytest.mark.skipif(sys.platform == 'win32', reason="Not supported on Windows")
    def test_start_stop(self):
        """Test starting and stopping keyboard handler."""
        mock_callback = Mock()
        handler = KeyboardHandler(mock_callback)
        
        # Test basic state management
        assert handler.running is False
        assert handler.thread is None
        
        with patch('sys.stdout', new=StringIO()) as mock_stdout:
            # Start handler
            handler.start()
            
            # Check hint message
            output = mock_stdout.getvalue()
            assert "ESC" in output
            
            # Check running flag was set
            assert handler.running is True
            
            # Stop handler
            handler.stop()
            
            # Check stopped
            assert handler.running is False
    
    def test_windows_skip(self):
        """Test that keyboard handler skips on Windows."""
        mock_callback = Mock()
        handler = KeyboardHandler(mock_callback)
        
        with patch('sys.platform', 'win32'):
            handler.start()
            
            # Should not start thread on Windows
            assert handler.thread is None
    
    @pytest.mark.skipif(sys.platform == 'win32', reason="Not supported on Windows")
    def test_esc_detection(self):
        """Test ESC key detection logic."""
        mock_callback = Mock()
        handler = KeyboardHandler(mock_callback)
        
        # Test the callback mechanism directly
        # The actual _listen method is complex with threading
        # So we test the core logic
        handler.abort_callback()
        mock_callback.assert_called_once()


def test_create_console_interface():
    """Test interface factory function."""
    interface = create_console_interface()
    assert isinstance(interface, ConsoleInterface)
</file>

<file path="tests/unit/test_cli_parser.py">
"""
Unit tests for CLI parser module.
"""
import pytest
import sys
from io import StringIO
from unittest.mock import patch

from folder_extractor.cli.parser import ArgumentParser, create_parser


class TestArgumentParser:
    """Test ArgumentParser class."""
    
    def setup_method(self):
        """Set up test fixtures."""
        self.parser = create_parser()
    
    def test_default_arguments(self):
        """Test parsing with default arguments."""
        args = self.parser.parse_args([])
        
        assert args.depth == 0
        assert args.dry_run is False
        assert args.sort_by_type is False
        assert args.undo is False
        assert args.include_hidden is False
        assert args.type is None
        assert args.domain is None
    
    def test_depth_argument(self):
        """Test depth argument parsing."""
        # Valid depth
        args = self.parser.parse_args(['--depth', '5'])
        assert args.depth == 5
        
        args = self.parser.parse_args(['-d', '10'])
        assert args.depth == 10
        
        # Invalid depth
        with pytest.raises(SystemExit):
            self.parser.parse_args(['--depth', '-1'])
        
        with pytest.raises(SystemExit):
            self.parser.parse_args(['--depth', 'abc'])
    
    def test_type_argument(self):
        """Test type argument parsing."""
        args = self.parser.parse_args(['--type', 'pdf,jpg,mp3'])
        assert args.type == 'pdf,jpg,mp3'
        
        args = self.parser.parse_args(['-t', 'txt'])
        assert args.type == 'txt'
    
    def test_boolean_flags(self):
        """Test boolean flag arguments."""
        # Dry run
        args = self.parser.parse_args(['--dry-run'])
        assert args.dry_run is True
        
        args = self.parser.parse_args(['-n'])
        assert args.dry_run is True
        
        # Sort by type
        args = self.parser.parse_args(['--sort-by-type'])
        assert args.sort_by_type is True
        
        args = self.parser.parse_args(['-s'])
        assert args.sort_by_type is True
        
        # Undo
        args = self.parser.parse_args(['--undo'])
        assert args.undo is True
        
        args = self.parser.parse_args(['-u'])
        assert args.undo is True
        
        # Include hidden
        args = self.parser.parse_args(['--include-hidden'])
        assert args.include_hidden is True
    
    def test_domain_argument(self):
        """Test domain argument parsing."""
        args = self.parser.parse_args(['--domain', 'youtube.com,github.com'])
        assert args.domain == 'youtube.com,github.com'
    
    def test_help_flag(self):
        """Test help flag handling."""
        with patch('sys.stdout', new=StringIO()) as mock_stdout:
            with pytest.raises(SystemExit) as exc_info:
                self.parser.parse_args(['--help'])
            
            assert exc_info.value.code == 0
            output = mock_stdout.getvalue()
            assert "Folder Extractor" in output
            assert "Verwendung:" in output
    
    def test_version_flag(self):
        """Test version flag handling."""
        with patch('sys.stdout', new=StringIO()) as mock_stdout:
            with pytest.raises(SystemExit) as exc_info:
                self.parser.parse_args(['--version'])
            
            assert exc_info.value.code == 0
            output = mock_stdout.getvalue()
            assert "folder-extractor" in output
            assert "Von" in output
    
    def test_combined_arguments(self):
        """Test combining multiple arguments."""
        args = self.parser.parse_args([
            '--depth', '3',
            '--type', 'pdf,doc',
            '--dry-run',
            '--sort-by-type',
            '--include-hidden',
            '--domain', 'example.com'
        ])
        
        assert args.depth == 3
        assert args.type == 'pdf,doc'
        assert args.dry_run is True
        assert args.sort_by_type is True
        assert args.include_hidden is True
        assert args.domain == 'example.com'
    
    def test_short_and_long_forms(self):
        """Test that short and long forms work the same."""
        # Test equivalent arguments
        args1 = self.parser.parse_args(['-d', '5', '-t', 'pdf', '-n', '-s', '-u'])
        args2 = self.parser.parse_args([
            '--depth', '5', 
            '--type', 'pdf',
            '--dry-run',
            '--sort-by-type',
            '--undo'
        ])
        
        assert args1.depth == args2.depth
        assert args1.type == args2.type
        assert args1.dry_run == args2.dry_run
        assert args1.sort_by_type == args2.sort_by_type
        assert args1.undo == args2.undo
</file>

<file path="tests/unit/test_core_extractor.py">
"""
Unit tests for the core extractor module.
"""
import os
import pytest
from pathlib import Path
import tempfile
import threading
from unittest.mock import Mock, MagicMock, patch

from folder_extractor.core.extractor import (
    FileExtractor,
    ExtractionOrchestrator,
    SecurityError,
    ExtractionError
)
from folder_extractor.config.settings import settings
from folder_extractor.core.file_discovery import FileDiscovery
from folder_extractor.core.file_operations import FileOperations, HistoryManager


class TestFileExtractor:
    """Test FileExtractor class."""
    
    def setup_method(self):
        """Set up test fixtures."""
        # Reset settings
        settings.reset_to_defaults()
        self.extractor = FileExtractor()
    
    def test_validate_security_safe_path(self):
        """Test security validation with safe path."""
        home = Path.home()
        safe_path = str(home / "Desktop" / "test")
        
        # Create directory
        Path(safe_path).mkdir(parents=True, exist_ok=True)
        
        # Should not raise
        self.extractor.validate_security(safe_path)
        
        # Cleanup
        Path(safe_path).rmdir()
    
    def test_validate_security_unsafe_path(self):
        """Test security validation with unsafe path."""
        unsafe_paths = ["/etc", "/usr/bin", str(Path.home())]
        
        for path in unsafe_paths:
            with pytest.raises(SecurityError):
                self.extractor.validate_security(path)
    
    def test_discover_files_basic(self):
        """Test basic file discovery."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create test structure
            subdir = Path(temp_dir) / "subdir"
            subdir.mkdir()
            (subdir / "file1.txt").touch()
            (subdir / "file2.pdf").touch()
            
            # Mock file discovery to return our files
            mock_discovery = Mock()
            mock_discovery.find_files.return_value = [
                str(subdir / "file1.txt"),
                str(subdir / "file2.pdf")
            ]
            
            extractor = FileExtractor(file_discovery=mock_discovery)
            files = extractor.discover_files(temp_dir)
            
            assert len(files) == 2
            mock_discovery.find_files.assert_called_once()
    
    def test_filter_by_domain(self):
        """Test domain filtering for weblink files."""
        files = [
            "/path/to/file.txt",
            "/path/to/youtube.url",
            "/path/to/github.webloc",
            "/path/to/other.url"
        ]
        
        # Mock domain checking
        mock_discovery = Mock()
        mock_discovery.check_weblink_domain.side_effect = [
            True,   # youtube.url matches
            False,  # github.webloc doesn't match
            False   # other.url doesn't match
        ]
        
        extractor = FileExtractor(file_discovery=mock_discovery)
        filtered = extractor.filter_by_domain(files, ["youtube.com"])
        
        # Should keep non-weblink files and matching weblinks
        assert len(filtered) == 2
        assert "/path/to/file.txt" in filtered
        assert "/path/to/youtube.url" in filtered
    
    def test_extract_files_normal_mode(self):
        """Test file extraction in normal mode."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create source files
            source_dir = Path(temp_dir) / "source"
            source_dir.mkdir()
            files = []
            for i in range(3):
                file_path = source_dir / f"file{i}.txt"
                file_path.touch()
                files.append(str(file_path))
            
            # Extract files
            result = self.extractor.extract_files(files, temp_dir)
            
            assert result["moved"] == 3
            assert result["errors"] == 0
            assert result["duplicates"] == 0
            assert len(result["history"]) == 3
            assert result["created_folders"] == []
    
    def test_extract_files_sort_by_type(self):
        """Test file extraction with sort by type."""
        settings.set("sort_by_type", True)
        
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create source files
            source_dir = Path(temp_dir) / "source"
            source_dir.mkdir()
            files = [
                str((source_dir / "doc.pdf").touch() or source_dir / "doc.pdf"),
                str((source_dir / "img.jpg").touch() or source_dir / "img.jpg"),
                str((source_dir / "script.py").touch() or source_dir / "script.py")
            ]
            
            # Extract files
            result = self.extractor.extract_files(files, temp_dir)
            
            assert result["moved"] == 3
            assert "PDF" in result["created_folders"]
            assert "JPEG" in result["created_folders"]
            assert "PYTHON" in result["created_folders"]
    
    def test_extract_files_dry_run(self):
        """Test extraction in dry run mode."""
        settings.set("dry_run", True)
        
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create source file
            source_file = Path(temp_dir) / "source.txt"
            source_file.touch()
            
            # Extract
            result = self.extractor.extract_files([str(source_file)], temp_dir)
            
            # File should still exist in original location
            assert source_file.exists()
            assert result["moved"] == 1
            assert len(result["history"]) == 0  # No history in dry run
    
    def test_undo_last_operation(self):
        """Test undo functionality."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create history
            operations = [{
                "original_pfad": str(Path(temp_dir) / "original" / "file.txt"),
                "neuer_pfad": str(Path(temp_dir) / "new" / "file.txt"),
                "original_name": "file.txt",
                "neuer_name": "file.txt",
                "zeitstempel": "2024-01-01T12:00:00"
            }]
            
            # Create the "moved" file
            new_dir = Path(temp_dir) / "new"
            new_dir.mkdir()
            (new_dir / "file.txt").write_text("content")
            
            # Save history
            HistoryManager.save_history(operations, temp_dir)
            
            # Undo
            restored = self.extractor.undo_last_operation(temp_dir)
            
            assert restored == 1
            assert (Path(temp_dir) / "original" / "file.txt").exists()
            assert not (new_dir / "file.txt").exists()
    
    def test_undo_no_history(self):
        """Test undo when no history exists."""
        with tempfile.TemporaryDirectory() as temp_dir:
            restored = self.extractor.undo_last_operation(temp_dir)
            assert restored == 0


class TestExtractionOrchestrator:
    """Test ExtractionOrchestrator class."""
    
    def setup_method(self):
        """Set up test fixtures."""
        settings.reset_to_defaults()
        self.mock_extractor = Mock()
        self.orchestrator = ExtractionOrchestrator(self.mock_extractor)
    
    def test_execute_extraction_success(self):
        """Test successful extraction workflow."""
        # Set up mocks
        self.mock_extractor.discover_files.return_value = [
            "/file1.txt", "/file2.txt"
        ]
        self.mock_extractor.extract_files.return_value = {
            "moved": 2,
            "errors": 0,
            "duplicates": 0,
            "history": [],
            "created_folders": [],
            "removed_directories": 0
        }
        
        # Execute
        result = self.orchestrator.execute_extraction("/safe/path")
        
        assert result["status"] == "success"
        assert result["total_files"] == 2
        assert result["moved"] == 2
        
        self.mock_extractor.validate_security.assert_called_once_with("/safe/path")
        self.mock_extractor.discover_files.assert_called_once()
        self.mock_extractor.extract_files.assert_called_once()
    
    def test_execute_extraction_no_files(self):
        """Test extraction when no files found."""
        self.mock_extractor.discover_files.return_value = []
        
        result = self.orchestrator.execute_extraction("/safe/path")
        
        assert result["status"] == "no_files"
        assert "Keine Dateien" in result["message"]
    
    def test_execute_extraction_cancelled(self):
        """Test extraction when user cancels."""
        self.mock_extractor.discover_files.return_value = ["/file.txt"]
        
        # Confirmation callback returns False
        confirmation = Mock(return_value=False)
        
        result = self.orchestrator.execute_extraction(
            "/safe/path",
            confirmation_callback=confirmation
        )
        
        assert result["status"] == "cancelled"
        confirmation.assert_called_once_with(1)
    
    def test_execute_extraction_security_error(self):
        """Test extraction with security error."""
        self.mock_extractor.validate_security.side_effect = SecurityError("Unsafe!")
        
        with pytest.raises(SecurityError):
            self.orchestrator.execute_extraction("/unsafe/path")
    
    def test_execute_undo_success(self):
        """Test successful undo operation."""
        self.mock_extractor.undo_last_operation.return_value = 5
        
        result = self.orchestrator.execute_undo("/safe/path")
        
        assert result["status"] == "success"
        assert result["restored"] == 5
        assert "5 Dateien" in result["message"]
    
    def test_execute_undo_no_history(self):
        """Test undo when no history exists."""
        self.mock_extractor.undo_last_operation.return_value = 0
        
        result = self.orchestrator.execute_undo("/safe/path")
        
        assert result["status"] == "no_history"
        assert result["restored"] == 0


class TestIntegration:
    """Integration tests with real components."""
    
    def test_full_extraction_workflow(self):
        """Test complete extraction workflow."""
        # Use safe test directory
        home = Path.home()
        test_dir = home / "Desktop" / "extractor_test"
        test_dir.mkdir(exist_ok=True)
        
        try:
            # Create test structure
            source_dir = test_dir / "source"
            source_dir.mkdir()
            
            # Create test files
            (source_dir / "doc.pdf").touch()
            (source_dir / "img.jpg").touch()
            (source_dir / ".hidden.txt").touch()
            
            # Create extractor
            extractor = FileExtractor()
            orchestrator = ExtractionOrchestrator(extractor)
            
            # Execute extraction
            result = orchestrator.execute_extraction(str(test_dir))
            
            assert result["status"] == "success"
            assert result["moved"] == 2  # Hidden file excluded by default
            assert result["errors"] == 0
            
            # Check files were moved
            assert (test_dir / "doc.pdf").exists()
            assert (test_dir / "img.jpg").exists()
            assert not (source_dir / "doc.pdf").exists()
            assert not (source_dir / "img.jpg").exists()
            
            # Test undo
            undo_result = orchestrator.execute_undo(str(test_dir))
            assert undo_result["restored"] == 2
            
            # Files should be back
            assert (source_dir / "doc.pdf").exists()
            assert (source_dir / "img.jpg").exists()
            
        finally:
            # Cleanup
            import shutil
            if test_dir.exists():
                shutil.rmtree(test_dir)
    
    def test_extraction_with_abort(self):
        """Test extraction with abort signal."""
        abort_signal = threading.Event()
        
        # Create extractor with abort signal
        extractor = FileExtractor(abort_signal=abort_signal)
        
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create many files
            source_dir = Path(temp_dir) / "source"
            source_dir.mkdir()
            files = []
            for i in range(100):
                file_path = source_dir / f"file{i}.txt"
                file_path.touch()
                files.append(str(file_path))
            
            # Set abort signal immediately
            abort_signal.set()
            
            # Extract - should be interrupted
            result = extractor.extract_files(files, temp_dir)
            
            # Should have processed fewer files
            assert result["moved"] < len(files)
</file>

<file path="tests/unit/test_core_file_discovery.py">
"""
Unit tests for the core file discovery module.
"""
import os
import pytest
from pathlib import Path
import tempfile
import threading
import xml.etree.ElementTree as ET

from folder_extractor.core.file_discovery import (
    FileDiscovery,
    FileFilter
)


class TestFileDiscovery:
    """Test FileDiscovery class."""
    
    def setup_method(self):
        """Set up test fixtures."""
        self.file_discovery = FileDiscovery()
    
    def test_find_files_basic(self):
        """Test basic file discovery."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create file structure
            (Path(temp_dir) / "subdir1").mkdir()
            (Path(temp_dir) / "subdir2").mkdir()
            
            # Create files
            (Path(temp_dir) / "subdir1" / "file1.txt").touch()
            (Path(temp_dir) / "subdir1" / "file2.pdf").touch()
            (Path(temp_dir) / "subdir2" / "file3.txt").touch()
            
            # Find files
            files = self.file_discovery.find_files(temp_dir)
            
            assert len(files) == 3
            filenames = [os.path.basename(f) for f in files]
            assert "file1.txt" in filenames
            assert "file2.pdf" in filenames
            assert "file3.txt" in filenames
    
    def test_find_files_max_depth(self):
        """Test file discovery with depth limit."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create nested structure
            deep_path = Path(temp_dir) / "level1" / "level2" / "level3"
            deep_path.mkdir(parents=True)
            
            # Create files at different levels
            (Path(temp_dir) / "level1" / "file1.txt").touch()
            (Path(temp_dir) / "level1" / "level2" / "file2.txt").touch()
            (deep_path / "file3.txt").touch()
            
            # Test different depths
            files_depth1 = self.file_discovery.find_files(temp_dir, max_depth=1)
            assert len(files_depth1) == 1  # Only file1.txt
            
            files_depth2 = self.file_discovery.find_files(temp_dir, max_depth=2)
            assert len(files_depth2) == 2  # file1.txt and file2.txt
            
            files_unlimited = self.file_discovery.find_files(temp_dir, max_depth=0)
            assert len(files_unlimited) == 3  # All files
    
    def test_find_files_type_filter(self):
        """Test file discovery with type filtering."""
        with tempfile.TemporaryDirectory() as temp_dir:
            subdir = Path(temp_dir) / "subdir"
            subdir.mkdir()
            
            # Create various file types
            (subdir / "doc.txt").touch()
            (subdir / "doc.pdf").touch()
            (subdir / "image.jpg").touch()
            (subdir / "data.json").touch()
            
            # Filter for specific types
            txt_files = self.file_discovery.find_files(
                temp_dir, file_type_filter=[".txt"]
            )
            assert len(txt_files) == 1
            assert txt_files[0].endswith("doc.txt")
            
            # Multiple types
            doc_files = self.file_discovery.find_files(
                temp_dir, file_type_filter=[".txt", ".pdf"]
            )
            assert len(doc_files) == 2
    
    def test_find_files_hidden_files(self):
        """Test handling of hidden files."""
        with tempfile.TemporaryDirectory() as temp_dir:
            subdir = Path(temp_dir) / "subdir"
            subdir.mkdir()
            hidden_dir = Path(temp_dir) / ".hidden"
            hidden_dir.mkdir()
            
            # Create files
            (subdir / "visible.txt").touch()
            (subdir / ".hidden.txt").touch()
            (hidden_dir / "file.txt").touch()
            
            # Without include_hidden
            files = self.file_discovery.find_files(temp_dir, include_hidden=False)
            assert len(files) == 1
            assert files[0].endswith("visible.txt")
            
            # With include_hidden
            files = self.file_discovery.find_files(temp_dir, include_hidden=True)
            assert len(files) == 3
    
    def test_find_files_abort_signal(self):
        """Test abort signal handling."""
        abort_signal = threading.Event()
        file_discovery = FileDiscovery(abort_signal)
        
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create many subdirectories
            for i in range(10):
                subdir = Path(temp_dir) / f"subdir{i}"
                subdir.mkdir()
                (subdir / "file.txt").touch()
            
            # Set abort signal
            abort_signal.set()
            
            # Should return fewer files due to abort
            files = file_discovery.find_files(temp_dir)
            assert len(files) < 10
    
    def test_check_url_file(self):
        """Test checking Windows .url files."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create .url file
            url_file = Path(temp_dir) / "youtube.url"
            url_file.write_text(
                "[InternetShortcut]\n"
                "URL=https://www.youtube.com/watch?v=123\n"
                "IconIndex=0\n"
            )
            
            # Check domain
            assert self.file_discovery.check_weblink_domain(
                str(url_file), ["youtube.com"]
            ) is True
            
            assert self.file_discovery.check_weblink_domain(
                str(url_file), ["github.com"]
            ) is False
    
    def test_check_webloc_file(self):
        """Test checking macOS .webloc files."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create .webloc file
            webloc_file = Path(temp_dir) / "github.webloc"
            
            # Create plist structure
            plist = ET.Element("plist", version="1.0")
            dict_elem = ET.SubElement(plist, "dict")
            ET.SubElement(dict_elem, "key").text = "URL"
            ET.SubElement(dict_elem, "string").text = "https://github.com/user/repo"
            
            # Write XML
            tree = ET.ElementTree(plist)
            tree.write(str(webloc_file), encoding="UTF-8", xml_declaration=True)
            
            # Check domain
            assert self.file_discovery.check_weblink_domain(
                str(webloc_file), ["github.com"]
            ) is True
            
            assert self.file_discovery.check_weblink_domain(
                str(webloc_file), ["youtube.com"]
            ) is False
    
    def test_check_weblink_nonexistent(self):
        """Test checking non-existent weblink files."""
        result = self.file_discovery.check_weblink_domain(
            "/nonexistent/file.url", ["any.com"]
        )
        assert result is False
    
    def test_check_weblink_invalid_format(self):
        """Test handling of invalid weblink files."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Invalid .url file
            invalid_url = Path(temp_dir) / "invalid.url"
            invalid_url.write_text("Not a valid URL file")
            
            assert self.file_discovery.check_weblink_domain(
                str(invalid_url), ["any.com"]
            ) is False
            
            # Invalid .webloc file
            invalid_webloc = Path(temp_dir) / "invalid.webloc"
            invalid_webloc.write_text("Not valid XML")
            
            assert self.file_discovery.check_weblink_domain(
                str(invalid_webloc), ["any.com"]
            ) is False


class TestFileFilter:
    """Test FileFilter class."""
    
    def test_extension_filter(self):
        """Test extension filtering."""
        filter = FileFilter()
        filter.add_extension_filter([".txt", ".pdf"])
        
        assert filter.apply("/path/to/file.txt") is True
        assert filter.apply("/path/to/file.pdf") is True
        assert filter.apply("/path/to/file.jpg") is False
    
    def test_size_filter(self):
        """Test size filtering."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create files of different sizes
            small_file = Path(temp_dir) / "small.txt"
            small_file.write_text("small")  # 5 bytes
            
            large_file = Path(temp_dir) / "large.txt"
            large_file.write_text("x" * 1000)  # 1000 bytes
            
            # Test min size
            filter = FileFilter()
            filter.add_size_filter(min_size=100)
            
            assert filter.apply(str(small_file)) is False
            assert filter.apply(str(large_file)) is True
            
            # Test max size
            filter = FileFilter()
            filter.add_size_filter(max_size=100)
            
            assert filter.apply(str(small_file)) is True
            assert filter.apply(str(large_file)) is False
            
            # Test range
            filter = FileFilter()
            filter.add_size_filter(min_size=10, max_size=500)
            
            assert filter.apply(str(small_file)) is False
            assert filter.apply(str(large_file)) is False
    
    def test_name_pattern_filter(self):
        """Test filename pattern filtering."""
        filter = FileFilter()
        filter.add_name_pattern_filter("test_*.txt")
        
        assert filter.apply("/path/to/test_file.txt") is True
        assert filter.apply("/path/to/test_123.txt") is True
        assert filter.apply("/path/to/other.txt") is False
        assert filter.apply("/path/to/test_file.pdf") is False
    
    def test_combined_filters(self):
        """Test combining multiple filters."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create test file
            test_file = Path(temp_dir) / "test_document.txt"
            test_file.write_text("x" * 500)  # 500 bytes
            
            # Create filter with multiple conditions
            filter = FileFilter()
            filter.add_extension_filter([".txt", ".pdf"])
            filter.add_size_filter(min_size=100, max_size=1000)
            filter.add_name_pattern_filter("test_*")
            
            # Should pass all filters
            assert filter.apply(str(test_file)) is True
            
            # Create file that fails one filter
            other_file = Path(temp_dir) / "other.txt"
            other_file.write_text("x" * 500)
            
            # Fails pattern filter
            assert filter.apply(str(other_file)) is False


class TestCompatibility:
    """Test compatibility with original functions."""
    
    def test_find_files_compatibility(self):
        """Test that new implementation matches old behavior."""
        from folder_extractor.main import finde_dateien as old_func
        file_discovery = FileDiscovery()
        
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create test structure
            (Path(temp_dir) / "subdir").mkdir()
            (Path(temp_dir) / ".hidden").mkdir()
            
            (Path(temp_dir) / "subdir" / "file.txt").touch()
            (Path(temp_dir) / "subdir" / ".hidden.txt").touch()
            (Path(temp_dir) / ".hidden" / "secret.txt").touch()
            
            # Compare results
            old_result = set(old_func(temp_dir, max_tiefe=0, include_hidden=False))
            new_result = set(file_discovery.find_files(temp_dir, max_depth=0, 
                                                      include_hidden=False))
            
            assert old_result == new_result
    
    def test_weblink_domain_compatibility(self):
        """Test that new implementation matches old behavior."""
        from folder_extractor.main import pruefe_weblink_domain as old_func
        file_discovery = FileDiscovery()
        
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create test .url file
            url_file = Path(temp_dir) / "test.url"
            url_file.write_text(
                "[InternetShortcut]\n"
                "URL=https://www.youtube.com/watch?v=123\n"
            )
            
            domains = ["youtube.com"]
            
            old_result = old_func(str(url_file), domains)
            new_result = file_discovery.check_weblink_domain(str(url_file), domains)
            
            assert old_result == new_result
</file>

<file path="tests/unit/test_core_file_operations.py">
"""
Unit tests for the core file operations module.
"""
import os
import pytest
from pathlib import Path
import tempfile
import shutil
import threading
from unittest.mock import Mock, patch

from folder_extractor.core.file_operations import (
    FileOperations,
    FileMover,
    HistoryManager,
    FileOperationError
)


class TestFileOperations:
    """Test FileOperations class."""
    
    def setup_method(self):
        """Set up test fixtures."""
        self.file_ops = FileOperations()
    
    def test_generate_unique_name_no_conflict(self):
        """Test unique name generation when no conflict."""
        with tempfile.TemporaryDirectory() as temp_dir:
            name = self.file_ops.generate_unique_name(temp_dir, "test.txt")
            assert name == "test.txt"
    
    def test_generate_unique_name_with_conflicts(self):
        """Test unique name generation with existing files."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create existing files
            Path(temp_dir, "test.txt").touch()
            Path(temp_dir, "test_1.txt").touch()
            
            name = self.file_ops.generate_unique_name(temp_dir, "test.txt")
            assert name == "test_2.txt"
    
    def test_generate_unique_name_no_extension(self):
        """Test unique name for files without extension."""
        with tempfile.TemporaryDirectory() as temp_dir:
            Path(temp_dir, "README").touch()
            
            name = self.file_ops.generate_unique_name(temp_dir, "README")
            assert name == "README_1"
    
    def test_move_file_success(self):
        """Test successful file move."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create source file
            source = Path(temp_dir, "source.txt")
            source.write_text("content")
            
            # Move file
            dest = Path(temp_dir, "dest.txt")
            result = self.file_ops.move_file(str(source), str(dest))
            
            assert result is True
            assert not source.exists()
            assert dest.exists()
            assert dest.read_text() == "content"
    
    def test_move_file_dry_run(self):
        """Test file move in dry run mode."""
        with tempfile.TemporaryDirectory() as temp_dir:
            source = Path(temp_dir, "source.txt")
            source.write_text("content")
            
            dest = Path(temp_dir, "dest.txt")
            result = self.file_ops.move_file(str(source), str(dest), dry_run=True)
            
            assert result is True
            assert source.exists()  # File should still exist
            assert not dest.exists()
    
    def test_move_file_cross_filesystem(self):
        """Test file move across filesystems (simulated)."""
        with tempfile.TemporaryDirectory() as temp_dir:
            source = Path(temp_dir, "source.txt")
            source.write_text("content")
            dest = Path(temp_dir, "dest.txt")
            
            # Mock os.rename to fail, forcing copy+delete
            with patch('os.rename', side_effect=OSError):
                result = self.file_ops.move_file(str(source), str(dest))
                
                assert result is True
                assert not source.exists()
                assert dest.exists()
                assert dest.read_text() == "content"
    
    def test_determine_type_folder_known_types(self):
        """Test folder determination for known file types."""
        assert self.file_ops.determine_type_folder("document.pdf") == "PDF"
        assert self.file_ops.determine_type_folder("script.py") == "PYTHON"
        assert self.file_ops.determine_type_folder("IMAGE.JPG") == "JPEG"
        assert self.file_ops.determine_type_folder("page.html") == "HTML"
    
    def test_determine_type_folder_unknown_type(self):
        """Test folder determination for unknown file types."""
        assert self.file_ops.determine_type_folder("file.xyz") == "XYZ"
        assert self.file_ops.determine_type_folder("data.custom") == "CUSTOM"
    
    def test_determine_type_folder_no_extension(self):
        """Test folder determination for files without extension."""
        assert self.file_ops.determine_type_folder("README") == "OHNE_ERWEITERUNG"
        assert self.file_ops.determine_type_folder("Makefile") == "OHNE_ERWEITERUNG"
    
    def test_remove_empty_directories(self):
        """Test removing empty directories."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create empty directories
            (Path(temp_dir) / "empty1").mkdir()
            (Path(temp_dir) / "empty2" / "nested").mkdir(parents=True)
            
            # Create non-empty directory
            non_empty = Path(temp_dir) / "non_empty"
            non_empty.mkdir()
            (non_empty / "file.txt").touch()
            
            removed = self.file_ops.remove_empty_directories(temp_dir)
            
            assert removed >= 3  # empty1, empty2, nested
            assert not (Path(temp_dir) / "empty1").exists()
            assert not (Path(temp_dir) / "empty2").exists()
            assert non_empty.exists()
    
    def test_remove_empty_directories_with_hidden(self):
        """Test removing directories with hidden files."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Directory with hidden file
            hidden_dir = Path(temp_dir) / "hidden_dir"
            hidden_dir.mkdir()
            (hidden_dir / ".hidden").touch()
            
            # Without include_hidden - should remove
            removed = self.file_ops.remove_empty_directories(temp_dir, include_hidden=False)
            assert removed == 1
            assert not hidden_dir.exists()
            
            # Recreate
            hidden_dir.mkdir()
            (hidden_dir / ".hidden").touch()
            
            # With include_hidden - should keep
            removed = self.file_ops.remove_empty_directories(temp_dir, include_hidden=True)
            assert removed == 0
            assert hidden_dir.exists()


class TestHistoryManager:
    """Test HistoryManager class."""
    
    def test_save_and_load_history(self):
        """Test saving and loading history."""
        with tempfile.TemporaryDirectory() as temp_dir:
            operations = [
                {
                    "original_pfad": "/old/path/file.txt",
                    "neuer_pfad": "/new/path/file.txt",
                    "original_name": "file.txt",
                    "neuer_name": "file.txt",
                    "zeitstempel": "2024-01-01T12:00:00"
                }
            ]
            
            # Save history
            history_file = HistoryManager.save_history(operations, temp_dir)
            assert os.path.exists(history_file)
            
            # Load history
            loaded = HistoryManager.load_history(temp_dir)
            assert loaded is not None
            assert "operationen" in loaded
            assert len(loaded["operationen"]) == 1
            assert loaded["operationen"][0]["original_pfad"] == "/old/path/file.txt"
    
    def test_load_nonexistent_history(self):
        """Test loading when no history exists."""
        with tempfile.TemporaryDirectory() as temp_dir:
            loaded = HistoryManager.load_history(temp_dir)
            assert loaded is None
    
    def test_delete_history(self):
        """Test deleting history file."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create history
            HistoryManager.save_history([{"test": "data"}], temp_dir)
            
            # Delete
            result = HistoryManager.delete_history(temp_dir)
            assert result is True
            
            # Try to load
            loaded = HistoryManager.load_history(temp_dir)
            assert loaded is None
            
            # Delete again - should return False
            result = HistoryManager.delete_history(temp_dir)
            assert result is False


class TestFileMover:
    """Test FileMover class."""
    
    def setup_method(self):
        """Set up test fixtures."""
        self.file_ops = FileOperations()
        self.file_mover = FileMover(self.file_ops)
    
    def test_move_files_success(self):
        """Test moving multiple files."""
        with tempfile.TemporaryDirectory() as temp_dir:
            source_dir = Path(temp_dir) / "source"
            source_dir.mkdir()
            dest_dir = Path(temp_dir) / "dest"
            dest_dir.mkdir()
            
            # Create test files
            files = []
            for i in range(3):
                file_path = source_dir / f"file{i}.txt"
                file_path.write_text(f"content{i}")
                files.append(str(file_path))
            
            # Move files
            moved, errors, duplicates, history = self.file_mover.move_files(
                files, str(dest_dir)
            )
            
            assert moved == 3
            assert errors == 0
            assert duplicates == 0
            assert len(history) == 3
            
            # Check files exist in destination
            for i in range(3):
                dest_file = dest_dir / f"file{i}.txt"
                assert dest_file.exists()
                assert dest_file.read_text() == f"content{i}"
    
    def test_move_files_with_duplicates(self):
        """Test moving files with duplicate names."""
        with tempfile.TemporaryDirectory() as temp_dir:
            source_dir = Path(temp_dir) / "source"
            source_dir.mkdir()
            dest_dir = Path(temp_dir) / "dest"
            dest_dir.mkdir()
            
            # Create existing file in destination
            (dest_dir / "duplicate.txt").write_text("existing")
            
            # Create source file with same name
            source_file = source_dir / "duplicate.txt"
            source_file.write_text("new")
            
            # Move file
            moved, errors, duplicates, history = self.file_mover.move_files(
                [str(source_file)], str(dest_dir)
            )
            
            assert moved == 1
            assert duplicates == 1
            assert (dest_dir / "duplicate_1.txt").exists()
            assert (dest_dir / "duplicate_1.txt").read_text() == "new"
    
    def test_move_files_with_abort(self):
        """Test aborting file move operation."""
        abort_signal = threading.Event()
        file_mover = FileMover(self.file_ops, abort_signal)
        
        with tempfile.TemporaryDirectory() as temp_dir:
            source_dir = Path(temp_dir) / "source"
            source_dir.mkdir()
            
            # Create many files
            files = []
            for i in range(100):
                file_path = source_dir / f"file{i}.txt"
                file_path.touch()
                files.append(str(file_path))
            
            # Set abort signal
            abort_signal.set()
            
            # Move files
            moved, errors, duplicates, history = file_mover.move_files(
                files, temp_dir
            )
            
            # Should have moved very few files
            assert moved < len(files)
    
    def test_move_files_sorted(self):
        """Test moving files sorted by type."""
        with tempfile.TemporaryDirectory() as temp_dir:
            source_dir = Path(temp_dir) / "source"
            source_dir.mkdir()
            dest_dir = Path(temp_dir) / "dest"
            dest_dir.mkdir()
            
            # Create various file types
            files = []
            test_files = [
                "document.pdf",
                "image.jpg",
                "script.py",
                "data.json"
            ]
            
            for filename in test_files:
                file_path = source_dir / filename
                file_path.touch()
                files.append(str(file_path))
            
            # Move files sorted
            moved, errors, duplicates, history, created_folders = \
                self.file_mover.move_files_sorted(files, str(dest_dir))
            
            assert moved == 4
            assert errors == 0
            assert "PDF" in created_folders
            assert "JPEG" in created_folders
            assert "PYTHON" in created_folders
            assert "JSON" in created_folders
            
            # Check files are in correct folders
            assert (dest_dir / "PDF" / "document.pdf").exists()
            assert (dest_dir / "JPEG" / "image.jpg").exists()
            assert (dest_dir / "PYTHON" / "script.py").exists()
            assert (dest_dir / "JSON" / "data.json").exists()
    
    def test_move_files_with_progress_callback(self):
        """Test progress callback during file move."""
        progress_calls = []
        
        def progress_callback(current, total, filepath, error=None):
            progress_calls.append({
                'current': current,
                'total': total,
                'filepath': filepath,
                'error': error
            })
        
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create test file
            test_file = Path(temp_dir) / "test.txt"
            test_file.touch()
            
            # Move with callback
            self.file_mover.move_files(
                [str(test_file)], temp_dir,
                progress_callback=progress_callback
            )
            
            assert len(progress_calls) == 1
            assert progress_calls[0]['current'] == 1
            assert progress_calls[0]['total'] == 1
            assert progress_calls[0]['error'] is None
</file>

<file path="tests/unit/test_file_operations.py">
"""
Unit tests for file operation functions.
"""
import os
import pytest
from pathlib import Path
import tempfile
import shutil

from folder_extractor.main import (
    generiere_eindeutigen_namen,
    ist_sicherer_pfad,
    entferne_leere_ordner,
    pruefe_weblink_domain
)


class TestUniqueNameGeneration:
    """Test unique name generation."""
    
    def test_no_conflict(self):
        """Test when no file exists."""
        with tempfile.TemporaryDirectory() as temp_dir:
            name = generiere_eindeutigen_namen(temp_dir, "test.txt")
            assert name == "test.txt"
    
    def test_single_conflict(self):
        """Test with one existing file."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create existing file
            Path(temp_dir, "test.txt").touch()
            
            name = generiere_eindeutigen_namen(temp_dir, "test.txt")
            assert name == "test_1.txt"
    
    def test_multiple_conflicts(self):
        """Test with multiple existing files."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create existing files
            Path(temp_dir, "test.txt").touch()
            Path(temp_dir, "test_1.txt").touch()
            Path(temp_dir, "test_2.txt").touch()
            
            name = generiere_eindeutigen_namen(temp_dir, "test.txt")
            assert name == "test_3.txt"
    
    def test_no_extension(self):
        """Test files without extension."""
        with tempfile.TemporaryDirectory() as temp_dir:
            Path(temp_dir, "README").touch()
            
            name = generiere_eindeutigen_namen(temp_dir, "README")
            assert name == "README_1"
    
    def test_multiple_dots(self):
        """Test files with multiple dots."""
        with tempfile.TemporaryDirectory() as temp_dir:
            Path(temp_dir, "archive.tar.gz").touch()
            
            name = generiere_eindeutigen_namen(temp_dir, "archive.tar.gz")
            assert name == "archive.tar_1.gz"
    
    def test_gap_in_numbering(self):
        """Test when there's a gap in numbering."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create files with gap
            Path(temp_dir, "test.txt").touch()
            Path(temp_dir, "test_1.txt").touch()
            Path(temp_dir, "test_3.txt").touch()  # Gap at _2
            
            name = generiere_eindeutigen_namen(temp_dir, "test.txt")
            assert name == "test_2.txt"
    
    def test_high_numbers(self):
        """Test with high numbered files."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create files up to 99
            Path(temp_dir, "test.txt").touch()
            for i in range(1, 100):
                Path(temp_dir, f"test_{i}.txt").touch()
            
            name = generiere_eindeutigen_namen(temp_dir, "test.txt")
            assert name == "test_100.txt"


class TestSafePathValidation:
    """Test safe path validation."""
    
    def test_desktop_paths(self):
        """Test Desktop paths are allowed."""
        home = Path.home()
        desktop_paths = [
            str(home / "Desktop"),
            str(home / "Desktop" / "subfolder"),
            str(home / "Desktop" / "deep" / "nested" / "folder")
        ]
        
        for path in desktop_paths:
            # Create path if needed
            Path(path).mkdir(parents=True, exist_ok=True)
            assert ist_sicherer_pfad(path) is True
            # Cleanup
            if "subfolder" in path or "deep" in path:
                parent = Path(path).parent
                while parent != home / "Desktop" and parent.exists():
                    if any(parent.iterdir()):
                        break
                    parent.rmdir()
                    parent = parent.parent
    
    def test_downloads_paths(self):
        """Test Downloads paths are allowed."""
        home = Path.home()
        downloads = home / "Downloads" / "test_folder"
        downloads.mkdir(parents=True, exist_ok=True)
        
        assert ist_sicherer_pfad(str(downloads)) is True
        
        # Cleanup
        downloads.rmdir()
    
    def test_documents_paths(self):
        """Test Documents paths are allowed."""
        home = Path.home()
        documents = home / "Documents" / "test_folder"
        documents.mkdir(parents=True, exist_ok=True)
        
        assert ist_sicherer_pfad(str(documents)) is True
        
        # Cleanup
        documents.rmdir()
    
    def test_unsafe_system_paths(self):
        """Test system paths are rejected."""
        unsafe_paths = [
            "/",
            "/etc",
            "/usr",
            "/bin",
            "/System",
            "C:\\Windows" if os.name == 'nt' else "/usr/bin",
            "C:\\Program Files" if os.name == 'nt' else "/opt"
        ]
        
        for path in unsafe_paths:
            assert ist_sicherer_pfad(path) is False
    
    def test_home_directory_rejected(self):
        """Test home directory itself is rejected."""
        assert ist_sicherer_pfad(str(Path.home())) is False
    
    def test_unsafe_home_subdirs(self):
        """Test unsafe home subdirectories are rejected."""
        home = Path.home()
        unsafe_subdirs = [
            str(home / "Library"),
            str(home / "Applications"),
            str(home / ".ssh"),
            str(home / ".config")
        ]
        
        for path in unsafe_subdirs:
            assert ist_sicherer_pfad(path) is False
    
    def test_case_sensitivity(self):
        """Test case variations of safe paths."""
        home = Path.home()
        
        # Different case variations
        variations = [
            str(home / "desktop" / "test"),
            str(home / "DESKTOP" / "test"),
            str(home / "DeskTop" / "test")
        ]
        
        for path in variations:
            # On case-insensitive systems, these might be valid
            # The function should handle this appropriately
            # Just ensure it doesn't crash
            result = ist_sicherer_pfad(path)
            assert isinstance(result, bool)


class TestEmptyFolderRemoval:
    """Test empty folder removal functionality."""
    
    def test_remove_single_empty_folder(self):
        """Test removing a single empty folder."""
        with tempfile.TemporaryDirectory() as temp_dir:
            empty_dir = Path(temp_dir) / "empty"
            empty_dir.mkdir()
            
            removed = entferne_leere_ordner(temp_dir)
            
            assert removed == 1
            assert not empty_dir.exists()
    
    def test_keep_non_empty_folders(self):
        """Test that non-empty folders are kept."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create folder with file
            non_empty = Path(temp_dir) / "non_empty"
            non_empty.mkdir()
            (non_empty / "file.txt").touch()
            
            removed = entferne_leere_ordner(temp_dir)
            
            assert removed == 0
            assert non_empty.exists()
    
    def test_nested_empty_folders(self):
        """Test removing nested empty folders."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create nested structure
            nested = Path(temp_dir) / "level1" / "level2" / "level3"
            nested.mkdir(parents=True)
            
            removed = entferne_leere_ordner(temp_dir)
            
            # Should remove all empty folders
            assert removed >= 3
            assert not (Path(temp_dir) / "level1").exists()
    
    def test_mixed_empty_and_full(self):
        """Test mixed empty and non-empty folders."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Empty folders
            (Path(temp_dir) / "empty1").mkdir()
            (Path(temp_dir) / "empty2").mkdir()
            
            # Non-empty folder
            full = Path(temp_dir) / "full"
            full.mkdir()
            (full / "file.txt").touch()
            
            # Nested with file at bottom
            nested = Path(temp_dir) / "nested" / "deep"
            nested.mkdir(parents=True)
            (nested / "file.txt").touch()
            
            removed = entferne_leere_ordner(temp_dir)
            
            assert removed == 2  # empty1 and empty2
            assert not (Path(temp_dir) / "empty1").exists()
            assert not (Path(temp_dir) / "empty2").exists()
            assert full.exists()
            assert nested.exists()
    
    def test_hidden_files_handling(self):
        """Test handling of hidden files."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Folder with only hidden file
            hidden_only = Path(temp_dir) / "hidden_only"
            hidden_only.mkdir()
            (hidden_only / ".hidden").touch()
            
            # Test without include_hidden - should remove
            removed = entferne_leere_ordner(temp_dir, include_hidden=False)
            assert removed == 1
            assert not hidden_only.exists()
            
            # Recreate for second test
            hidden_only.mkdir()
            (hidden_only / ".hidden").touch()
            
            # Test with include_hidden - should keep
            removed = entferne_leere_ordner(temp_dir, include_hidden=True)
            assert removed == 0
            assert hidden_only.exists()


class TestWebLinkDomainCheck:
    """Test web link domain checking."""
    
    def test_url_file_parsing(self):
        """Test parsing of .url files."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create .url file
            url_file = Path(temp_dir) / "test.url"
            url_file.write_text(
                "[InternetShortcut]\n"
                "URL=https://www.youtube.com/watch?v=123\n"
            )
            
            # Test matching domain
            assert pruefe_weblink_domain(str(url_file), ["youtube.com"]) is True
            assert pruefe_weblink_domain(str(url_file), ["github.com"]) is False
    
    def test_webloc_file_parsing(self):
        """Test parsing of .webloc files."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create .webloc file
            webloc_file = Path(temp_dir) / "test.webloc"
            webloc_file.write_text(
                '<?xml version="1.0" encoding="UTF-8"?>\n'
                '<plist version="1.0">\n'
                '<dict>\n'
                '    <key>URL</key>\n'
                '    <string>https://github.com/user/repo</string>\n'
                '</dict>\n'
                '</plist>\n'
            )
            
            # Test matching domain
            assert pruefe_weblink_domain(str(webloc_file), ["github.com"]) is True
            assert pruefe_weblink_domain(str(webloc_file), ["youtube.com"]) is False
    
    def test_invalid_file_format(self):
        """Test handling of invalid file formats."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create invalid file
            invalid_file = Path(temp_dir) / "test.url"
            invalid_file.write_text("This is not a valid URL file")
            
            # Should return False for invalid format
            assert pruefe_weblink_domain(str(invalid_file), ["any.com"]) is False
    
    def test_nonexistent_file(self):
        """Test handling of nonexistent files."""
        result = pruefe_weblink_domain("/nonexistent/file.url", ["any.com"])
        assert result is False
    
    def test_multiple_domains(self):
        """Test checking against multiple domains."""
        with tempfile.TemporaryDirectory() as temp_dir:
            url_file = Path(temp_dir) / "test.url"
            url_file.write_text(
                "[InternetShortcut]\n"
                "URL=https://stackoverflow.com/questions/123\n"
            )
            
            # Test with multiple allowed domains
            domains = ["github.com", "youtube.com", "stackoverflow.com"]
            assert pruefe_weblink_domain(str(url_file), domains) is True
            
            # Test with non-matching domains
            domains = ["github.com", "youtube.com"]
            assert pruefe_weblink_domain(str(url_file), domains) is False
</file>

<file path="tests/unit/test_new_parsers.py">
"""
Unit tests for the new parser module.
"""
import pytest
from folder_extractor.utils.parsers import (
    parse_file_types,
    parse_domains,
    parse_depth
)


class TestNewParsers:
    """Test the refactored parser functions."""
    
    def test_parse_file_types_compatibility(self):
        """Test that new parser maintains compatibility."""
        # Import both old and new
        from folder_extractor.main import parse_dateitypen as old_parse
        
        test_cases = [
            "pdf",
            "pdf,jpg,png",
            ".pdf,.jpg",
            "*.pdf,*.jpg",
            "PDF,JPG",
            "",
            None,
            "pdf, jpg, png"
        ]
        
        for test in test_cases:
            old_result = old_parse(test)
            new_result = parse_file_types(test)
            assert old_result == new_result, f"Mismatch for input '{test}'"
    
    def test_parse_domains_compatibility(self):
        """Test that new domain parser maintains compatibility."""
        from folder_extractor.main import parse_domains as old_parse
        
        test_cases = [
            "youtube.com",
            "youtube.com,github.com",
            "www.youtube.com",
            "",
            None,
            "youtube.com, github.com"
        ]
        
        for test in test_cases:
            old_result = old_parse(test)
            new_result = parse_domains(test)
            assert old_result == new_result, f"Mismatch for input '{test}'"
    
    def test_parse_depth_new_functionality(self):
        """Test the new depth parser."""
        # Valid depths
        assert parse_depth("0") == 0
        assert parse_depth("5") == 5
        assert parse_depth("100") == 100
        
        # Invalid depths
        with pytest.raises(ValueError, match="positive Zahl"):
            parse_depth("-1")
        
        with pytest.raises(ValueError, match="keine Zahl"):
            parse_depth("abc")
        
        with pytest.raises(ValueError, match="keine Zahl"):
            parse_depth("1.5")
</file>

<file path="tests/unit/test_progress.py">
"""
Unit tests for progress tracking module.
"""
import pytest
import time
from unittest.mock import Mock, MagicMock

from folder_extractor.core.progress import (
    ProgressInfo, ProgressTracker, BatchProgressTracker,
    CompositeProgressTracker
)


class TestProgressInfo:
    """Test ProgressInfo dataclass."""
    
    def test_init(self):
        """Test initialization."""
        info = ProgressInfo(current=5, total=10)
        assert info.current == 5
        assert info.total == 10
        assert info.current_file is None
        assert info.error is None
    
    def test_percentage(self):
        """Test percentage calculation."""
        # Normal case
        info = ProgressInfo(current=5, total=10)
        assert info.percentage == 50.0
        
        # Complete
        info = ProgressInfo(current=10, total=10)
        assert info.percentage == 100.0
        
        # Empty
        info = ProgressInfo(current=0, total=0)
        assert info.percentage == 100.0
    
    def test_is_complete(self):
        """Test completion check."""
        # Not complete
        info = ProgressInfo(current=5, total=10)
        assert not info.is_complete
        
        # Complete
        info = ProgressInfo(current=10, total=10)
        assert info.is_complete
        
        # Over complete
        info = ProgressInfo(current=11, total=10)
        assert info.is_complete


class TestProgressTracker:
    """Test ProgressTracker class."""
    
    def test_basic_tracking(self):
        """Test basic progress tracking."""
        callback = Mock()
        tracker = ProgressTracker(callback=callback)
        
        # Start tracking
        tracker.start(total=10)
        
        # Check initial callback
        callback.assert_called_once()
        info = callback.call_args[0][0]
        assert info.current == 0
        assert info.total == 10
        assert info.percentage == 0.0
        
        # Update progress
        callback.reset_mock()
        tracker.update(5, "/path/to/file.txt")
        
        # Should have called callback
        callback.assert_called_once()
        info = callback.call_args[0][0]
        assert info.current == 5
        assert info.total == 10
        assert info.current_file == "/path/to/file.txt"
        assert info.percentage == 50.0
        
        # Finish
        callback.reset_mock()
        tracker.finish()
        
        # Should call callback on finish
        callback.assert_called_once()
        info = callback.call_args[0][0]
        assert info.current == 10
        assert info.is_complete
    
    def test_increment(self):
        """Test increment functionality."""
        tracker = ProgressTracker()
        tracker.start(total=5)
        
        # Increment
        tracker.increment("/file1.txt")
        info = tracker.get_info()
        assert info.current == 1
        assert info.current_file == "/file1.txt"
        
        # Increment with error
        tracker.increment("/file2.txt", error="Permission denied")
        info = tracker.get_info()
        assert info.current == 2
        assert info.current_file == "/file2.txt"
        assert info.error == "Permission denied"
    
    def test_rate_limiting(self):
        """Test callback rate limiting."""
        callback = Mock()
        tracker = ProgressTracker(callback=callback, update_interval=0.1)
        
        tracker.start(total=100)
        callback.reset_mock()
        
        # Rapid updates
        for i in range(10):
            tracker.update(i)
        
        # Should have limited callbacks
        # (exact count depends on timing, but should be less than 10)
        assert callback.call_count < 10
        
        # Wait and update again
        time.sleep(0.15)
        tracker.update(50)
        
        # Should have called again after interval
        last_call_count = callback.call_count
        assert last_call_count > 0
    
    def test_time_tracking(self):
        """Test time tracking features."""
        tracker = ProgressTracker()
        tracker.start(total=10)
        
        # Check elapsed time
        time.sleep(0.05)
        elapsed = tracker.elapsed_time
        assert elapsed > 0.04
        assert elapsed < 0.1
        
        # Update progress
        tracker.update(5)
        
        # Check estimated remaining
        remaining = tracker.estimated_remaining_time
        assert remaining is not None
        assert remaining > 0
        
        # Finish and check final time
        tracker.finish()
        final_elapsed = tracker.elapsed_time
        assert final_elapsed > elapsed
    
    def test_statistics(self):
        """Test statistics generation."""
        tracker = ProgressTracker()
        tracker.start(total=10)
        
        time.sleep(0.01)
        tracker.update(5, error="Test error")
        
        stats = tracker.get_statistics()
        assert stats['current'] == 5
        assert stats['total'] == 10
        assert stats['percentage'] == 50.0
        assert stats['elapsed_time'] > 0
        assert stats['average_rate'] > 0
        assert stats['has_errors'] is True
    
    def test_boundary_conditions(self):
        """Test boundary conditions."""
        tracker = ProgressTracker()
        
        # Empty progress
        tracker.start(total=0)
        info = tracker.get_info()
        assert info.percentage == 100.0
        assert tracker.estimated_remaining_time is None
        
        # Update beyond total
        tracker.start(total=10)
        tracker.update(15)
        info = tracker.get_info()
        assert info.current == 10  # Clamped to total


class TestBatchProgressTracker:
    """Test BatchProgressTracker class."""
    
    def test_batch_tracking(self):
        """Test batch-specific functionality."""
        tracker = BatchProgressTracker(batch_size=5)
        tracker.start(total=20)
        
        # Process first batch
        tracker.start_batch()
        for i in range(5):
            if i == 2:
                tracker.increment(error="Error on item 3")
            else:
                tracker.increment()
        
        # End batch and check stats
        batch_stats = tracker.end_batch()
        assert batch_stats['items_processed'] == 5
        assert batch_stats['errors'] == 1
        assert batch_stats['success_rate'] == 80.0
        
        # Process second batch (all successful)
        tracker.start_batch()
        for i in range(5):
            tracker.increment()
        
        batch_stats = tracker.end_batch()
        assert batch_stats['items_processed'] == 5
        assert batch_stats['errors'] == 0
        assert batch_stats['success_rate'] == 100.0
    
    def test_empty_batch(self):
        """Test empty batch handling."""
        tracker = BatchProgressTracker()
        tracker.start(total=10)
        
        tracker.start_batch()
        batch_stats = tracker.end_batch()
        
        assert batch_stats['items_processed'] == 0
        assert batch_stats['errors'] == 0
        assert batch_stats['success_rate'] == 0


class TestCompositeProgressTracker:
    """Test CompositeProgressTracker class."""
    
    def test_composite_tracking(self):
        """Test delegating to multiple trackers."""
        # Create sub-trackers
        tracker1 = Mock(spec=ProgressTracker)
        tracker2 = Mock(spec=ProgressTracker)
        
        # Set up return value for get_info
        mock_info = ProgressInfo(current=5, total=10)
        tracker1.get_info.return_value = mock_info
        
        # Create composite
        composite = CompositeProgressTracker([tracker1, tracker2])
        
        # Test start
        composite.start(10)
        tracker1.start.assert_called_once_with(10)
        tracker2.start.assert_called_once_with(10)
        
        # Test update
        composite.update(5, "/file.txt", "error")
        tracker1.update.assert_called_once_with(5, "/file.txt", "error")
        tracker2.update.assert_called_once_with(5, "/file.txt", "error")
        
        # Test increment
        composite.increment("/file2.txt")
        tracker1.increment.assert_called_once_with("/file2.txt", None)
        tracker2.increment.assert_called_once_with("/file2.txt", None)
        
        # Test finish
        composite.finish()
        tracker1.finish.assert_called_once()
        tracker2.finish.assert_called_once()
        
        # Test get_info (returns from first tracker)
        info = composite.get_info()
        assert info == mock_info
    
    def test_empty_composite(self):
        """Test composite with no trackers."""
        composite = CompositeProgressTracker([])
        
        # Should not crash
        composite.start(10)
        composite.update(5)
        composite.increment()
        composite.finish()
        
        # Get info returns empty
        info = composite.get_info()
        assert info.current == 0
        assert info.total == 0
</file>

<file path="tests/unit/test_state_manager.py">
"""
Unit tests for state manager module.
"""
import pytest
import time
import threading
from unittest.mock import Mock, MagicMock
from pathlib import Path
import json
import tempfile

from folder_extractor.core.state_manager import (
    StateManager, OperationStats, ManagedOperation,
    get_state_manager, reset_state_manager
)


class TestOperationStats:
    """Test OperationStats dataclass."""
    
    def test_init(self):
        """Test initialization."""
        stats = OperationStats(
            operation_type="extraction",
            start_time=1000.0
        )
        
        assert stats.operation_type == "extraction"
        assert stats.start_time == 1000.0
        assert stats.end_time is None
        assert stats.files_processed == 0
        assert stats.files_moved == 0
        assert stats.files_skipped == 0
        assert stats.errors == 0
        assert stats.aborted is False
    
    def test_duration(self):
        """Test duration calculation."""
        stats = OperationStats(
            operation_type="extraction",
            start_time=1000.0
        )
        
        # No end time
        assert stats.duration is None
        
        # With end time
        stats.end_time = 1010.5
        assert stats.duration == 10.5
    
    def test_success_rate(self):
        """Test success rate calculation."""
        stats = OperationStats(
            operation_type="extraction",
            start_time=1000.0
        )
        
        # No files processed
        assert stats.success_rate == 0.0
        
        # Some files processed
        stats.files_processed = 10
        stats.files_moved = 8
        assert stats.success_rate == 80.0
        
        # All files processed
        stats.files_processed = 10
        stats.files_moved = 10
        assert stats.success_rate == 100.0


class TestStateManager:
    """Test StateManager class."""
    
    def setup_method(self):
        """Set up test fixtures."""
        self.manager = StateManager()
    
    def test_operation_lifecycle(self):
        """Test operation start and end."""
        # Start operation
        op_id = self.manager.start_operation("extraction")
        
        assert op_id is not None
        assert op_id.startswith("extraction_")
        assert "_1" in op_id or "_2" in op_id  # Contains counter
        assert self.manager.get_current_operation_id() == op_id
        
        # Get stats
        stats = self.manager.get_operation_stats(op_id)
        assert stats is not None
        assert stats.operation_type == "extraction"
        assert stats.start_time > 0
        assert stats.end_time is None
        
        # End operation
        time.sleep(0.01)  # Ensure some time passes
        self.manager.end_operation(op_id)
        
        # Check stats updated
        stats = self.manager.get_operation_stats(op_id)
        assert stats.end_time is not None
        assert stats.end_time > stats.start_time
        assert self.manager.get_current_operation_id() is None
    
    def test_update_operation_stats(self):
        """Test updating operation statistics."""
        op_id = self.manager.start_operation("extraction")
        
        # Update counters
        self.manager.update_operation_stats(op_id, files_processed=5)
        self.manager.update_operation_stats(op_id, files_moved=3)
        self.manager.update_operation_stats(op_id, errors=1)
        
        stats = self.manager.get_operation_stats(op_id)
        assert stats.files_processed == 5
        assert stats.files_moved == 3
        assert stats.errors == 1
        
        # Increment counters
        self.manager.update_operation_stats(op_id, files_processed=2)
        stats = self.manager.get_operation_stats(op_id)
        assert stats.files_processed == 7
    
    def test_abort_handling(self):
        """Test abort request handling."""
        assert not self.manager.is_abort_requested()
        
        # Request abort
        self.manager.request_abort()
        assert self.manager.is_abort_requested()
        
        # Get abort signal
        signal = self.manager.get_abort_signal()
        assert signal.is_set()
        
        # Clear abort
        self.manager.clear_abort()
        assert not self.manager.is_abort_requested()
        assert not signal.is_set()
    
    def test_state_values(self):
        """Test state value storage."""
        # Set single value
        self.manager.set_value("key1", "value1")
        assert self.manager.get_value("key1") == "value1"
        assert self.manager.get_value("nonexistent", "default") == "default"
        
        # Update multiple values
        self.manager.update_values({
            "key2": "value2",
            "key3": 123
        })
        assert self.manager.get_value("key2") == "value2"
        assert self.manager.get_value("key3") == 123
    
    def test_event_listeners(self):
        """Test event listener functionality."""
        mock_listener = Mock()
        
        # Add listener
        self.manager.add_listener("operation_started", mock_listener)
        
        # Start operation (should trigger listener)
        op_id = self.manager.start_operation("test")
        mock_listener.assert_called_once_with(operation_id=op_id)
        
        # Remove listener
        self.manager.remove_listener("operation_started", mock_listener)
        mock_listener.reset_mock()
        
        # Start another operation (should not trigger)
        self.manager.start_operation("test2")
        mock_listener.assert_not_called()
    
    def test_state_change_listener(self):
        """Test state change notifications."""
        mock_listener = Mock()
        self.manager.add_listener("state_changed", mock_listener)
        
        # Set value (should trigger)
        self.manager.set_value("test_key", "test_value")
        mock_listener.assert_called_once_with(
            key="test_key",
            old_value=None,
            new_value="test_value"
        )
        
        # Set same value (should not trigger)
        mock_listener.reset_mock()
        self.manager.set_value("test_key", "test_value")
        mock_listener.assert_not_called()
    
    def test_save_and_load_state(self):
        """Test state persistence."""
        # Set up some state
        op_id = self.manager.start_operation("extraction")
        self.manager.update_operation_stats(op_id, files_processed=10, files_moved=8)
        self.manager.end_operation(op_id)
        self.manager.set_value("last_path", "/test/path")
        
        # Save state
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            temp_path = Path(f.name)
        
        try:
            self.manager.save_state(temp_path)
            
            # Create new manager and load state
            new_manager = StateManager()
            new_manager.load_state(temp_path)
            
            # Check state restored
            assert new_manager.get_value("last_path") == "/test/path"
            
            # Check operations restored
            loaded_stats = new_manager.get_operation_stats(op_id)
            assert loaded_stats is not None
            assert loaded_stats.files_processed == 10
            assert loaded_stats.files_moved == 8
        
        finally:
            temp_path.unlink(missing_ok=True)
    
    def test_clear(self):
        """Test clearing all state."""
        # Set up state
        op_id = self.manager.start_operation("test")
        self.manager.set_value("key", "value")
        self.manager.request_abort()
        
        # Clear
        self.manager.clear()
        
        # Check everything cleared
        assert self.manager.get_current_operation_id() is None
        assert self.manager.get_operation_stats(op_id) is None
        assert self.manager.get_value("key") is None
        assert not self.manager.is_abort_requested()
    
    def test_thread_safety(self):
        """Test thread-safe operations."""
        results = []
        errors = []
        
        def worker(worker_id):
            try:
                for i in range(10):
                    # Start operation
                    op_id = self.manager.start_operation(f"worker_{worker_id}")
                    
                    # Update stats
                    self.manager.update_operation_stats(op_id, files_processed=1)
                    
                    # Set value
                    self.manager.set_value(f"worker_{worker_id}_value", i)
                    
                    # End operation
                    self.manager.end_operation(op_id)
                    
                    results.append((worker_id, i))
            except Exception as e:
                errors.append(e)
        
        # Run multiple threads
        threads = []
        for i in range(5):
            t = threading.Thread(target=worker, args=(i,))
            threads.append(t)
            t.start()
        
        # Wait for completion
        for t in threads:
            t.join()
        
        # Check results
        assert len(errors) == 0
        assert len(results) == 50  # 5 workers * 10 iterations
        
        # Check all operations recorded
        all_ops = self.manager.get_all_operations()
        assert len(all_ops) == 50


class TestManagedOperation:
    """Test ManagedOperation context manager."""
    
    def test_context_manager(self):
        """Test basic context manager usage."""
        manager = StateManager()
        
        with ManagedOperation(manager, "test_op") as op:
            # Check operation started
            assert op.operation_id is not None
            assert manager.get_current_operation_id() == op.operation_id
            
            # Update stats
            op.update_stats(files_processed=5, files_moved=3)
            
            # Check abort signal available
            assert op.abort_signal is not None
        
        # Check operation ended
        assert manager.get_current_operation_id() is None
        stats = manager.get_operation_stats(op.operation_id)
        assert stats.end_time is not None
        assert stats.files_processed == 5
        assert stats.files_moved == 3
    
    def test_exception_handling(self):
        """Test operation ends even with exception."""
        manager = StateManager()
        op_id = None
        
        try:
            with ManagedOperation(manager, "test_op") as op:
                op_id = op.operation_id
                raise ValueError("Test error")
        except ValueError:
            pass
        
        # Check operation still ended
        assert manager.get_current_operation_id() is None
        stats = manager.get_operation_stats(op_id)
        assert stats is not None
        assert stats.end_time is not None


def test_global_state_manager():
    """Test global state manager functions."""
    # Reset first
    reset_state_manager()
    
    # Get instance
    manager1 = get_state_manager()
    manager2 = get_state_manager()
    
    # Should be same instance
    assert manager1 is manager2
    
    # Test it works
    manager1.set_value("test", "value")
    assert manager2.get_value("test") == "value"
    
    # Reset
    reset_state_manager()
    manager3 = get_state_manager()
    
    # Should be new instance
    assert manager3 is not manager1
    assert manager3.get_value("test") is None
</file>

<file path="tests/unit/test_validators.py">
"""
Unit tests for validator modules.
"""
import pytest
import tempfile
from pathlib import Path

from folder_extractor.utils.file_validators import (
    is_temp_or_system_file,
    is_git_path,
    is_hidden_file,
    should_include_file,
    validate_file_extension
)

from folder_extractor.utils.path_validators import (
    is_safe_path,
    get_safe_path_info,
    normalize_path,
    is_subdirectory
)


class TestFileValidators:
    """Test file validation functions."""
    
    def test_temp_system_file_detection(self):
        """Test temporary and system file detection."""
        # System files
        assert is_temp_or_system_file(".DS_Store") is True
        assert is_temp_or_system_file("Thumbs.db") is True
        assert is_temp_or_system_file("desktop.ini") is True
        
        # Temp files
        assert is_temp_or_system_file("file.tmp") is True
        assert is_temp_or_system_file("~$temp.doc") is True
        assert is_temp_or_system_file(".swp") is True
        
        # Normal files
        assert is_temp_or_system_file("document.pdf") is False
        assert is_temp_or_system_file("normal.txt") is False
    
    def test_git_path_detection(self):
        """Test git path detection."""
        # Git internal paths
        assert is_git_path(".git/config") is True
        assert is_git_path("project/.git/HEAD") is True
        assert is_git_path("path/to/.git/objects/abc") is True
        
        # Normal paths
        assert is_git_path("src/main.py") is False
        assert is_git_path(".gitignore") is False
    
    def test_is_hidden_file(self):
        """Test hidden file detection."""
        assert is_hidden_file(".hidden") is True
        assert is_hidden_file(".DS_Store") is True
        assert is_hidden_file("normal.txt") is False
        assert is_hidden_file(".") is False  # Current directory
        assert is_hidden_file("..") is False  # Parent directory
    
    def test_should_include_file(self):
        """Test comprehensive file inclusion logic."""
        # Normal files should be included
        assert should_include_file("document.pdf", include_hidden=False) is True
        
        # System files should be excluded
        assert should_include_file(".DS_Store", include_hidden=False) is False
        assert should_include_file(".DS_Store", include_hidden=True) is False
        
        # Hidden files depend on setting
        assert should_include_file(".hidden", include_hidden=False) is False
        assert should_include_file(".hidden", include_hidden=True) is True
        
        # Git files always excluded
        assert should_include_file(".git/config", include_hidden=True) is False
    
    def test_validate_file_extension(self):
        """Test file extension validation."""
        # No filter allows all
        assert validate_file_extension("file.pdf", None) is True
        assert validate_file_extension("file.txt", None) is True
        
        # With filter
        pdf_filter = [".pdf"]
        assert validate_file_extension("file.pdf", pdf_filter) is True
        assert validate_file_extension("file.PDF", pdf_filter) is True
        assert validate_file_extension("file.txt", pdf_filter) is False
        
        # Multiple extensions
        multi_filter = [".pdf", ".jpg", ".png"]
        assert validate_file_extension("doc.pdf", multi_filter) is True
        assert validate_file_extension("img.jpg", multi_filter) is True
        assert validate_file_extension("doc.txt", multi_filter) is False


class TestPathValidators:
    """Test path validation functions."""
    
    def test_safe_path_compatibility(self):
        """Test compatibility with original function."""
        from folder_extractor.main import ist_sicherer_pfad as old_func
        
        home = Path.home()
        test_paths = [
            str(home / "Desktop" / "test"),
            str(home / "Downloads" / "test"),
            str(home / "Documents" / "test"),
            "/etc/passwd",
            str(home),
            str(home / "Library")
        ]
        
        for path in test_paths:
            # Create directory if it's supposed to be safe
            if any(safe in path for safe in ["Desktop", "Downloads", "Documents"]):
                Path(path).mkdir(parents=True, exist_ok=True)
            
            old_result = old_func(path)
            new_result = is_safe_path(path)
            assert old_result == new_result, f"Mismatch for '{path}'"
    
    def test_get_safe_path_info(self):
        """Test detailed path safety information."""
        home = Path.home()
        
        # Safe path
        safe, reason = get_safe_path_info(str(home / "Desktop" / "test"))
        assert safe is True
        assert "Desktop" in reason
        
        # Unsafe path - outside home
        safe, reason = get_safe_path_info("/etc")
        assert safe is False
        assert "outside home" in reason
        
        # Unsafe path - wrong folder
        safe, reason = get_safe_path_info(str(home / "Pictures"))
        assert safe is False
        assert "not in allowed folders" in reason
    
    def test_normalize_path(self):
        """Test path normalization."""
        # Test tilde expansion
        normalized = normalize_path("~/Desktop")
        assert normalized == str(Path.home() / "Desktop")
        
        # Test relative path
        cwd = Path.cwd()
        normalized = normalize_path("./test")
        assert normalized == str(cwd / "test")
        
        # Test already absolute
        abs_path = "/tmp/test"
        assert normalize_path(abs_path) == abs_path
    
    def test_is_subdirectory(self):
        """Test subdirectory checking."""
        # Simple case
        assert is_subdirectory("/parent", "/parent/child") is True
        assert is_subdirectory("/parent", "/parent/child/grandchild") is True
        
        # Not subdirectory
        assert is_subdirectory("/parent", "/other") is False
        assert is_subdirectory("/parent/child", "/parent") is False
        
        # Same directory
        assert is_subdirectory("/same", "/same") is True
</file>

<file path="tests/__init__.py">
"""
Test Suite f√ºr Folder Extractor
"""
</file>

<file path="tests/conftest.py">
"""
Pytest configuration and shared fixtures
"""
import os
import sys
import pytest
import tempfile
import shutil
from pathlib import Path

# Add parent directory to path so we can import folder_extractor
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


@pytest.fixture
def temp_dir():
    """Create a temporary directory for testing."""
    temp_dir = tempfile.mkdtemp()
    yield temp_dir
    # Cleanup after test
    if os.path.exists(temp_dir):
        shutil.rmtree(temp_dir)


@pytest.fixture
def test_file_structure(temp_dir):
    """Create a standard test file structure."""
    # Create directories
    os.makedirs(os.path.join(temp_dir, "subdir1"))
    os.makedirs(os.path.join(temp_dir, "subdir2", "nested"))
    os.makedirs(os.path.join(temp_dir, ".hidden"))
    os.makedirs(os.path.join(temp_dir, ".git", "objects"))
    
    # Create files
    files = {
        "file1.txt": "Content 1",
        "file2.pdf": "PDF content",
        "subdir1/file3.txt": "Content 3",
        "subdir1/file4.jpg": "Image content",
        "subdir2/file5.doc": "Doc content",
        "subdir2/nested/file6.txt": "Nested content",
        ".hidden/secret.txt": "Secret content",
        ".git/config": "Git config",
        ".git/HEAD": "ref: refs/heads/main",
        ".DS_Store": "System file",
    }
    
    created_files = []
    for file_path, content in files.items():
        full_path = os.path.join(temp_dir, file_path)
        with open(full_path, 'w') as f:
            f.write(content)
        created_files.append(full_path)
    
    return temp_dir, created_files


@pytest.fixture
def safe_test_dir():
    """Create a test directory in a safe location (Desktop)."""
    desktop = Path.home() / "Desktop" / "folder_extractor_test"
    desktop.mkdir(exist_ok=True)
    yield str(desktop)
    # Cleanup
    if desktop.exists():
        shutil.rmtree(desktop)


@pytest.fixture
def mock_user_input(monkeypatch):
    """Helper to mock user input."""
    def _mock_input(inputs):
        input_iterator = iter(inputs)
        monkeypatch.setattr('builtins.input', lambda _: next(input_iterator))
    return _mock_input
</file>

<file path="tests/README.md">
# Folder Extractor Test Suite

## √úbersicht

Diese Test Suite dokumentiert und verifiziert das aktuelle Verhalten von Folder Extractor vor der geplanten Refaktorierung.

## Test-Struktur

```
tests/
‚îú‚îÄ‚îÄ unit/                    # Unit Tests f√ºr einzelne Funktionen
‚îÇ   ‚îú‚îÄ‚îÄ test_parsing_functions.py
‚îÇ   ‚îî‚îÄ‚îÄ test_file_operations.py
‚îú‚îÄ‚îÄ integration/             # Integration Tests f√ºr Workflows
‚îÇ   ‚îú‚îÄ‚îÄ test_main_functionality.py
‚îÇ   ‚îú‚îÄ‚îÄ test_file_moving.py
‚îÇ   ‚îú‚îÄ‚îÄ test_undo_functionality.py
‚îÇ   ‚îú‚îÄ‚îÄ test_abort_handling.py
‚îÇ   ‚îú‚îÄ‚îÄ test_terminal_handling.py
‚îÇ   ‚îî‚îÄ‚îÄ test_edge_cases.py
‚îî‚îÄ‚îÄ performance/            # Performance Benchmarks
    ‚îî‚îÄ‚îÄ test_benchmarks.py
```

## Tests ausf√ºhren

### Alle Tests
```bash
python run_tests.py
```

### Nur Unit Tests
```bash
python run_tests.py unit
```

### Nur Integration Tests
```bash
python run_tests.py integration
```

### Performance Benchmarks
```bash
python run_tests.py performance
```

### Mit Coverage Report
```bash
python run_tests.py coverage
```

## Test-Kategorien

### Unit Tests
- **Parsing Functions**: Test der Eingabe-Parser f√ºr Dateitypen und Domains
- **File Operations**: Test von Dateioperationen wie eindeutige Namengenerierung

### Integration Tests
- **Main Functionality**: Test der Hauptfunktionen (Dateisuche, Sicherheitsvalidierung)
- **File Moving**: Test des Dateiverschiebens und Sortierens
- **Undo Functionality**: Test der Undo-Operationen
- **Abort Handling**: Test der ESC-Taste Abbruchfunktion
- **Terminal Handling**: Test der Terminal-Einstellungen
- **Edge Cases**: Test von Spezialf√§llen (Unicode, gro√üe Dateimengen)

### Performance Benchmarks
- Dateisuche in verschiedenen Strukturen
- Verschieben vieler Dateien
- Eindeutige Namengenerierung
- Leere Ordner Bereinigung

## Wichtige Test-Fixtures

- `temp_dir`: Tempor√§res Verzeichnis f√ºr Tests
- `test_file_structure`: Standard-Testdateistruktur
- `safe_test_dir`: Sicheres Testverzeichnis auf Desktop
- `mock_user_input`: Mock f√ºr Benutzereingaben

## Hinweise

1. Tests laufen nur in sicheren Verzeichnissen (Desktop/Downloads/Documents)
2. Terminal-Tests werden auf Windows √ºbersprungen
3. Performance-Tests erstellen tempor√§re Dateien auf dem Desktop
4. Alle Test-Dateien werden nach dem Test automatisch bereinigt
</file>

<file path=".coderabbit.yaml">
# CodeRabbit Configuration for Folder Extractor
# https://docs.coderabbit.ai

version: 1

language: python

reviews:
  profile: balanced  # lenient, balanced, strict, very_strict
  
  auto_review:
    enabled: true
    comment: "ü§ñ CodeRabbit AI Review"
    
  paths:
    include:
      - "folder_extractor/**/*.py"
      - "tests/**/*.py"
      - "setup.py"
    
    exclude:
      - "**/__pycache__/**"
      - "**/*.pyc"
      - "**/*.pyo"
      - "**/*.pyd"
      - "tests/fixtures/**"
      - ".github/**"
      - ".vscode/**"
      - ".idea/**"

  focus_areas:
    - security
    - performance
    - maintainability
    - documentation
    - best_practices

pr_description:
  auto_generate:
    enabled: true
    style: detailed
    
  sections:
    - summary
    - changes
    - impact
    - suggestions

pr_title:
  auto_generate:
    enabled: true
    prefix: "[AUTO] "
    style: concise

chat:
  auto_reply: true
  model: gpt-4
  
  context:
    include:
      - "folder_extractor/**"
      - "ARCHITECTURE.md"
      - "README.md"
    
    exclude:
      - "tests/**"
      - ".github/**"

suggestions:
  auto_apply:
    enabled: false
    confidence_threshold: high
  
  categories:
    - style
    - performance
    - security
    - documentation

notifications:
  slack:
    enabled: false
    # channel: "#code-reviews"
  
  email:
    enabled: false
    # recipients: ["team@example.com"]
</file>

<file path=".gitignore">
# Python
__pycache__/
*.py[cod]
*$py.class

# Virtual environment
.venv/
venv/
ENV/

# macOS
.DS_Store

# IDE
.idea/
.vscode/

# Python package files
*.egg-info/
dist/
build/

# Test outputs
.coverage
.htmlcov/

# Logs
*.log

# Temporary files
*.tmp
*.swp
*.swo

# System files
Thumbs.db
desktop.ini

# Compiled Python files
*.pyc
*.pyo
*.pyd

# Jupyter notebooks
.ipynb_checkpoints/

# Environment variables
.env
.env.local

# Dependency directories
node_modules/

# Cache directories
.cache/

# Local settings
settings.local.json

# History files
.folder_extractor_history.json
</file>

<file path="ARCHITECTURE.md">
# Folder Extractor - Architecture Documentation

## Overview

Folder Extractor is a German-language command-line tool for safely extracting files from subdirectories. The application has been refactored from a monolithic architecture (1201 lines in a single file) to a clean, modular architecture following best practices and design patterns.

## Architecture Principles

- **Separation of Concerns**: Each module has a single, well-defined responsibility
- **Dependency Injection**: Components receive their dependencies rather than creating them
- **Interface Segregation**: Clear interfaces define contracts between modules
- **Open/Closed Principle**: Extensible through interfaces without modifying existing code
- **DRY (Don't Repeat Yourself)**: Common functionality is extracted and reused
- **Thread Safety**: State management is thread-safe for concurrent operations

## Directory Structure

```
folder_extractor/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ main.py               # Legacy monolithic implementation (preserved for compatibility)
‚îú‚îÄ‚îÄ main_enhanced.py      # Enhanced entry point with architecture selection
‚îú‚îÄ‚îÄ main_final.py         # Final integrated entry point
‚îÇ
‚îú‚îÄ‚îÄ cli/                  # Command Line Interface layer
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ parser.py         # Argument parsing
‚îÇ   ‚îú‚îÄ‚îÄ interface.py      # Console interaction & progress display
‚îÇ   ‚îú‚îÄ‚îÄ app.py           # CLI application orchestration
‚îÇ   ‚îî‚îÄ‚îÄ app_v2.py        # Enhanced CLI with state management
‚îÇ
‚îú‚îÄ‚îÄ core/                 # Business logic layer
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ file_discovery.py # File finding and filtering
‚îÇ   ‚îú‚îÄ‚îÄ file_operations.py # File manipulation operations
‚îÇ   ‚îú‚îÄ‚îÄ extractor.py      # Core extraction orchestration
‚îÇ   ‚îú‚îÄ‚îÄ extractor_v2.py   # Enhanced extractor with state management
‚îÇ   ‚îú‚îÄ‚îÄ state.py          # Application state interfaces
‚îÇ   ‚îú‚îÄ‚îÄ state_manager.py  # Thread-safe state management
‚îÇ   ‚îú‚îÄ‚îÄ progress.py       # Progress tracking
‚îÇ   ‚îî‚îÄ‚îÄ migration.py      # Migration utilities and adapters
‚îÇ
‚îú‚îÄ‚îÄ config/              # Configuration layer
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ constants.py     # Application constants
‚îÇ   ‚îî‚îÄ‚îÄ settings.py      # Runtime settings management
‚îÇ
‚îî‚îÄ‚îÄ utils/               # Utility functions
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ path_validators.py  # Path security validation
    ‚îú‚îÄ‚îÄ file_validators.py  # File validation utilities
    ‚îî‚îÄ‚îÄ terminal.py         # Terminal operations
```

## Key Components

### 1. CLI Layer (`cli/`)

**Purpose**: Handle user interaction, command parsing, and presentation

- **`parser.py`**: Defines command-line arguments using argparse
- **`interface.py`**: 
  - `ConsoleInterface`: Manages user output and input
  - `KeyboardHandler`: Handles ESC key detection for abort
- **`app.py`**: Basic CLI application orchestration
- **`app_v2.py`**: Enhanced CLI with integrated state management

### 2. Core Business Logic (`core/`)

**Purpose**: Implement the actual file extraction logic

- **`file_discovery.py`**:
  - `IFileDiscovery`: Interface for file discovery
  - `FileDiscovery`: Finds files based on criteria (depth, type, hidden)
  
- **`file_operations.py`**:
  - `IFileOperations`: Interface for file operations
  - `FileOperations`: Basic file operations (move, copy, unique naming)
  - `FileMover`: High-level file moving with progress tracking
  - `HistoryManager`: Manages operation history for undo

- **`extractor.py`**:
  - `IExtractor`: Interface for extraction operations
  - `FileExtractor`: Coordinates file discovery and moving
  - `ExtractionOrchestrator`: High-level extraction workflow

- **`state_manager.py`**:
  - `IStateManager`: Interface for state management
  - `StateManager`: Thread-safe state management with operation tracking
  - `OperationStats`: Statistics for operations
  - `ManagedOperation`: Context manager for operation lifecycle

- **`progress.py`**:
  - `IProgressTracker`: Interface for progress tracking
  - `ProgressTracker`: Track and report operation progress
  - `CompositeProgressTracker`: Aggregate multiple progress trackers

### 3. Configuration (`config/`)

**Purpose**: Centralize configuration and constants

- **`constants.py`**: All string constants, messages, and file type mappings
- **`settings.py`**: Runtime settings management (singleton pattern)

### 4. Utilities (`utils/`)

**Purpose**: Shared utility functions

- **`path_validators.py`**: Security validation for paths
- **`file_validators.py`**: File type and attribute validation
- **`terminal.py`**: Terminal settings and color support

## Design Patterns Used

### 1. **Interface Segregation**
Each module defines clear interfaces (abstract base classes) that specify contracts:
```python
class IFileDiscovery(ABC):
    @abstractmethod
    def find_files(self, directory: str, ...) -> List[str]:
        pass
```

### 2. **Dependency Injection**
Components receive dependencies through constructors:
```python
class FileExtractor:
    def __init__(self, file_discovery: IFileDiscovery, 
                 file_operations: IFileOperations):
        self.file_discovery = file_discovery
        self.file_operations = file_operations
```

### 3. **Factory Pattern**
Creation functions provide configured instances:
```python
def create_console_interface() -> IConsoleInterface:
    return ConsoleInterface()
```

### 4. **Singleton Pattern**
Settings and state manager use singleton pattern for global access:
```python
_state_manager_instance: Optional[StateManager] = None

def get_state_manager() -> StateManager:
    global _state_manager_instance
    if _state_manager_instance is None:
        _state_manager_instance = StateManager()
    return _state_manager_instance
```

### 5. **Context Manager Pattern**
Operation lifecycle management:
```python
with ManagedOperation(state_manager, "extraction") as op:
    # Perform operation
    # Automatic cleanup on exit
```

### 6. **Observer Pattern**
State manager supports event listeners:
```python
state_manager.add_listener("state_changed", callback_function)
```

### 7. **Adapter Pattern**
Migration adapters provide compatibility:
```python
class ExtractorAdapter(IExtractor):
    def __init__(self, enhanced_extractor: IEnhancedExtractor):
        self.enhanced_extractor = enhanced_extractor
```

## Data Flow

1. **User Input** ‚Üí CLI Parser ‚Üí Settings Configuration
2. **Execution Request** ‚Üí CLI App ‚Üí Orchestrator
3. **File Discovery** ‚Üí FileDiscovery finds files based on criteria
4. **Validation** ‚Üí Security and file validators check each file
5. **File Operations** ‚Üí FileMover moves files with progress tracking
6. **State Updates** ‚Üí StateManager tracks operation progress
7. **Progress Display** ‚Üí ConsoleInterface shows real-time progress
8. **History Saving** ‚Üí HistoryManager saves operations for undo
9. **Result Display** ‚Üí ConsoleInterface shows summary

## Thread Safety

The application ensures thread safety through:

1. **Thread-safe State Manager**: Uses locks for concurrent access
2. **Abort Signal**: Threading.Event for safe operation cancellation
3. **Atomic Operations**: File operations are atomic where possible
4. **Progress Callbacks**: Thread-safe progress reporting

## Migration Strategy

The architecture supports gradual migration from the monolithic design:

1. **Backward Compatibility**: Legacy main.py preserved
2. **Architecture Selection**: Environment variable controls which architecture to use
3. **Adapters**: Bridge between old and new interfaces
4. **Settings Migration**: Automatic migration of settings to state manager

## Testing Strategy

The modular architecture enables comprehensive testing:

1. **Unit Tests**: Test each component in isolation
2. **Integration Tests**: Test component interactions
3. **Backward Compatibility Tests**: Ensure legacy behavior preserved
4. **Performance Tests**: Benchmark critical operations

## Extension Points

The architecture is designed for extensibility:

1. **New File Discovery Strategies**: Implement `IFileDiscovery`
2. **Custom File Operations**: Implement `IFileOperations`
3. **Alternative UI**: Implement `IConsoleInterface`
4. **State Persistence**: Extend `IStateManager`
5. **Progress Visualization**: Extend `IProgressTracker`

## Performance Considerations

1. **Lazy Loading**: Components loaded only when needed
2. **Efficient File Walking**: Single pass through directory tree
3. **Batch Operations**: Progress updates batched for efficiency
4. **Memory Efficiency**: Stream processing for large file sets

## Security Considerations

1. **Path Validation**: Only operates in safe user directories
2. **No Code Execution**: No dynamic code execution
3. **Input Sanitization**: All user input validated
4. **Atomic Operations**: Prevent partial state corruption

## Future Enhancements

The modular architecture enables future enhancements:

1. **GUI Frontend**: Add graphical interface using the same core
2. **Network Operations**: Add remote file system support
3. **Plugin System**: Dynamic loading of extensions
4. **Parallel Processing**: Multi-threaded file operations
5. **Cloud Integration**: Support for cloud storage providers
</file>

<file path="CHANGELOG.md">
# Changelog

Alle bemerkenswerten √Ñnderungen an diesem Projekt werden in dieser Datei dokumentiert.

Das Format basiert auf [Keep a Changelog](https://keepachangelog.com/de/1.0.0/).

## [1.3.3] - 2025-01-31

### Behoben
- Kritischer Bug behoben: Versteckte Dateien in Unterordnern wurden f√§lschlicherweise extrahiert, auch wenn `--include-hidden` nicht gesetzt war
- Die Logik f√ºr das Durchsuchen von Unterordnern wurde korrigiert, sodass versteckte Dateien nur mit dem expliziten Flag extrahiert werden

## [1.3.2] - 2025-01-31

### Hinzugef√ºgt
- Neue Option `--include-hidden` zum Einbeziehen versteckter Dateien (die mit . beginnen)
- Versteckte Dateien werden standardm√§√üig ignoriert, k√∂nnen aber jetzt optional einbezogen werden

### Behoben
- Git-spezifische Dateinamen (wie `index`, `HEAD`, `config`) werden jetzt nur noch ohne Erweiterung ignoriert
- `index.html`, `config.json` und √§hnliche Dateien werden jetzt korrekt erkannt und nicht mehr f√§lschlicherweise ignoriert

### Ge√§ndert
- Verbesserte Filter-Logik f√ºr tempor√§re und System-Dateien
- Aktualisierte Dokumentation mit Beispielen f√ºr die neue Option

## [1.3.1] - 2025-01-28

### Hinzugef√ºgt
- Automatische Bereinigung von Terminal-Escape-Sequenzen im Domain-Namensfeld

### Behoben
- Web-Link Analyse funktioniert jetzt korrekt auch bei komplexeren .webloc Dateien
- Verbesserte Fehlerbehandlung bei der Domain-Extraktion

## [1.3.0] - 2025-01-27

### Hinzugef√ºgt
- Neue Option `--sort-by-type` zum automatischen Sortieren von Dateien in Typ-spezifische Ordner
- Dateien werden in Ordner wie PDF/, JPEG/, DOCX/ etc. organisiert
- √Ñhnliche Dateitypen werden intelligent zusammengefasst (z.B. jpg ‚Üí JPEG/)
- Dateien ohne Erweiterung werden in OHNE_ERWEITERUNG/ gespeichert
- Die Option funktioniert mit allen anderen Filtern und Optionen

### Verbessert
- Erweiterte Hilfe-Dokumentation mit detaillierten Beispielen
- Bessere Strukturierung der Kommandozeilen-Hilfe

## [1.2.0] - 2025-01-26

### Hinzugef√ºgt
- Dateityp-Filter mit `--type` Option zum selektiven Extrahieren bestimmter Dateitypen
- Domain-Filter mit `--domain` Option zum Filtern von Web-Links nach Domains
- Unterst√ºtzung f√ºr .url und .webloc Dateien
- Erweiterte Beispiele in der Dokumentation

### Verbessert
- Flexiblere Eingabe f√ºr Dateitypen (mit oder ohne Punkt, case-insensitive)
- Bessere Fehlerbehandlung bei der Analyse von Web-Links

## [1.1.0] - 2025-01-25

### Hinzugef√ºgt
- Dry-Run Modus mit `--dry-run` Option
- Verbesserte Fortschrittsanzeige mit Prozentangaben
- Detailliertere Statistiken nach Abschluss

### Behoben
- Verbesserte Behandlung von Sonderzeichen in Dateinamen
- Stabilere ESC-Tasten-Erkennung auf verschiedenen Terminals

## [1.0.0] - 2025-01-24

### Erstver√∂ffentlichung
- Grundlegende Funktionalit√§t zum Extrahieren von Dateien aus Unterordnern
- Sicherheitspr√ºfung f√ºr Desktop, Downloads und Documents Ordner
- Intelligente Duplikat-Behandlung mit automatischer Umbenennung
- Tiefensteuerung mit `--depth` Option
- ESC-Taste zum Abbrechen
- Undo-Funktion zum R√ºckg√§ngigmachen der letzten Operation
- Automatisches L√∂schen leerer Ordner
- Benutzerbest√§tigung vor dem Start
- Detailliertes Feedback und Zusammenfassung
</file>

<file path="CLAUDE.md">
# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Development Commands

**Installation**: 
```bash
# Standard installation
pip install .

# Development installation (editable)
pip install -e .
```

**Uninstall**: `pip uninstall folder-extractor`

**Direct usage without installation**: `python folder_extractor/main.py [options]`

## Architecture Overview

This is a German-language command-line tool for safely extracting files from subdirectories. Built with pure Python (3.7+) using only standard library modules - no external dependencies.

### Key Components

**Main Module** (`folder_extractor/main.py`): Single-file implementation containing all functionality:
- Security checks restricting operation to Desktop/Downloads/Documents folders
- Recursive file discovery with configurable depth limits
- File type filtering (e.g., extract only PDFs, images, etc.)
- Domain filtering for web links (.url, .webloc files)
- Duplicate handling with automatic renaming (_1, _2, etc.)
- Sort-by-type mode organizing files into type-specific folders
- Undo functionality tracking all operations in JSON history
- ESC key interruption support with proper terminal handling
- Empty folder cleanup after extraction

**Entry Point**: Configured in `setup.py` as `folder-extractor=folder_extractor.main:main`

### Core Functions

- `ist_sicherer_pfad()`: Validates execution is in safe user directories only
- `finde_dateien()`: Recursive file discovery with depth control and filtering
- `verschiebe_dateien()` / `verschiebe_dateien_sortiert()`: File moving with atomic operations
- `keyboard_listener()`: ESC key monitoring in separate thread
- `speichere_verlauf()` / `undo_operationen()`: Operation history for undo capability
- `pruefe_weblink_domain()`: Domain filtering for .url/.webloc files

### Data Flow

1. Security validation of current directory
2. File discovery based on depth, type, and domain filters  
3. User confirmation with preview showing planned operations
4. File movement with progress display and ESC interruption support
5. History saved to `.folder_extractor_history.json` for undo
6. Empty folder cleanup (unless type filter is active)

### Important Implementation Details

- Uses atomic file operations (rename when possible, copy+delete fallback for cross-device)
- Terminal settings saved/restored for proper ESC key handling  
- Ignores system files (.DS_Store, .git, temporary downloads, etc.)
- Thread-safe abort mechanism using `threading.Event()`
- Comprehensive help text with German examples and explanations
</file>

<file path="CODE_OF_CONDUCT.md">
# Code of Conduct

## Our Pledge

In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to make participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.

## Our Standards

Examples of behavior that contributes to creating a positive environment include:

* Using welcoming and inclusive language
* Being respectful of differing viewpoints and experiences
* Gracefully accepting constructive criticism
* Focusing on what is best for the community
* Showing empathy towards other community members

Examples of unacceptable behavior by participants include:

* The use of sexualized language or imagery and unwelcome sexual attention or advances
* Trolling, insulting/derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or electronic address, without explicit permission
* Other conduct which could reasonably be considered inappropriate in a professional setting

## Our Responsibilities

Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.

Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.

## Scope

This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at [your-email@example.com]. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.

Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant](https://www.contributor-covenant.org), version 1.4, available at [https://www.contributor-covenant.org/version/1/4](https://www.contributor-covenant.org/version/1/4)

For answers to common questions about this code of conduct, see [https://www.contributor-covenant.org/faq](https://www.contributor-covenant.org/faq)
</file>

<file path="CODE_RABBIT_SETUP.md">
# CodeRabbit Setup for Folder Extractor

## üéâ Welcome to CodeRabbit!

This guide helps you set up **CodeRabbit** with the Folder Extractor repository.

## üîß Prerequisites

- GitHub repository created and pushed
- CodeRabbit account (sign up at [coderabbit.ai](https://coderabbit.ai))
- Admin access to the GitHub repository

## üöÄ Setup Instructions

### 1. Install CodeRabbit GitHub App

1. Go to [CodeRabbit GitHub App](https://github.com/apps/coderabbit)
2. Click "Install" and select your account
3. Choose the `folder-extractor` repository
4. Install with **All repositories** or **Only selected repositories**

### 2. Configure Repository Settings

1. Go to your GitHub repository settings
2. Navigate to **Branches** ‚Üí **Branch protection rules**
3. Add a new rule for the `main` branch:
   - **Require a pull request before merging** ‚úÖ
   - **Require approvals** (1-2)
   - **Require status checks to pass before merging** ‚úÖ
   - **Require branches to be up to date before merging** ‚úÖ
   - **Include administrators** ‚úÖ

### 3. CodeRabbit Configuration

1. Create a `.coderabbit.yaml` file in the repository root:

```yaml
# .coderabbit.yaml
version: 1

language: python

reviews:
  profile: balanced
  auto_review:
    enabled: true
    comment: "CodeRabbit AI Review"
  
  paths:
    include:
      - "folder_extractor/**/*.py"
      - "tests/**/*.py"
    exclude:
      - "**/__pycache__/**"
      - "**/*.pyc"
      - "setup.py"

pr_description:
  auto_generate:
    enabled: true
    style: detailed

pr_title:
  auto_generate:
    enabled: true
    prefix: "[AUTO]"

chat:
  auto_reply: true
  model: gpt-4
```

### 4. Commit and Push Configuration

```bash
cd /Users/philippbriese/Documents/dev/dump/Folder\ Extractor
git add .coderabbit.yaml
git commit -m "feat: add CodeRabbit configuration"
git push origin main
```

## ü§ñ CodeRabbit Features

### Automatic Code Reviews
- **AI-powered code analysis** for every pull request
- **Style and quality checks** based on Python best practices
- **Security vulnerability detection**
- **Performance optimization suggestions**

### Pull Request Automation
- **Auto-generated PR descriptions** with detailed analysis
- **Auto-generated PR titles** with clear prefixes
- **Smart suggestions** for improvements

### Chat Integration
- **AI chat assistant** for code questions
- **Context-aware responses** based on your codebase
- **Multi-file analysis** for complex questions

## üìã Best Practices with CodeRabbit

### 1. Pull Request Workflow

1. **Create feature branch**:
   ```bash
   git checkout -b feature/your-feature
   ```

2. **Make changes** and commit with clear messages

3. **Push branch**:
   ```bash
   git push origin feature/your-feature
   ```

4. **Create Pull Request** on GitHub

5. **CodeRabbit will automatically**:
   - Analyze the code
   - Provide detailed review
   - Suggest improvements
   - Check for vulnerabilities

### 2. Addressing CodeRabbit Feedback

- **Review suggestions** carefully
- **Fix issues** marked as critical
- **Consider improvements** for better code quality
- **Use chat** to ask for clarification

### 3. Merging Process

1. **All checks pass** (CI/CD + CodeRabbit)
2. **Required approvals** are obtained
3. **No critical issues** remain
4. **Merge with confidence**

## üéØ CodeRabbit Configuration Tips

### Customizing Review Profile

```yaml
reviews:
  profile: strict  # Options: lenient, balanced, strict, very_strict
```

### Focusing on Specific Areas

```yaml
reviews:
  focus_areas:
    - security
    - performance
    - maintainability
    - documentation
```

### Ignoring Specific Files

```yaml
reviews:
  paths:
    exclude:
      - "tests/fixtures/**"
      - "docs/**"
      - "*.md"
```

## üìä Integration with Existing Workflows

### GitHub Actions + CodeRabbit

The repository's GitHub Actions workflows work seamlessly with CodeRabbit:

1. **CodeRabbit analyzes** the code first
2. **GitHub Actions runs** tests and linting
3. **Both must pass** before merging

### Example Workflow

```mermaid
graph TD
    A[Create PR] --> B[CodeRabbit Review]
    B --> C[GitHub Actions CI]
    C --> D[Manual Review]
    D --> E[Merge to main]
```

## ü§î Troubleshooting

### CodeRabbit Not Reviewing

1. **Check GitHub App installation**
2. **Verify repository access**
3. **Ensure `.coderabbit.yaml` exists**
4. **Check branch protection rules**

### False Positives

1. **Use chat** to ask for clarification
2. **Add comments** explaining the code
3. **Configure exceptions** in `.coderabbit.yaml`

## üéâ Benefits of CodeRabbit

‚úÖ **Faster code reviews** - AI assists human reviewers  
‚úÖ **Higher code quality** - Consistent style and best practices  
‚úÖ **Better security** - Automatic vulnerability detection  
‚úÖ **Knowledge sharing** - AI explains complex code  
‚úÖ **Onboarding help** - New developers get instant feedback  

## üìö Resources

- [CodeRabbit Documentation](https://docs.coderabbit.ai)
- [Python Best Practices](https://peps.python.org/pep-0008/)
- [GitHub Actions Docs](https://docs.github.com/en/actions)

---

**Happy Coding with CodeRabbit!** üöÄ
</file>

<file path="CONTRIBUTING.md">
# Contributing to Folder Extractor

Thank you for your interest in contributing to Folder Extractor! We welcome contributions from everyone.

## ü§ù Ways to Contribute

- **Bug Reports**: Report bugs by opening issues
- **Feature Requests**: Suggest new features
- **Code Contributions**: Submit pull requests
- **Documentation**: Improve documentation
- **Tests**: Add more test cases
- **Translations**: Help with internationalization

## üìã Getting Started

1. **Fork the repository** on GitHub
2. **Clone your fork** locally:
   ```bash
   git clone https://github.com/your-username/folder-extractor.git
   cd folder-extractor
   ```
3. **Install development dependencies**:
   ```bash
   pip install -r requirements.txt
   pip install -e .
   ```

## üîß Development Workflow

### Branch Strategy

- `main`: Stable production code
- `develop`: Integration branch for features
- `feature/*`: Feature development branches
- `bugfix/*`: Bug fix branches
- `hotfix/*`: Critical production fixes

### Commit Messages

Follow [Conventional Commits](https://www.conventionalcommits.org/):

```
<type>(<scope>): <description>

<body>

<footer>
```

**Types**:
- `feat`: New feature
- `fix`: Bug fix
- `docs`: Documentation changes
- `style`: Code style changes (formatting, missing semicolons)
- `refactor`: Code refactoring
- `perf`: Performance improvements
- `test`: Adding or modifying tests
- `chore`: Build process or auxiliary tool changes

**Examples**:
```
feat(extractor): add domain filtering for web links
fix(interface): correct progress percentage calculation
docs(readme): update installation instructions
test(extractor): add tests for duplicate file handling
```

### Pull Request Process

1. **Create a branch** for your feature/fix:
   ```bash
   git checkout -b feature/your-feature-name
   ```

2. **Make your changes** and commit them with clear messages

3. **Run tests** to ensure nothing breaks:
   ```bash
   python -m pytest tests/
   ```

4. **Run linting** to maintain code quality:
   ```bash
   black .
   flake8 .
   isort .
   ```

5. **Push your branch**:
   ```bash
   git push origin feature/your-feature-name
   ```

6. **Open a Pull Request** against the `develop` branch

7. **Wait for review** and address any feedback

## üìö Code Style

### Python Style

- Follow [PEP 8](https://www.python.org/dev/peps/pep-0008/) guidelines
- Use **Black** for code formatting (automatically enforced)
- Use **isort** for import sorting
- Use **Flake8** for linting

### Type Hints

- Use type hints for all functions and methods
- Use `Optional` for nullable parameters
- Use `Any` sparingly

### Documentation

- Use **Google-style docstrings** for all public functions and classes
- Keep docstrings up-to-date
- Document all parameters and return values

### Testing

- Write tests for new features
- Maintain >90% code coverage
- Use descriptive test names
- Test edge cases and error conditions

## üß™ Testing

### Running Tests

```bash
# Run all tests
python -m pytest tests/

# Run specific test file
python -m pytest tests/unit/test_core_extractor.py

# Run with coverage
python -m pytest --cov=folder_extractor tests/

# Run with verbose output
python -m pytest -v tests/
```

### Test Structure

```
tests/
‚îú‚îÄ‚îÄ unit/          # Unit tests for individual components
‚îú‚îÄ‚îÄ integration/   # Integration tests for component interactions
‚îî‚îÄ‚îÄ performance/   # Performance and benchmark tests
```

## üéØ Architecture Guidelines

### Key Principles

1. **Separation of Concerns**: Each module has a single responsibility
2. **Interface-based Design**: Use abstract base classes for contracts
3. **Dependency Injection**: Pass dependencies through constructors
4. **Thread Safety**: Ensure thread-safe operations where needed
5. **Backward Compatibility**: Maintain compatibility with existing code

### Adding New Features

1. **Define Interfaces** first in the appropriate module
2. **Implement** the concrete classes
3. **Add Tests** for the new functionality
4. **Update Documentation** in ARCHITECTURE.md
5. **Integrate** with existing components

## üìñ Documentation

### Updating Documentation

- **ARCHITECTURE.md**: Update for architectural changes
- **README.md**: Update for user-facing changes
- **GITHUB_README.md**: Update for GitHub-specific content
- **CHANGELOG.md**: Add entries for new versions

### Docstring Format

```python
def function_name(param1: type, param2: type) -> return_type:
    """Brief description of the function.
    
    Detailed description explaining what the function does,
    when to use it, and any important considerations.
    
    Args:
        param1: Description of parameter 1
        param2: Description of parameter 2
        
    Returns:
        Description of return value
        
    Raises:
        ExceptionType: Description of when this exception is raised
        
    Examples:
        >>> function_name(value1, value2)
        expected_result
    """
    # Function implementation
```

## ü§î Need Help?

If you have questions about contributing:

- Check existing issues and pull requests
- Ask in the discussions section
- Contact the maintainers

## üôè Thank You!

Your contributions help make Folder Extractor better for everyone! üéâ
</file>

<file path="FINAL_SETUP_SUMMARY.md">
# üéâ Final Setup Summary - Folder Extractor

## ‚úÖ Repository Successfully Configured for GitHub & CodeRabbit!

Your **Folder Extractor** project is now **fully prepared** for GitHub with **CodeRabbit integration**!

## üìÅ Current Repository Status

```bash
# Branch: main ‚úÖ
# Commits: 11
# Files: 120+ Python files + configuration
# Lines of Code: 9,393+
# Status: Clean working tree
```

## üöÄ What Has Been Set Up

### 1. **Git Repository** ‚úÖ
- Initialized with `main` branch (CodeRabbit-compatible)
- Clean commit history
- Proper `.gitignore` configuration
- All project files committed

### 2. **GitHub Configuration** ‚úÖ
- **`.github/`** directory with CI/CD workflows
- **GitHub Actions** for testing, linting, and releases
- **Issue Templates** (Bug Report, Feature Request)
- **Pull Request Template** with checklist
- **Branch Protection** ready for `main`

### 3. **CodeRabbit Integration** ‚úÖ
- **`.coderabbit.yaml`** configuration file
- **CODE_RABBIT_SETUP.md** comprehensive guide
- **Optimized for Python** code analysis
- **Focus areas**: Security, Performance, Maintainability
- **Auto-generated PR descriptions and titles**

### 4. **Documentation** ‚úÖ
- **GITHUB_README.md** (English, GitHub-optimized)
- **README.md** (German, original)
- **CONTRIBUTING.md** (Contribution guidelines)
- **CODE_OF_CONDUCT.md** (Community standards)
- **CHANGELOG.md** (Version history)
- **ARCHITECTURE.md** (Technical documentation)

### 5. **Development Setup** ‚úÖ
- **requirements.txt** (Development dependencies)
- **setup.py** (Package configuration)
- **Test suite** (120+ tests)
- **CI/CD pipeline** (GitHub Actions)

## üéØ Next Steps

### 1. **Push to GitHub** (If not already done)

```bash
cd /Users/philippbriese/Documents/dev/dump/Folder\ Extractor

# Add GitHub remote (replace with your username)
git remote add origin https://github.com/your-username/folder-extractor.git

# Push main branch
git push -u origin main
```

### 2. **Set Up GitHub Repository**

1. **Create repository** on GitHub (don't initialize with README)
2. **Install CodeRabbit GitHub App**
3. **Configure branch protection** for `main`
4. **Enable GitHub Pages** (optional for docs)

### 3. **Configure CodeRabbit**

1. **Install CodeRabbit App** on your GitHub repository
2. **Verify `.coderabbit.yaml`** is in the root
3. **Test with a sample PR** to see AI reviews in action

### 4. **Start Developing**

```bash
# Install dependencies
pip install -r requirements.txt
pip install -e .

# Run tests
python -m pytest tests/

# Run linting
black .
flake8 .
isort .
```

## ü§ñ CodeRabbit Features Ready

### Automatic Code Reviews
- **AI-powered analysis** for every pull request
- **Style and quality checks** based on Python best practices
- **Security vulnerability detection**
- **Performance optimization suggestions**

### Pull Request Automation
- **Auto-generated PR descriptions** with detailed analysis
- **Auto-generated PR titles** with clear prefixes
- **Smart suggestions** for improvements

### AI Chat Assistant
- **Context-aware responses** based on your codebase
- **Multi-file analysis** for complex questions
- **Instant explanations** for code patterns

## üìä Repository Quality Metrics

‚úÖ **Architecture**: Modular, interface-based design  
‚úÖ **Code Quality**: Type hints, docstrings, PEP 8 compliant  
‚úÖ **Testing**: 120+ unit and integration tests  
‚úÖ **Documentation**: Comprehensive and up-to-date  
‚úÖ **CI/CD**: GitHub Actions with test coverage  
‚úÖ **Security**: Thread-safe, input validation, path security  
‚úÖ **CodeRabbit**: Fully configured for AI assistance  

## üéì Learning Resources

- **CodeRabbit Docs**: [docs.coderabbit.ai](https://docs.coderabbit.ai)
- **GitHub Actions**: [docs.github.com/en/actions](https://docs.github.com/en/actions)
- **Python Best Practices**: [peps.python.org/pep-0008](https://peps.python.org/pep-0008/)
- **Clean Architecture**: [blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html)

## üôè Thank You!

Your Folder Extractor project is now **production-ready** with:

- Professional GitHub repository structure
- State-of-the-art CI/CD pipeline
- AI-powered code reviews with CodeRabbit
- Comprehensive documentation
- Modern Python development practices

**Ready to push to GitHub and start collaborating!** üöÄ

---

*Need help? Check the documentation or ask the community!* üòä
</file>

<file path="GITHUB_README.md">
# Folder Extractor üóÇÔ∏è

[![Python](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Code Style](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

A **secure command-line tool** for extracting files from subdirectories into the current folder. Perfect for cleaning up deeply nested folder structures.

## üöÄ Features

- **üîí Security**: Only runs in Desktop, Downloads, or Documents folders
- **üìÅ Smart Duplicate Handling**: Automatic renaming for duplicate files
- **üéØ Depth Control**: Specify how deep to search in folder structure
- **üßπ Auto-Cleanup**: Removes empty folders after moving files
- **üìä Detailed Feedback**: Shows each step and final summary
- **‚úÖ User Confirmation**: Preview and confirmation before execution
- **üõë ESC Key Abort**: Safe cancellation at any time
- **‚Ü©Ô∏è Undo Function**: Revert the last operation
- **üîç Dry-Run Mode**: Preview what would happen without doing it
- **üìà Progress Display**: Percentage progress during operations
- **üìé File Type Filter**: Extract only specific file types
- **üåê Domain Filter**: Filter web links by domain
- **üóÇÔ∏è Sort by Type**: Organize files automatically into type folders
- **üëª Hidden Files**: Optionally include hidden files

## üì¶ Installation

### System-wide installation via pip

```bash
# In the project directory:
pip install .

# Or for development (editable installation):
pip install -e .
```

After installation, the `folder-extractor` command is available system-wide!

### Alternative: Direct usage without installation

```bash
python folder_extractor.py [options]
```

## üíª Usage

```bash
# Standard: Unlimited depth
folder-extractor

# Maximum 3 levels deep
folder-extractor --depth 3

# Only first level
folder-extractor --depth 1

# Preview without actual moving
folder-extractor --dry-run

# Undo last operation
folder-extractor --undo

# Show version
folder-extractor --version

# Extract only PDFs (folder structure remains)
folder-extractor --type pdf

# Multiple file types
folder-extractor --type pdf,doc,docx

# Extract images from max 2 levels
folder-extractor --type jpg,png,gif --depth 2

# Extract only YouTube links
folder-extractor --type url,webloc --domain youtube.com

# Links from multiple domains
folder-extractor --type url --domain youtube.com,github.com,reddit.com

# Sort files by type
folder-extractor --sort-by-type

# Include hidden files
folder-extractor --include-hidden

# Combined: Extract hidden PDFs sorted
folder-extractor --type pdf --include-hidden --sort-by-type
```

## üìö Documentation

- [ARCHITECTURE.md](ARCHITECTURE.md) - Detailed architecture documentation
- [CHANGELOG.md](CHANGELOG.md) - Version history and changes
- [README.md](README.md) - Complete German documentation

## üîß Development

### Requirements

- Python 3.7+
- macOS, Linux, or Windows
- No external dependencies

### Running Tests

```bash
python -m pytest tests/

# Run specific test
python -m pytest tests/unit/test_core_extractor.py

# Run with coverage
python -m pytest --cov=folder_extractor tests/
```

### Project Structure

```
folder_extractor/
‚îú‚îÄ‚îÄ cli/                  # Command Line Interface
‚îú‚îÄ‚îÄ core/                 # Business Logic
‚îú‚îÄ‚îÄ config/               # Configuration
‚îú‚îÄ‚îÄ utils/                # Utilities
‚îî‚îÄ‚îÄ main_final.py         # Main entry point
```

## ü§ù Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/your-feature`
3. Commit your changes: `git commit -m 'Add some feature'`
4. Push to the branch: `git push origin feature/your-feature`
5. Open a pull request

## üìú License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üéØ Future Enhancements

- GUI frontend using the same core
- Network operations for remote file systems
- Plugin system for dynamic extensions
- Parallel processing for file operations
- Cloud storage provider support

## üìû Contact

For questions or suggestions, please open an issue or contact the maintainer.

---

**Folder Extractor** - Making file organization simple and secure! üöÄ
</file>

<file path="GITHUB_SETUP_SUMMARY.md">
# GitHub Repository Setup Summary

## üéâ Repository Successfully Initialized!

Your Folder Extractor project is now ready for GitHub! Here's what has been set up:

## üìÅ Repository Structure

```
Folder Extractor/
‚îú‚îÄ‚îÄ .git/                    # Git repository
‚îú‚îÄ‚îÄ .github/                 # GitHub configuration
‚îÇ   ‚îú‚îÄ‚îÄ ISSUE_TEMPLATE/      # Issue templates
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bug_report.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feature_request.md
‚îÇ   ‚îú‚îÄ‚îÄ PULL_REQUEST_TEMPLATE.md
‚îÇ   ‚îî‚îÄ‚îÄ workflows/           # CI/CD workflows
‚îÇ       ‚îú‚îÄ‚îÄ python-package.yml
‚îÇ       ‚îî‚îÄ‚îÄ release.yml
‚îú‚îÄ‚îÄ .gitignore              # Files to ignore
‚îú‚îÄ‚îÄ GITHUB_README.md        # GitHub-specific README
‚îú‚îÄ‚îÄ README.md               # Original German README
‚îú‚îÄ‚îÄ LICENSE                 # MIT License
‚îú‚îÄ‚îÄ CONTRIBUTING.md         # Contribution guidelines
‚îú‚îÄ‚îÄ CODE_OF_CONDUCT.md      # Community guidelines
‚îú‚îÄ‚îÄ CHANGELOG.md            # Version history
‚îú‚îÄ‚îÄ requirements.txt        # Development dependencies
‚îú‚îÄ‚îÄ folder_extractor/       # Main package
‚îú‚îÄ‚îÄ tests/                  # Test suite
‚îî‚îÄ‚îÄ setup.py                # Package configuration
```

## üöÄ GitHub Setup Instructions

### 1. Create GitHub Repository

1. Go to [GitHub](https://github.com) and log in
2. Click "New" to create a new repository
3. Enter repository name: `folder-extractor`
4. Choose **Public** or **Private**
5. **Do NOT** initialize with README, .gitignore, or license
6. Click "Create repository"

### 2. Connect Local Repository to GitHub

```bash
# Navigate to your project directory
cd /Users/philippbriese/Documents/dev/dump/Folder\ Extractor

# Add GitHub as remote repository
git remote add origin https://github.com/your-username/folder-extractor.git

# Push your code to GitHub
git push -u origin master
```

### 3. Enable GitHub Features

After pushing, go to your GitHub repository and:

1. **Enable Issues**: Already enabled by default
2. **Enable Wiki**: Optional for additional documentation
3. **Enable Projects**: For project management
4. **Enable Discussions**: For community discussions

## ü§ñ CI/CD Pipeline

The repository includes **GitHub Actions workflows** that will automatically:

### Python Package CI Workflow
- **Tests**: Runs on Python 3.7-3.12
- **Linting**: Checks code style with Black, Flake8, isort
- **Coverage**: Uploads test coverage to Codecov
- **Build**: Creates distribution packages

### Release Workflow
- **Automatic releases** when tags are pushed (e.g., `v1.3.4`)
- **Builds and uploads** Python packages to releases
- **Creates release notes** automatically

## üìã Issue and Pull Request Templates

### Issue Templates
- **Bug Report**: Structured template for reporting bugs
- **Feature Request**: Template for suggesting new features

### Pull Request Template
- Checklist for contributors
- Related issue tracking
- Testing requirements
- Documentation updates

## üìù Documentation Files

### GITHUB_README.md
- English version optimized for GitHub
- Badges for Python version, license, code style
- Clear installation and usage instructions
- Feature highlights with emojis

### CONTRIBUTING.md
- Comprehensive contribution guidelines
- Development workflow
- Code style requirements
- Testing instructions
- Branch strategy

### CODE_OF_CONDUCT.md
- Community guidelines based on Contributor Covenant
- Standards for behavior
- Reporting procedures
- Enforcement policies

## üîß Development Setup

### Install Dependencies

```bash
pip install -r requirements.txt
pip install -e .
```

### Run Tests

```bash
python -m pytest tests/
```

### Run Linting

```bash
black .
flake8 .
isort .
```

## üéØ Next Steps

1. **Push to GitHub**: `git push -u origin master`
2. **Create a release**: Tag a version and push it
3. **Set up Codecov**: Add CODECOV_TOKEN to GitHub secrets
4. **Enable GitHub Pages**: For documentation (optional)
5. **Add collaborators**: If working with a team

## üìä Repository Statistics

- **Commits**: 9 initial commits
- **Files**: 120+ Python files
- **Lines of Code**: 9,393+ lines
- **Test Coverage**: Ready for integration
- **Documentation**: Complete and comprehensive

## üéâ Congratulations!

Your Folder Extractor project is now **GitHub-ready** with:

‚úÖ Professional repository structure  
‚úÖ CI/CD pipeline with GitHub Actions  
‚úÖ Issue and PR templates  
‚úÖ Comprehensive documentation  
‚úÖ Contribution guidelines  
‚úÖ Code of conduct  
‚úÖ MIT License  
‚úÖ Development dependencies  
‚úÖ Test suite  
‚úÖ Professional README  

The repository follows **best practices** for open-source projects and is ready for collaboration! üöÄ
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2024 Philipp Briese

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>

<file path="README.md">
# Folder Extractor

Ein sicheres Command-Line-Tool zum Extrahieren aller Dateien aus Unterordnern in den aktuellen Ordner. Perfekt zum Aufr√§umen tief verschachtelter Ordnerstrukturen.

## Features

- üîí **Sicherheitspr√ºfung**: L√§uft nur in Desktop, Downloads oder Documents Ordnern
- üìÅ **Intelligente Duplikat-Behandlung**: Automatische Umbenennung bei gleichnamigen Dateien
- üéØ **Flexible Tiefensteuerung**: Bestimmen Sie, wie tief in die Ordnerstruktur gesucht werden soll
- üßπ **Automatisches Aufr√§umen**: Entfernt leere Ordner nach dem Verschieben
- üìä **Detailliertes Feedback**: Zeigt jeden Schritt und eine abschlie√üende Zusammenfassung
- ‚úÖ **Benutzer-Best√§tigung**: Zeigt Vorschau und fragt vor dem Start nach Best√§tigung
- üõë **ESC-Taste zum Abbrechen**: Jederzeit sicherer Abbruch m√∂glich
- ‚Ü©Ô∏è **Undo-Funktion**: Macht die letzte Operation r√ºckg√§ngig
- üîç **Dry-Run Modus**: Zeigt was passieren w√ºrde, ohne es zu tun
- üìà **Fortschrittsanzeige**: Prozentuale Anzeige w√§hrend der Verschiebung
- üìé **Dateityp-Filter**: Extrahiere nur bestimmte Dateitypen (NEU in v1.2.0)
- üåê **Domain-Filter**: Filtere Web-Links nach bestimmten Domains (NEU in v1.2.0)
- üóÇÔ∏è **Sortierung nach Typ**: Organisiere Dateien automatisch in Typ-Ordner (NEU in v1.3.0)
- üëª **Versteckte Dateien**: Optional auch versteckte Dateien einbeziehen (NEU in v1.3.2)

## Installation

### Systemweite Installation via pip

```bash
# Im Projektverzeichnis ausf√ºhren:
pip install .

# Oder f√ºr Entwicklung (editierbare Installation):
pip install -e .
```

Nach der Installation ist der Befehl `folder-extractor` systemweit verf√ºgbar!

### Alternative: Direkte Nutzung ohne Installation

```bash
python folder_extractor.py [optionen]
```

## Verwendung

Nach der Installation k√∂nnen Sie das Tool in jedem erlaubten Ordner verwenden:

```bash
# Standard: Unbegrenzte Tiefe
folder-extractor

# Maximal 3 Ebenen tief suchen
folder-extractor --depth 3

# Nur erste Ebene
folder-extractor --depth 1

# Vorschau ohne tats√§chliche Verschiebung
folder-extractor --dry-run

# Letzte Operation r√ºckg√§ngig machen
folder-extractor --undo

# Version anzeigen
folder-extractor --version

# Nur PDFs extrahieren (Ordnerstruktur bleibt erhalten)
folder-extractor --type pdf

# Mehrere Dateitypen
folder-extractor --type pdf,doc,docx

# Bilder aus maximal 2 Ebenen extrahieren
folder-extractor --type jpg,png,gif --depth 2

# Nur YouTube-Links extrahieren
folder-extractor --type url,webloc --domain youtube.com

# Links von mehreren Domains
folder-extractor --type url --domain youtube.com,github.com,reddit.com

# Dateien nach Typ sortieren
folder-extractor --sort-by-type

# Versteckte Dateien einbeziehen
folder-extractor --include-hidden

# Kombiniert: Versteckte PDFs sortiert extrahieren
folder-extractor --type pdf --include-hidden --sort-by-type
```

### Dateityp-Filter (NEU in v1.2.0)

Mit der `--type` Option k√∂nnen Sie gezielt nur bestimmte Dateitypen extrahieren:
- Andere Dateien bleiben unber√ºhrt
- Die Ordnerstruktur bleibt vollst√§ndig erhalten
- Perfekt f√ºr selektives Organisieren

Beispiele f√ºr Dateitypen:
- **Dokumente**: pdf, doc, docx, txt, odt, md
- **Bilder**: jpg, jpeg, png, gif, bmp, svg
- **Web-Links**: url, webloc
- **Daten**: json, xml, csv, xlsx
- **Code**: py, js, java, cpp, html, css, md

### Domain-Filter f√ºr Web-Links (NEU in v1.2.0)

Mit der `--domain` Option k√∂nnen Sie Web-Links nach Domains filtern:
- Funktioniert nur zusammen mit `--type url` oder `--type webloc`
- Unterst√ºtzt Subdomains (youtube.com matcht auch m.youtube.com)
- Mehrere Domains mit Komma trennen

Beispiele:
```bash
# Alle YouTube-Links sammeln
folder-extractor --type url,webloc --domain youtube.com

# Links von bestimmten Entwickler-Seiten
folder-extractor --type url --domain github.com,stackoverflow.com

# Reddit-Links aus maximal 3 Ebenen
folder-extractor --type url,webloc --domain reddit.com --depth 3
```

### Sortierung nach Typ (NEU in v1.3.0)

Mit der `--sort-by-type` Option werden Dateien automatisch in Typ-spezifische Ordner organisiert:
- Erstellt automatisch Ordner wie PDF/, JPEG/, DOCX/, etc.
- √Ñhnliche Typen werden zusammengefasst (jpg ‚Üí JPEG/)
- Dateien ohne Erweiterung ‚Üí OHNE_ERWEITERUNG/
- Funktioniert mit allen anderen Optionen

Beispiel-Struktur nach Sortierung:
```
Arbeitsordner/
‚îú‚îÄ‚îÄ PDF/       (alle .pdf Dateien)
‚îú‚îÄ‚îÄ JPEG/      (alle .jpg und .jpeg Dateien)  
‚îú‚îÄ‚îÄ PNG/       (alle .png Dateien)
‚îî‚îÄ‚îÄ DOCX/      (alle .docx Dateien)
```

### Versteckte Dateien einbeziehen (NEU in v1.3.2)

Mit der `--include-hidden` Option werden auch versteckte Dateien (die mit . beginnen) extrahiert:
- Standardm√§√üig werden versteckte Dateien/Ordner ignoriert
- System-Dateien wie .DS_Store werden weiterhin ignoriert
- N√ºtzlich f√ºr Konfigurationsdateien wie .env, .gitignore, etc.

Beispiele:
```bash
# Alle Dateien inklusive versteckte
folder-extractor --include-hidden

# Versteckte Konfigurationsdateien extrahieren
folder-extractor --type json,yml,env --include-hidden
```

### Sicherheitsfeatures

1. **Best√§tigung vor Start**: Das Tool zeigt eine detaillierte Vorschau und wartet auf Ihre Best√§tigung ("leg los" oder "stop")
2. **ESC zum Abbrechen**: Dr√ºcken Sie jederzeit ESC, um den Prozess sicher zu stoppen
3. **Undo-Funktion**: Jede Operation wird gespeichert und kann mit `--undo` r√ºckg√§ngig gemacht werden

## Beispiel

```bash
cd ~/Desktop/MeinProjekt
folder-extractor --depth 2
```

Dies wird:
1. Alle Dateien aus Unterordnern bis zur 2. Ebene finden
2. Diese in den Ordner "MeinProjekt" verschieben
3. Duplikate automatisch umbenennen (z.B. bild.jpg ‚Üí bild_1.jpg)
4. Alle nun leeren Unterordner entfernen

## Sicherheit

Das Tool verhindert versehentliche Ausf√ºhrung in Systemordnern. Es l√§uft ausschlie√ülich in:
- `~/Desktop/*`
- `~/Downloads/*`
- `~/Documents/*`

## Deinstallation

```bash
pip uninstall folder-extractor
```

## Systemanforderungen

- Python 3.7 oder h√∂her
- macOS, Linux oder Windows
- Keine externen Abh√§ngigkeiten

## Lizenz

MIT License
</file>

<file path="requirements.txt">
# Development requirements
pytest==8.4.2
pytest-cov==4.1.0
black==23.12.1
flake8==6.1.0
isort==5.13.2
build==1.0.3
twine==4.0.2

# Optional for better testing
pytest-mock==3.12.0
coverage==7.4.0
</file>

<file path="run_tests.py">
#!/usr/bin/env python3
"""
Test runner for Folder Extractor.

Usage:
    python run_tests.py              # Run all tests
    python run_tests.py unit         # Run only unit tests
    python run_tests.py integration  # Run only integration tests
    python run_tests.py performance  # Run performance benchmarks
    python run_tests.py coverage     # Run with coverage report
"""
import sys
import subprocess
import os
from pathlib import Path


def run_command(cmd, description):
    """Run a command and print results."""
    print(f"\n{'='*60}")
    print(f"{description}")
    print(f"{'='*60}\n")
    
    result = subprocess.run(cmd, shell=True)
    return result.returncode


def main():
    """Main test runner."""
    # Change to project directory
    project_dir = Path(__file__).parent
    os.chdir(project_dir)
    
    # Determine what to run
    if len(sys.argv) > 1:
        test_type = sys.argv[1].lower()
    else:
        test_type = "all"
    
    # Install test dependencies if needed
    if not Path("pytest").exists():
        print("Installing test dependencies...")
        subprocess.run([sys.executable, "-m", "pip", "install", "-e", ".[test]"])
    
    exit_code = 0
    
    if test_type == "unit":
        exit_code = run_command(
            "pytest tests/unit -v",
            "Running Unit Tests"
        )
    
    elif test_type == "integration":
        exit_code = run_command(
            "pytest tests/integration -v",
            "Running Integration Tests"
        )
    
    elif test_type == "performance":
        exit_code = run_command(
            "pytest tests/performance -v -m benchmark",
            "Running Performance Benchmarks"
        )
    
    elif test_type == "coverage":
        exit_code = run_command(
            "pytest --cov=folder_extractor --cov-report=html --cov-report=term",
            "Running Tests with Coverage"
        )
        print("\nCoverage report generated in htmlcov/index.html")
    
    elif test_type == "all":
        # Run all test types
        test_types = [
            ("pytest tests/unit -v", "Running Unit Tests"),
            ("pytest tests/integration -v", "Running Integration Tests"),
            ("pytest tests/performance -v -m benchmark -k 'not test_'", "Running Quick Benchmarks")
        ]
        
        for cmd, desc in test_types:
            code = run_command(cmd, desc)
            if code != 0:
                exit_code = code
    
    else:
        print(f"Unknown test type: {test_type}")
        print(__doc__)
        exit_code = 1
    
    # Print summary
    print(f"\n{'='*60}")
    if exit_code == 0:
        print("‚úÖ All tests passed!")
    else:
        print("‚ùå Some tests failed!")
    print(f"{'='*60}\n")
    
    return exit_code


if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="setup.py">
#!/usr/bin/env python3
"""
Setup-Skript f√ºr Folder Extractor
Erm√∂glicht die Installation via pip
"""

from setuptools import setup, find_packages
from pathlib import Path

# README einlesen
this_directory = Path(__file__).parent
long_description = (this_directory / "README.md").read_text(encoding="utf-8") if (this_directory / "README.md").exists() else ""

setup(
    name="folder-extractor",
    version="1.3.3",
    author="Philipp Briese",
    author_email="",
    description="Ein sicheres Tool zum Extrahieren von Dateien aus Unterordnern",
    long_description=long_description,
    long_description_content_type="text/markdown",
    url="https://github.com/yourusername/folder-extractor",
    packages=find_packages(),
    classifiers=[
        "Development Status :: 4 - Beta",
        "Intended Audience :: End Users/Desktop",
        "Topic :: Utilities",
        "License :: OSI Approved :: MIT License",
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.7",
        "Programming Language :: Python :: 3.8",
        "Programming Language :: Python :: 3.9",
        "Programming Language :: Python :: 3.10",
        "Programming Language :: Python :: 3.11",
        "Operating System :: MacOS",
        "Operating System :: POSIX :: Linux",
        "Operating System :: Microsoft :: Windows",
    ],
    python_requires=">=3.7",
    entry_points={
        "console_scripts": [
            "folder-extractor=folder_extractor.main_final:main",
        ],
    },
    install_requires=[
        # Keine externen Abh√§ngigkeiten - nur Standard-Bibliotheken
    ],
    extras_require={
        "test": [
            "pytest>=7.0",
            "pytest-cov>=4.0",
            "pytest-benchmark>=4.0",
        ],
    },
    keywords="folder, extractor, organize, files, directory, cleanup",
    project_urls={
        "Bug Reports": "https://github.com/yourusername/folder-extractor/issues",
        "Source": "https://github.com/yourusername/folder-extractor",
    },
)
</file>

</files>
